{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples for SRL - allennlp\n",
    "\n",
    "The examples in this notebook work with the allennlp model. You can easily adapt the code to the output of a different model. \n",
    "\n",
    "The main purpose of the code presented here is to adapt Checklist to a complex sequence classification problem. Inspiration is taken from the NER notebook included in checklist. \n",
    "\n",
    "I'm sure there are more sophisticated tests - this is just supposed to get you started. \n",
    "\n",
    "Enjoy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp_models.pretrained import load_predictor\n",
    "from allennlp_models.pretrained import get_pretrained_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import checklist\n",
    "from checklist.editor import Editor\n",
    "from checklist.perturb import Perturb\n",
    "from checklist.test_types import MFT, INV, DIR\n",
    "from checklist.expect import Expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from checklist.pred_wrapper import PredictorWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:18:21,949 - INFO - allennlp.common.plugins - Plugin allennlp_models available\n",
      "2022-03-29 15:18:22,097 - INFO - allennlp.common.params - id = vgqa-vilbert\n",
      "2022-03-29 15:18:22,098 - INFO - allennlp.common.params - registered_model_name = vqa_vilbert_from_huggingface\n",
      "2022-03-29 15:18:22,104 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:22,109 - INFO - allennlp.common.params - registered_predictor_name = vgqa_vilbert\n",
      "2022-03-29 15:18:22,119 - INFO - allennlp.common.params - display_name = ViLBERT - Visual Genome Question Answering\n",
      "2022-03-29 15:18:22,124 - INFO - allennlp.common.params - task_id = vgqa\n",
      "2022-03-29 15:18:22,128 - INFO - allennlp.common.params - model_usage.archive_file = vilbert-vgqa-pretrained.2021-05-10.tar.gz\n",
      "2022-03-29 15:18:22,160 - INFO - allennlp.common.params - model_usage.training_config = vision/vilbert_vgqa_pretrained.jsonnet\n",
      "2022-03-29 15:18:22,164 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.5.0 allennlp-models==2.5.0\n",
      "2022-03-29 15:18:22,172 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:22,186 - INFO - allennlp.common.params - model_details.description = ViLBERT (short for Vision-and-Language BERT), is a model for learning task-agnostic joint representations of image content and natural language.\n",
      "2022-03-29 15:18:22,220 - INFO - allennlp.common.params - model_details.short_description = ViLBERT (short for Vision-and-Language BERT), is a model for learning task-agnostic joint representations of image content and natural language.\n",
      "2022-03-29 15:18:22,234 - INFO - allennlp.common.params - model_details.developed_by = Lu et al\n",
      "2022-03-29 15:18:22,251 - INFO - allennlp.common.params - model_details.contributed_by = Jacob Morrison\n",
      "2022-03-29 15:18:22,256 - INFO - allennlp.common.params - model_details.date = 2021-05-07\n",
      "2022-03-29 15:18:22,294 - INFO - allennlp.common.params - model_details.version = 2\n",
      "2022-03-29 15:18:22,307 - INFO - allennlp.common.params - model_details.model_type = ViLBERT based on BERT large\n",
      "2022-03-29 15:18:22,313 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Lu2019ViLBERTPT,\n",
      "title={ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks},\n",
      "author={Jiasen Lu and Dhruv Batra and D. Parikh and Stefan Lee},\n",
      "booktitle={NeurIPS},\n",
      "year={2019}\n",
      "}\n",
      "2022-03-29 15:18:22,332 - INFO - allennlp.common.params - model_details.paper.title = ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks\n",
      "2022-03-29 15:18:22,338 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:199453025\n",
      "2022-03-29 15:18:22,340 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:22,342 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:22,345 - INFO - allennlp.common.params - intended_use.primary_uses = This model is developed for the AllenNLP demo.\n",
      "2022-03-29 15:18:22,369 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:22,372 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:22,385 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:22,399 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:22,402 - INFO - allennlp.common.params - metrics.model_performance_measures = F1-metric and VQA score\n",
      "2022-03-29 15:18:22,405 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:22,430 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:22,437 - INFO - allennlp.common.params - evaluation_data.dataset.name = VGQA dataset\n",
      "2022-03-29 15:18:22,448 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Evaluation requires a large amount of images to be accessible locally, so we cannot provide a command you can easily copy and paste. The first time you run it, you will get an error message that tells you how to get the rest of the data.\n",
      "2022-03-29 15:18:22,465 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://visualgenome.org/static/data/dataset/question_answers.json.zip!question_answers.json[:5000]\n",
      "2022-03-29 15:18:22,475 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://visualgenome.org/\n",
      "2022-03-29 15:18:22,484 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:22,489 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:22,510 - INFO - allennlp.common.params - training_data.dataset.name = VGQA dataset\n",
      "2022-03-29 15:18:22,523 - INFO - allennlp.common.params - training_data.dataset.notes = Training requires a large amount of images to be accessible locally, so we cannot provide a command you can easily copy and paste. The first time you run it, you will get an error message that tells you how to get the rest of the data.\n",
      "2022-03-29 15:18:22,527 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://visualgenome.org/static/data/dataset/question_answers.json.zip!question_answers.json[5000:]\n",
      "2022-03-29 15:18:22,529 - INFO - allennlp.common.params - training_data.dataset.url = https://visualgenome.org/\n",
      "2022-03-29 15:18:22,533 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:22,538 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:22,541 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = On the validation set:\n",
      "F1: 29.6%\n",
      "VQA: 26.5%.\n",
      "These scores do not match the performance in the VilBERT paper. Please contact us if you want to match those scores!\n",
      "2022-03-29 15:18:22,545 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:22,552 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:22,555 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:22,688 - INFO - allennlp.common.params - id = structured-prediction-srl-bert\n",
      "2022-03-29 15:18:22,692 - INFO - allennlp.common.params - registered_model_name = srl_bert\n",
      "2022-03-29 15:18:22,695 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:22,696 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:22,697 - INFO - allennlp.common.params - display_name = SRL BERT\n",
      "2022-03-29 15:18:22,698 - INFO - allennlp.common.params - task_id = srl\n",
      "2022-03-29 15:18:22,699 - INFO - allennlp.common.params - model_usage.archive_file = structured-prediction-srl-bert.2020.12.15.tar.gz\n",
      "2022-03-29 15:18:22,702 - INFO - allennlp.common.params - model_usage.training_config = structured_prediction/bert_base_srl.jsonnet\n",
      "2022-03-29 15:18:22,707 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 15:18:22,708 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:22,709 - INFO - allennlp.common.params - model_details.description = An implementation of a BERT based model (Shi et al, 2019) with some modifications (no additional parameters apart from a linear classification layer), which is currently the state of the art single model for English PropBank SRL (Newswire sentences). It achieves 86.49 test F1 on the Ontonotes 5.0 dataset.\n",
      "2022-03-29 15:18:22,710 - INFO - allennlp.common.params - model_details.short_description = A BERT based model (Shi et al, 2019) with some modifications (no additional parameters apart from a linear classification layer)\n",
      "2022-03-29 15:18:22,712 - INFO - allennlp.common.params - model_details.developed_by = Shi et al\n",
      "2022-03-29 15:18:22,714 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 15:18:22,715 - INFO - allennlp.common.params - model_details.date = 2020-09-03\n",
      "2022-03-29 15:18:22,717 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:22,720 - INFO - allennlp.common.params - model_details.model_type = BERT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:18:22,724 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Shi2019SimpleBM,\n",
      "title={Simple BERT Models for Relation Extraction and Semantic Role Labeling},\n",
      "author={Peng Shi and Jimmy Lin},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1904.05255}}\n",
      "\n",
      "2022-03-29 15:18:22,725 - INFO - allennlp.common.params - model_details.paper.title = Simple BERT Models for Relation Extraction and Semantic Role Labeling\n",
      "2022-03-29 15:18:22,728 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:131773936\n",
      "2022-03-29 15:18:22,730 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:22,739 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:22,750 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:22,759 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:22,760 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:22,765 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:22,785 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:22,794 - INFO - allennlp.common.params - metrics.model_performance_measures = Precision, recall and F1-score\n",
      "2022-03-29 15:18:22,796 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:22,798 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:22,802 - INFO - allennlp.common.params - evaluation_data.dataset.name = Ontonotes 5.0\n",
      "2022-03-29 15:18:22,804 - INFO - allennlp.common.params - evaluation_data.dataset.notes = We cannot release this data due to licensing restrictions.\n",
      "2022-03-29 15:18:22,805 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "2022-03-29 15:18:22,807 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:22,809 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:22,810 - INFO - allennlp.common.params - training_data.dataset.name = Ontonotes 5.0\n",
      "2022-03-29 15:18:22,812 - INFO - allennlp.common.params - training_data.dataset.notes = We cannot release this data due to licensing restrictions.\n",
      "2022-03-29 15:18:22,814 - INFO - allennlp.common.params - training_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "2022-03-29 15:18:22,816 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:22,823 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:22,825 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = 86.49 test F1 on the Ontonotes 5.0 dataset\n",
      "2022-03-29 15:18:22,827 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:22,829 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:22,832 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:23,046 - INFO - allennlp.common.params - id = semparse-nlvr\n",
      "2022-03-29 15:18:23,048 - INFO - allennlp.common.params - registered_model_name = None\n",
      "2022-03-29 15:18:23,053 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:23,055 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:23,059 - INFO - allennlp.common.params - display_name = NLVR Semantic Parsing\n",
      "2022-03-29 15:18:23,065 - INFO - allennlp.common.params - task_id = semparse-nlvr\n",
      "2022-03-29 15:18:23,066 - INFO - allennlp.common.params - model_usage.archive_file = https://allennlp.s3.amazonaws.com/models/nlvr-erm-model-2020.02.10-rule-vocabulary-updated.tar.gz\n",
      "2022-03-29 15:18:23,068 - INFO - allennlp.common.params - model_usage.training_config = None\n",
      "2022-03-29 15:18:23,069 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-03-29 15:18:23,071 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:23,073 - INFO - allennlp.common.params - model_details.description = The model is a semantic parser trained on Cornell NLVR.\n",
      "2022-03-29 15:18:23,074 - INFO - allennlp.common.params - model_details.short_description = The model is a semantic parser trained on Cornell NLVR.\n",
      "2022-03-29 15:18:23,075 - INFO - allennlp.common.params - model_details.developed_by = Dasigi et al\n",
      "2022-03-29 15:18:23,077 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 15:18:23,079 - INFO - allennlp.common.params - model_details.date = None\n",
      "2022-03-29 15:18:23,080 - INFO - allennlp.common.params - model_details.version = None\n",
      "2022-03-29 15:18:23,082 - INFO - allennlp.common.params - model_details.model_type = None\n",
      "2022-03-29 15:18:23,087 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Dasigi2019IterativeSF,\n",
      "title={Iterative Search for Weakly Supervised Semantic Parsing},\n",
      "author={Pradeep Dasigi and Matt Gardner and Shikhar Murty and Luke Zettlemoyer and E. Hovy},\n",
      "booktitle={NAACL-HLT},\n",
      "year={2019}}\n",
      "\n",
      "2022-03-29 15:18:23,088 - INFO - allennlp.common.params - model_details.paper.title = Iterative Search for Weakly Supervised Semantic Parsing\n",
      "2022-03-29 15:18:23,090 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:174799945\n",
      "2022-03-29 15:18:23,092 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:23,093 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:23,094 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:23,096 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:23,097 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:23,100 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:23,105 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:23,112 - INFO - allennlp.common.params - metrics.model_performance_measures = Denotation accuracy and consistency\n",
      "2022-03-29 15:18:23,115 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:23,118 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:23,122 - INFO - allennlp.common.params - evaluation_data.dataset.name = Cornell NLVR\n",
      "2022-03-29 15:18:23,124 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-03-29 15:18:23,128 - INFO - allennlp.common.params - evaluation_data.dataset.url = http://lil.nlp.cornell.edu/nlvr/\n",
      "2022-03-29 15:18:23,130 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:23,132 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:23,138 - INFO - allennlp.common.params - training_data.dataset.name = Cornell NLVR\n",
      "2022-03-29 15:18:23,140 - INFO - allennlp.common.params - training_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-03-29 15:18:23,143 - INFO - allennlp.common.params - training_data.dataset.url = http://lil.nlp.cornell.edu/nlvr/\n",
      "2022-03-29 15:18:23,148 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:23,151 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:23,153 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 15:18:23,158 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:23,162 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:23,164 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:23,344 - INFO - allennlp.common.params - id = structured-prediction-biaffine-parser\n",
      "2022-03-29 15:18:23,348 - INFO - allennlp.common.params - registered_model_name = biaffine_parser\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:18:23,350 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:23,354 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:23,363 - INFO - allennlp.common.params - display_name = Deep Biaffine Attention for Neural Dependency Parsing\n",
      "2022-03-29 15:18:23,367 - INFO - allennlp.common.params - task_id = dependency-parsing\n",
      "2022-03-29 15:18:23,375 - INFO - allennlp.common.params - model_usage.archive_file = biaffine-dependency-parser-ptb-2020.04.06.tar.gz\n",
      "2022-03-29 15:18:23,400 - INFO - allennlp.common.params - model_usage.training_config = structured_prediction/dependency_parser.jsonnet\n",
      "2022-03-29 15:18:23,403 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 15:18:23,405 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:23,414 - INFO - allennlp.common.params - model_details.description = This dependency parser follows the model of [Deep Biaffine Attention for Neural Dependency Parsing (Dozat and Manning, 2016)](https://api.semanticscholar.org/CorpusID:7942973) .\n",
      "\n",
      "Word representations are generated using a bidirectional LSTM, followed by separate biaffine classifiers for pairs of words, predicting whether a directed arc exists between the two words and the dependency label the arc should have. Decoding can either be done greedily, or the optimal Minimum Spanning Tree can be decoded using Edmond's algorithm by viewing the dependency tree as a MST on a fully connected graph, where nodes are words and edges are scored dependency arcs.\n",
      "2022-03-29 15:18:23,428 - INFO - allennlp.common.params - model_details.short_description = A neural model for dependency parsing using biaffine classifiers on top of a bidirectional LSTM.\n",
      "2022-03-29 15:18:23,438 - INFO - allennlp.common.params - model_details.developed_by = Dozat et al\n",
      "2022-03-29 15:18:23,453 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 15:18:23,462 - INFO - allennlp.common.params - model_details.date = 2020-04-06\n",
      "2022-03-29 15:18:23,465 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:23,474 - INFO - allennlp.common.params - model_details.model_type = None\n",
      "2022-03-29 15:18:23,479 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Dozat2017DeepBA,\n",
      "title={Deep Biaffine Attention for Neural Dependency Parsing},\n",
      "author={Timothy Dozat and Christopher D. Manning},\n",
      "journal={ArXiv},\n",
      "year={2017},\n",
      "volume={abs/1611.01734}}\n",
      "\n",
      "2022-03-29 15:18:23,511 - INFO - allennlp.common.params - model_details.paper.title = Deep Biaffine Attention for Neural Dependency Parsing (Dozat and Manning, 2016)\n",
      "2022-03-29 15:18:23,518 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:7942973\n",
      "2022-03-29 15:18:23,520 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:23,522 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:23,525 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:23,527 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:23,530 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:23,541 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:23,545 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:23,549 - INFO - allennlp.common.params - metrics.model_performance_measures = Attachment scores and exact matches (UAS, LAS, UEM, LEM)\n",
      "2022-03-29 15:18:23,551 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:23,555 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:23,560 - INFO - allennlp.common.params - evaluation_data.dataset.name = PTB 3.0\n",
      "2022-03-29 15:18:23,562 - INFO - allennlp.common.params - evaluation_data.dataset.notes = The dependency parser was evaluated on the Penn Tree Bank dataset. Unfortunately we cannot release this data due to licensing restrictions by the LDC. You can download the PTB data from the LDC website.\n",
      "2022-03-29 15:18:23,565 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = /path/to/dataset\n",
      "2022-03-29 15:18:23,568 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://catalog.ldc.upenn.edu/LDC99T42\n",
      "2022-03-29 15:18:23,570 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:23,572 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:23,576 - INFO - allennlp.common.params - training_data.dataset.name = PTB 3.0\n",
      "2022-03-29 15:18:23,582 - INFO - allennlp.common.params - training_data.dataset.notes = The dependency parser was evaluated on the Penn Tree Bank dataset. Unfortunately we cannot release this data due to licensing restrictions by the LDC. You can download the PTB data from the LDC website.\n",
      "2022-03-29 15:18:23,584 - INFO - allennlp.common.params - training_data.dataset.processed_url = /path/to/dataset\n",
      "2022-03-29 15:18:23,589 - INFO - allennlp.common.params - training_data.dataset.url = https://catalog.ldc.upenn.edu/LDC99T42\n",
      "2022-03-29 15:18:23,596 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:23,599 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:23,601 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = The parser achieves 95.57% and 94.44% unlabeled and labeled attachement score using gold POS tags. For predicted POS tags, it achieves 94.81% UAS and 92.86% LAS respectively.\n",
      "2022-03-29 15:18:23,605 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:23,609 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:23,613 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:23,741 - INFO - allennlp.common.params - id = mc-roberta-swag\n",
      "2022-03-29 15:18:23,747 - INFO - allennlp.common.params - registered_model_name = transformer_mc\n",
      "2022-03-29 15:18:23,749 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:23,751 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:23,756 - INFO - allennlp.common.params - display_name = RoBERTa SWAG\n",
      "2022-03-29 15:18:23,758 - INFO - allennlp.common.params - task_id = mc\n",
      "2022-03-29 15:18:23,761 - INFO - allennlp.common.params - model_usage.archive_file = swag.2020-07-08.tar.gz\n",
      "2022-03-29 15:18:23,764 - INFO - allennlp.common.params - model_usage.training_config = mc/swag.jsonnet\n",
      "2022-03-29 15:18:23,766 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-03-29 15:18:23,769 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:23,774 - INFO - allennlp.common.params - model_details.description = This is a multiple choice model patterned after the BERT architecture. It calculates a score for each sequence on top of the CLS token, and then chooses the alternative with the highest score.\n",
      "2022-03-29 15:18:23,778 - INFO - allennlp.common.params - model_details.short_description = RoBERTa-based multiple choice model for SWAG.\n",
      "2022-03-29 15:18:23,780 - INFO - allennlp.common.params - model_details.developed_by = Devlin et al\n",
      "2022-03-29 15:18:23,782 - INFO - allennlp.common.params - model_details.contributed_by = Dirk Groeneveld\n",
      "2022-03-29 15:18:23,785 - INFO - allennlp.common.params - model_details.date = 2020-07-08\n",
      "2022-03-29 15:18:23,788 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:23,790 - INFO - allennlp.common.params - model_details.model_type = RoBERTa large\n",
      "2022-03-29 15:18:23,793 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and Luke Zettlemoyer and Veselin Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:18:23,797 - INFO - allennlp.common.params - model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al)\n",
      "2022-03-29 15:18:23,798 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "2022-03-29 15:18:23,800 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:23,803 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:23,806 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:23,807 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:23,810 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:23,813 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:23,816 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:23,820 - INFO - allennlp.common.params - metrics.model_performance_measures = The chosen metric is accuracy, since it is a multiple choice model.\n",
      "2022-03-29 15:18:23,823 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:23,825 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:23,829 - INFO - allennlp.common.params - evaluation_data.dataset.name = SWAG (validation set)\n",
      "2022-03-29 15:18:23,833 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-03-29 15:18:23,834 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://rowanzellers.com/swag/\n",
      "2022-03-29 15:18:23,838 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:23,840 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:23,843 - INFO - allennlp.common.params - training_data.dataset.name = SWAG (train set)\n",
      "2022-03-29 15:18:23,845 - INFO - allennlp.common.params - training_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-03-29 15:18:23,846 - INFO - allennlp.common.params - training_data.dataset.url = https://rowanzellers.com/swag/\n",
      "2022-03-29 15:18:23,848 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:23,849 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:23,852 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 15:18:23,857 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:23,863 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:23,867 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:24,021 - INFO - allennlp.common.params - id = lm-masked-language-model\n",
      "2022-03-29 15:18:24,023 - INFO - allennlp.common.params - registered_model_name = masked_language_model\n",
      "2022-03-29 15:18:24,025 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:24,028 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:24,032 - INFO - allennlp.common.params - display_name = BERT-based Masked Language Model\n",
      "2022-03-29 15:18:24,034 - INFO - allennlp.common.params - task_id = masked-language-modeling\n",
      "2022-03-29 15:18:24,038 - INFO - allennlp.common.params - model_usage.archive_file = bert-masked-lm-2020-10-07.tar.gz\n",
      "2022-03-29 15:18:24,041 - INFO - allennlp.common.params - model_usage.training_config = lm/bidirectional_language_model.jsonnet\n",
      "2022-03-29 15:18:24,042 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 15:18:24,044 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:24,046 - INFO - allennlp.common.params - model_details.description = The `MaskedLanguageModel` embeds some input tokens (including some which are masked), contextualizes them, then predicts targets for the masked tokens, computing a loss against known targets.\n",
      "2022-03-29 15:18:24,049 - INFO - allennlp.common.params - model_details.short_description = BERT-based masked language model\n",
      "2022-03-29 15:18:24,052 - INFO - allennlp.common.params - model_details.developed_by = Devlin et al\n",
      "2022-03-29 15:18:24,056 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 15:18:24,057 - INFO - allennlp.common.params - model_details.date = 2020-10-07\n",
      "2022-03-29 15:18:24,060 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:24,063 - INFO - allennlp.common.params - model_details.model_type = BERT\n",
      "2022-03-29 15:18:24,067 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Devlin2019BERTPO,\n",
      "title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},\n",
      "author={J. Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},\n",
      "booktitle={NAACL-HLT},\n",
      "year={2019}}\n",
      "\n",
      "2022-03-29 15:18:24,068 - INFO - allennlp.common.params - model_details.paper.title = BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\n",
      "2022-03-29 15:18:24,072 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:52967399\n",
      "2022-03-29 15:18:24,074 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:24,075 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:24,076 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:24,078 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:24,079 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:24,080 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:24,082 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:24,087 - INFO - allennlp.common.params - metrics.model_performance_measures = Perplexity\n",
      "2022-03-29 15:18:24,090 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:24,094 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:24,098 - INFO - allennlp.common.params - evaluation_data.dataset = BooksCorpus (800M words) and English Wikipedia (2,500M words).\n",
      "2022-03-29 15:18:24,101 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:24,103 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:24,106 - INFO - allennlp.common.params - training_data.dataset = BooksCorpus (800M words) and English Wikipedia (2,500M words).\n",
      "2022-03-29 15:18:24,111 - INFO - allennlp.common.params - training_data.motivation = Document-level corpus is used rather than shuffled sentence-level corpus, to extract long contiguous sequences.\n",
      "2022-03-29 15:18:24,115 - INFO - allennlp.common.params - training_data.preprocessing = For Wikipedia, text passages are extracted and lists, tables, and headers are ignored.\n",
      "2022-03-29 15:18:24,118 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 15:18:24,122 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:24,126 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = BERT demonstrates gender bias in that it thinks the doctor is more likely a man ('his') than a woman ('her'). An important issue in NLP is how to understand and address such biases in our linguistic models.\n",
      "2022-03-29 15:18:24,132 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = NOTE: This was developed for use in a demo, not for training.  It's possible that it will still work for training a masked LM, but it is very likely that some other code would be much more efficient for that.  This `does` compute correct gradients of the loss, because we use that in our demo, so in principle it should be able to train a model, we just don't necessarily endorse that use.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:18:24,288 - INFO - allennlp.common.params - id = roberta-sst\n",
      "2022-03-29 15:18:24,291 - INFO - allennlp.common.params - registered_model_name = None\n",
      "2022-03-29 15:18:24,299 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:24,310 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:24,316 - INFO - allennlp.common.params - display_name = RoBERTa large\n",
      "2022-03-29 15:18:24,330 - INFO - allennlp.common.params - task_id = sentiment-analysis\n",
      "2022-03-29 15:18:24,339 - INFO - allennlp.common.params - model_usage.archive_file = stanford-sentiment-treebank-roberta.2021-03-11.tar.gz\n",
      "2022-03-29 15:18:24,347 - INFO - allennlp.common.params - model_usage.training_config = classification/stanford_sentiment_treebank_roberta.jsonnet\n",
      "2022-03-29 15:18:24,354 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.4.0 allennlp-models==2.4.0\n",
      "2022-03-29 15:18:24,357 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:24,370 - INFO - allennlp.common.params - model_details.description = This model is trained on RoBERTa large with the binary classification setting of the Stanford Sentiment Treebank. It achieves 95.11% accuracy on the test set.\n",
      "2022-03-29 15:18:24,381 - INFO - allennlp.common.params - model_details.short_description = RoBERTa-based binary classifier for Stanford Sentiment Treebank\n",
      "2022-03-29 15:18:24,390 - INFO - allennlp.common.params - model_details.developed_by = Devlin et al\n",
      "2022-03-29 15:18:24,392 - INFO - allennlp.common.params - model_details.contributed_by = Zhaofeng Wu\n",
      "2022-03-29 15:18:24,396 - INFO - allennlp.common.params - model_details.date = 2020-06-08\n",
      "2022-03-29 15:18:24,399 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:24,404 - INFO - allennlp.common.params - model_details.model_type = RoBERTa large\n",
      "2022-03-29 15:18:24,405 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and Luke Zettlemoyer and Veselin Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n",
      "2022-03-29 15:18:24,414 - INFO - allennlp.common.params - model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al)\n",
      "2022-03-29 15:18:24,425 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "2022-03-29 15:18:24,435 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:24,444 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:24,449 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:24,450 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:24,453 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:24,457 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:24,460 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:24,465 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy\n",
      "2022-03-29 15:18:24,471 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:24,480 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:24,483 - INFO - allennlp.common.params - evaluation_data.dataset.name = Stanford Sentiment Treebank\n",
      "2022-03-29 15:18:24,487 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/sst/test.txt\n",
      "2022-03-29 15:18:24,488 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://nlp.stanford.edu/sentiment/treebank.html\n",
      "2022-03-29 15:18:24,499 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:24,503 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:24,506 - INFO - allennlp.common.params - training_data.dataset.name = Stanford Sentiment Treebank\n",
      "2022-03-29 15:18:24,516 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/sst/train.txt\n",
      "2022-03-29 15:18:24,520 - INFO - allennlp.common.params - training_data.dataset.url = https://nlp.stanford.edu/sentiment/treebank.html\n",
      "2022-03-29 15:18:24,523 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:24,532 - INFO - allennlp.common.params - training_data.preprocessing = Binary classification setting\n",
      "2022-03-29 15:18:24,540 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = Accuracy: 95.11% on SST test set.\n",
      "2022-03-29 15:18:24,541 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:24,544 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:24,553 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:24,708 - INFO - allennlp.common.params - id = lm-next-token-lm-gpt2\n",
      "2022-03-29 15:18:24,717 - INFO - allennlp.common.params - registered_model_name = next_token_lm\n",
      "2022-03-29 15:18:24,722 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:24,724 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:24,729 - INFO - allennlp.common.params - display_name = GPT2-based Next Token Language Model\n",
      "2022-03-29 15:18:24,731 - INFO - allennlp.common.params - task_id = language-modeling\n",
      "2022-03-29 15:18:24,736 - INFO - allennlp.common.params - model_usage.archive_file = gpt2-next-word-lm-2020.06.30.tar.gz\n",
      "2022-03-29 15:18:24,739 - INFO - allennlp.common.params - model_usage.training_config = None\n",
      "2022-03-29 15:18:24,756 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-03-29 15:18:24,763 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:24,772 - INFO - allennlp.common.params - model_details.description = This is the public 345M parameter OpenAI GPT-2 language model for generating sentences. The model embeds some input tokens, contextualizes them, then predicts the next word, computing a loss against known target. \n",
      "If `BeamSearch` is given, this model will predict a sequence of next tokens.\n",
      "2022-03-29 15:18:24,794 - INFO - allennlp.common.params - model_details.short_description = OpenAI's GPT-2 language model that generates the next token.\n",
      "2022-03-29 15:18:24,805 - INFO - allennlp.common.params - model_details.developed_by = Radford et al\n",
      "2022-03-29 15:18:24,822 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 15:18:24,835 - INFO - allennlp.common.params - model_details.date = 2020-06-30\n",
      "2022-03-29 15:18:24,847 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:24,865 - INFO - allennlp.common.params - model_details.model_type = GPT2\n",
      "2022-03-29 15:18:24,872 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Radford2019LanguageMA,\n",
      "title={Language Models are Unsupervised Multitask Learners},\n",
      "author={A. Radford and Jeffrey Wu and R. Child and David Luan and Dario Amodei and Ilya Sutskever},\n",
      "year={2019}}\n",
      "\n",
      "2022-03-29 15:18:24,875 - INFO - allennlp.common.params - model_details.paper.title = Language Models are Unsupervised Multitask Learners\n",
      "2022-03-29 15:18:24,880 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:160025533\n",
      "2022-03-29 15:18:24,894 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:24,898 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:24,902 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:24,905 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:24,907 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:18:24,913 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:24,941 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:24,952 - INFO - allennlp.common.params - metrics.model_performance_measures = Perplexity\n",
      "2022-03-29 15:18:24,953 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:24,972 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:24,979 - INFO - allennlp.common.params - evaluation_data.dataset.name = WebText corpus\n",
      "2022-03-29 15:18:24,983 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://github.com/openai/gpt-2-output-dataset\n",
      "2022-03-29 15:18:25,000 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:25,008 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:25,017 - INFO - allennlp.common.params - training_data.dataset.name = WebText corpus\n",
      "2022-03-29 15:18:25,021 - INFO - allennlp.common.params - training_data.dataset.url = https://github.com/openai/gpt-2-output-dataset\n",
      "2022-03-29 15:18:25,025 - INFO - allennlp.common.params - training_data.motivation = WebText emphasizes document quality. Only human-curated/filtered documents are scraped. Reddit outbound links which receive at least 3 karma points are taken as a proxy for human filtered webpages that are interesting.\n",
      "2022-03-29 15:18:25,030 - INFO - allennlp.common.params - training_data.preprocessing = Dragnet and [Newspaper](https://github.com/codelucas/newspaper) content extractors are used. Wikipedia articles are removed.\n",
      "2022-03-29 15:18:25,042 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 15:18:25,050 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:25,054 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:25,064 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:25,225 - INFO - allennlp.common.params - id = coref-spanbert\n",
      "2022-03-29 15:18:25,233 - INFO - allennlp.common.params - registered_model_name = coref\n",
      "2022-03-29 15:18:25,240 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:25,257 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:25,263 - INFO - allennlp.common.params - display_name = Coreference Resolution\n",
      "2022-03-29 15:18:25,265 - INFO - allennlp.common.params - task_id = coref\n",
      "2022-03-29 15:18:25,268 - INFO - allennlp.common.params - model_usage.archive_file = coref-spanbert-large-2021.03.10.tar.gz\n",
      "2022-03-29 15:18:25,271 - INFO - allennlp.common.params - model_usage.training_config = coref/coref_spanbert_large.jsonnet\n",
      "2022-03-29 15:18:25,283 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 15:18:25,289 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:25,292 - INFO - allennlp.common.params - model_details.description = The basic outline of this model is to get an embedded representation of each span in the document. These span representations are scored  and used to prune away spans that are unlikely to occur in a coreference  cluster. For the remaining spans, the model decides which antecedent span (if any) they are coreferent with. The resulting coreference links, after applying transitivity, imply a clustering of the spans in the document. The GloVe embeddings in the original paper have been substituted with SpanBERT embeddings.\n",
      "2022-03-29 15:18:25,297 - INFO - allennlp.common.params - model_details.short_description = Higher-order coref with coarse-to-fine inference (with SpanBERT embeddings).\n",
      "2022-03-29 15:18:25,300 - INFO - allennlp.common.params - model_details.developed_by = Lee et al\n",
      "2022-03-29 15:18:25,306 - INFO - allennlp.common.params - model_details.contributed_by = Zhaofeng Wu\n",
      "2022-03-29 15:18:25,322 - INFO - allennlp.common.params - model_details.date = 2020-02-27\n",
      "2022-03-29 15:18:25,331 - INFO - allennlp.common.params - model_details.version = 2\n",
      "2022-03-29 15:18:25,333 - INFO - allennlp.common.params - model_details.model_type = SpanBERT\n",
      "2022-03-29 15:18:25,336 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Lee2018HigherorderCR,\n",
      "title={Higher-order Coreference Resolution with Coarse-to-fine Inference},\n",
      "author={Kenton Lee and Luheng He and L. Zettlemoyer},\n",
      "booktitle={NAACL-HLT},\n",
      "year={2018}}\n",
      "\n",
      "2022-03-29 15:18:25,339 - INFO - allennlp.common.params - model_details.paper.title = Higher-order Coreference Resolution with Coarse-to-fine Inference\n",
      "2022-03-29 15:18:25,345 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:4891749\n",
      "2022-03-29 15:18:25,352 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:25,356 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:25,369 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:25,387 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:25,392 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:25,394 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:25,400 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:25,406 - INFO - allennlp.common.params - metrics.model_performance_measures = CoNLL coref scores and Mention Recall\n",
      "2022-03-29 15:18:25,409 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:25,411 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:25,413 - INFO - allennlp.common.params - evaluation_data.dataset.name = Ontonotes 5.0\n",
      "2022-03-29 15:18:25,418 - INFO - allennlp.common.params - evaluation_data.dataset.notes = The Coreference model was evaluated on the CoNLL 2012 dataset. Unfortunately we cannot release this data due to licensing restrictions by the LDC. To compile the data in the right format for evaluating the Coreference model, please see scripts/compile_coref_data.sh. This script requires the Ontonotes 5.0 dataset, available on the LDC website.\n",
      "2022-03-29 15:18:25,421 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = /path/to/dataset\n",
      "2022-03-29 15:18:25,423 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "2022-03-29 15:18:25,429 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:25,431 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:25,435 - INFO - allennlp.common.params - training_data.dataset.name = Ontonotes 5.0\n",
      "2022-03-29 15:18:25,439 - INFO - allennlp.common.params - training_data.dataset.notes = The Coreference model was evaluated on the CoNLL 2012 dataset. Unfortunately we cannot release this data due to licensing restrictions by the LDC. To compile the data in the right format for evaluating the Coreference model, please see scripts/compile_coref_data.sh. This script requires the Ontonotes 5.0 dataset, available on the LDC website.\n",
      "2022-03-29 15:18:25,440 - INFO - allennlp.common.params - training_data.dataset.processed_url = /path/to/dataset\n",
      "2022-03-29 15:18:25,443 - INFO - allennlp.common.params - training_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "2022-03-29 15:18:25,446 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:25,449 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:25,452 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 15:18:25,454 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:25,456 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:25,460 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:18:25,608 - INFO - allennlp.common.params - id = rc-bidaf-elmo\n",
      "2022-03-29 15:18:25,621 - INFO - allennlp.common.params - registered_model_name = bidaf\n",
      "2022-03-29 15:18:25,624 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:25,627 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:25,631 - INFO - allennlp.common.params - display_name = ELMo-BiDAF\n",
      "2022-03-29 15:18:25,634 - INFO - allennlp.common.params - task_id = rc\n",
      "2022-03-29 15:18:25,642 - INFO - allennlp.common.params - model_usage.archive_file = bidaf-elmo.2021-02-11.tar.gz\n",
      "2022-03-29 15:18:25,644 - INFO - allennlp.common.params - model_usage.training_config = rc/bidaf_elmo.jsonnet\n",
      "2022-03-29 15:18:25,647 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 15:18:25,649 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:25,651 - INFO - allennlp.common.params - model_details.description = This is an implementation of the BiDAF model with ELMo embeddings. The basic layout is pretty simple: encode words as a combination of word embeddings and a character-level encoder, pass the word representations through a bi-LSTM/GRU, use a matrix of attentions to put question information into the passage word representations (this is the only part that is at all non-standard), pass this through another few layers of bi-LSTMs/GRUs, and do a softmax over span start and span end.\n",
      "2022-03-29 15:18:25,653 - INFO - allennlp.common.params - model_details.short_description = BiDAF model with ELMo embeddings instead of GloVe.\n",
      "2022-03-29 15:18:25,656 - INFO - allennlp.common.params - model_details.developed_by = Seo et al\n",
      "2022-03-29 15:18:25,658 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 15:18:25,659 - INFO - allennlp.common.params - model_details.date = 2020-03-19\n",
      "2022-03-29 15:18:25,661 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:25,662 - INFO - allennlp.common.params - model_details.model_type = BiDAF\n",
      "2022-03-29 15:18:25,665 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Seo2017BidirectionalAF,\n",
      "title={Bidirectional Attention Flow for Machine Comprehension},\n",
      "author={Minjoon Seo and Aniruddha Kembhavi and Ali Farhadi and Hannaneh Hajishirzi},\n",
      "journal={ArXiv},\n",
      "year={2017},\n",
      "volume={abs/1611.01603}}\n",
      "\n",
      "2022-03-29 15:18:25,667 - INFO - allennlp.common.params - model_details.paper.title = Bidirectional Attention Flow for Machine Comprehension\n",
      "2022-03-29 15:18:25,668 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:8535316\n",
      "2022-03-29 15:18:25,670 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:25,673 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:25,675 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:25,677 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:25,680 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:25,683 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:25,685 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:25,688 - INFO - allennlp.common.params - metrics.model_performance_measures = Start, end and overall span accuracy, Exact Match, F1 score\n",
      "2022-03-29 15:18:25,690 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:25,691 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:25,694 - INFO - allennlp.common.params - evaluation_data.dataset.name = SQuAD dev set\n",
      "2022-03-29 15:18:25,698 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/squad/squad-dev-v1.1.json\n",
      "2022-03-29 15:18:25,702 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://rajpurkar.github.io/SQuAD-explorer/explore/1.1/dev/\n",
      "2022-03-29 15:18:25,704 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:25,706 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:25,710 - INFO - allennlp.common.params - training_data.dataset.name = SQuAD training set\n",
      "2022-03-29 15:18:25,711 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/squad/squad-train-v1.1.json\n",
      "2022-03-29 15:18:25,713 - INFO - allennlp.common.params - training_data.dataset.url = https://rajpurkar.github.io/SQuAD-explorer/explore/1.1/dev/\n",
      "2022-03-29 15:18:25,715 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:25,717 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:25,719 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = On the validation set:\n",
      "Start accuracy: 66%\n",
      "End accuracy: 69%\n",
      "Overall span accuracy: 57%\n",
      "Exact match: 71%\n",
      "F1: 80%\n",
      "2022-03-29 15:18:25,721 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:25,724 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:25,727 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = This model is based on ELMo. ELMo is not deterministic, meaning that you will see slight differences every time you run it. Also, ELMo likes to be warmed up, so we recommend processing dummy input before processing real workloads with it.\n",
      "2022-03-29 15:18:25,890 - INFO - allennlp.common.params - id = tagging-elmo-crf-tagger\n",
      "2022-03-29 15:18:25,898 - INFO - allennlp.common.params - registered_model_name = crf_tagger\n",
      "2022-03-29 15:18:25,906 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:25,910 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:25,920 - INFO - allennlp.common.params - display_name = ELMo-based Named Entity Recognition\n",
      "2022-03-29 15:18:25,921 - INFO - allennlp.common.params - task_id = ner\n",
      "2022-03-29 15:18:25,929 - INFO - allennlp.common.params - model_usage.archive_file = ner-elmo.2021-02-12.tar.gz\n",
      "2022-03-29 15:18:25,944 - INFO - allennlp.common.params - model_usage.training_config = tagging/ner_elmo.jsonnet\n",
      "2022-03-29 15:18:25,973 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 15:18:25,977 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:25,980 - INFO - allennlp.common.params - model_details.description = This model is the baseline model described in [Semi-supervised sequence tagging with bidirectional language models](https://api.semanticscholar.org/CorpusID:7197241). It uses a Gated Recurrent Unit (GRU) character encoder as well as a GRU phrase encoder, and it starts with pretrained GloVe vectors for its token embeddings. It was trained on the CoNLL-2003 NER dataset.\n",
      "2022-03-29 15:18:25,983 - INFO - allennlp.common.params - model_details.short_description = NER tagger using a Gated Recurrent Unit (GRU) character encoder as well as a GRU phrase encoder, with GloVe embeddings.\n",
      "2022-03-29 15:18:25,986 - INFO - allennlp.common.params - model_details.developed_by = Peters et al\n",
      "2022-03-29 15:18:26,000 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 15:18:26,002 - INFO - allennlp.common.params - model_details.date = 2020-02-10\n",
      "2022-03-29 15:18:26,006 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:26,013 - INFO - allennlp.common.params - model_details.model_type = Gated Recurrent Unit (GRU)\n",
      "2022-03-29 15:18:26,017 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Peters2017SemisupervisedST,\n",
      "title={Semi-supervised sequence tagging with bidirectional language models},\n",
      "author={Matthew E. Peters and Waleed Ammar and Chandra Bhagavatula and R. Power},\n",
      "booktitle={ACL},\n",
      "year={2017}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:18:26,022 - INFO - allennlp.common.params - model_details.paper.title = Semi-supervised sequence tagging with bidirectional language models\n",
      "2022-03-29 15:18:26,031 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:7197241\n",
      "2022-03-29 15:18:26,035 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:26,037 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:26,039 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:26,041 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:26,043 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:26,046 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:26,048 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:26,053 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy and Span-based F1 metric\n",
      "2022-03-29 15:18:26,055 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:26,058 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:26,060 - INFO - allennlp.common.params - evaluation_data.dataset.name = CoNLL-2003 NER dataset\n",
      "2022-03-29 15:18:26,063 - INFO - allennlp.common.params - evaluation_data.dataset.notes = The NER model was evaluated on the CoNLL-2003 NER dataset. Unfortunately we cannot release this data due to licensing restrictions.\n",
      "2022-03-29 15:18:26,065 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = path/to/dataset\n",
      "2022-03-29 15:18:26,069 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://www.clips.uantwerpen.be/conll2003/ner/\n",
      "2022-03-29 15:18:26,072 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:26,074 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:26,080 - INFO - allennlp.common.params - training_data.dataset.name = CoNLL-2003 NER dataset\n",
      "2022-03-29 15:18:26,083 - INFO - allennlp.common.params - training_data.dataset.notes = The NER model was trained on the CoNLL-2003 NER dataset. Unfortunately we cannot release this data due to licensing restrictions.\n",
      "2022-03-29 15:18:26,087 - INFO - allennlp.common.params - training_data.dataset.processed_url = /path/to/dataset\n",
      "2022-03-29 15:18:26,091 - INFO - allennlp.common.params - training_data.dataset.url = https://www.clips.uantwerpen.be/conll2003/ner/\n",
      "2022-03-29 15:18:26,094 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:26,096 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:26,102 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = Achieves 99% accuracy and 96% F1 on the CoNLL-2003 validation set.\n",
      "2022-03-29 15:18:26,107 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:26,116 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:26,121 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = This model is based on ELMo. ELMo is not deterministic, meaning that you will see slight differences every time you run it. Also, ELMo likes to be warmed up, so we recommend processing dummy input before processing real workloads with it.\n",
      "2022-03-29 15:18:26,291 - INFO - allennlp.common.params - id = semparse-text-to-sql\n",
      "2022-03-29 15:18:26,296 - INFO - allennlp.common.params - registered_model_name = None\n",
      "2022-03-29 15:18:26,304 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:26,313 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:26,323 - INFO - allennlp.common.params - display_name = Text to SQL (ATIS)\n",
      "2022-03-29 15:18:26,343 - INFO - allennlp.common.params - task_id = semparse-text-to-sql\n",
      "2022-03-29 15:18:26,359 - INFO - allennlp.common.params - model_usage.archive_file = https://allennlp.s3.amazonaws.com/models/atis-parser-2020.02.10.tar.gz\n",
      "2022-03-29 15:18:26,361 - INFO - allennlp.common.params - model_usage.training_config = None\n",
      "2022-03-29 15:18:26,374 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-03-29 15:18:26,387 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:26,397 - INFO - allennlp.common.params - model_details.description = This model is an implementation of an encoder-decoder architecture with LSTMs and constrained type decoding trained on the ATIS dataset. This model is still a proof-of-concept of what you can do with semantic parsing in AllenNLP and its performance is not state-of-the-art (this naive model gets around 40% exact denotation accuracy on the contextual ATIS dataset).\n",
      "2022-03-29 15:18:26,419 - INFO - allennlp.common.params - model_details.short_description = This model is an implementation of an encoder-decoder architecture with LSTMs and constrained type decoding trained on the ATIS dataset.\n",
      "2022-03-29 15:18:26,425 - INFO - allennlp.common.params - model_details.developed_by = Dasigi et al\n",
      "2022-03-29 15:18:26,433 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 15:18:26,437 - INFO - allennlp.common.params - model_details.date = 2020-02-10\n",
      "2022-03-29 15:18:26,439 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:26,452 - INFO - allennlp.common.params - model_details.model_type = None\n",
      "2022-03-29 15:18:26,468 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Dasigi2019IterativeSF,\n",
      "title={Iterative Search for Weakly Supervised Semantic Parsing},\n",
      "author={Pradeep Dasigi and Matt Gardner and Shikhar Murty and Luke Zettlemoyer and E. Hovy},\n",
      "booktitle={NAACL-HLT},\n",
      "year={2019}}\n",
      "\n",
      "2022-03-29 15:18:26,488 - INFO - allennlp.common.params - model_details.paper.title = Iterative Search for Weakly Supervised Semantic Parsing\n",
      "2022-03-29 15:18:26,501 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:174799945\n",
      "2022-03-29 15:18:26,512 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:26,515 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:26,519 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:26,525 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:26,527 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:26,532 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:26,538 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:26,543 - INFO - allennlp.common.params - metrics.model_performance_measures = 1. `exact_match`; the percentage of the time that our best output action sequence matches the SQL query exactly.\n",
      "2. `denotation_acc`; the percentage of examples where we get the correct denotation.\n",
      "3. `valid_sql_query`; the percentage of time that decoding actually produces avalid SQL query.\n",
      "4. `action_similarity`; how similar the action sequence predicted is to the actual action sequence.\n",
      "2022-03-29 15:18:26,545 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:26,548 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:26,550 - INFO - allennlp.common.params - evaluation_data.dataset.name = ATIS\n",
      "2022-03-29 15:18:26,555 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-03-29 15:18:26,559 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://api.semanticscholar.org/CorpusID:1094063\n",
      "2022-03-29 15:18:26,561 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:26,571 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:26,573 - INFO - allennlp.common.params - training_data.dataset.name = ATIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:18:26,577 - INFO - allennlp.common.params - training_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-03-29 15:18:26,579 - INFO - allennlp.common.params - training_data.dataset.url = https://api.semanticscholar.org/CorpusID:1094063\n",
      "2022-03-29 15:18:26,581 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:26,584 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:26,593 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 15:18:26,596 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:26,601 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:26,608 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:26,786 - INFO - allennlp.common.params - id = nlvr2-vilbert\n",
      "2022-03-29 15:18:26,788 - INFO - allennlp.common.params - registered_model_name = nlvr2\n",
      "2022-03-29 15:18:26,790 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:26,790 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:26,792 - INFO - allennlp.common.params - display_name = Visual Entailment - NLVR2\n",
      "2022-03-29 15:18:26,795 - INFO - allennlp.common.params - task_id = nlvr2\n",
      "2022-03-29 15:18:26,798 - INFO - allennlp.common.params - model_usage.archive_file = vilbert-nlvr2-head-2021.06.01.tar.gz\n",
      "2022-03-29 15:18:26,801 - INFO - allennlp.common.params - model_usage.training_config = vilbert_nlvr2_pretrained.jsonnet\n",
      "2022-03-29 15:18:26,806 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp>=2.5.1 allennlp-models>=2.5.1\n",
      "2022-03-29 15:18:26,808 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:26,811 - INFO - allennlp.common.params - model_details.description = This model uses a VilBERT-based backbone with an NLVR2-specific model head. The image features are obtained using the ResNet backbone and Faster RCNN (region detection).\n",
      "2022-03-29 15:18:26,814 - INFO - allennlp.common.params - model_details.short_description = ViLBERT-based model for Visual Entailment.\n",
      "2022-03-29 15:18:26,815 - INFO - allennlp.common.params - model_details.developed_by = Lu et al\n",
      "2022-03-29 15:18:26,818 - INFO - allennlp.common.params - model_details.contributed_by = Jacob Morrison\n",
      "2022-03-29 15:18:26,823 - INFO - allennlp.common.params - model_details.date = 2021-05-27\n",
      "2022-03-29 15:18:26,826 - INFO - allennlp.common.params - model_details.version = 2\n",
      "2022-03-29 15:18:26,830 - INFO - allennlp.common.params - model_details.model_type = ViLBERT based on BERT large\n",
      "2022-03-29 15:18:26,834 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Lu2019ViLBERTPT,\n",
      "title={ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks},\n",
      "author={Jiasen Lu and Dhruv Batra and D. Parikh and Stefan Lee},\n",
      "booktitle={NeurIPS},\n",
      "year={2019}\n",
      "2022-03-29 15:18:26,837 - INFO - allennlp.common.params - model_details.paper.title = ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks\n",
      "2022-03-29 15:18:26,840 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:199453025\n",
      "2022-03-29 15:18:26,842 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:26,846 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:26,849 - INFO - allennlp.common.params - intended_use.primary_uses = This model is developed for the AllenNLP demo.\n",
      "2022-03-29 15:18:26,852 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:26,854 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:26,858 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:26,860 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:26,862 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy and F1-score\n",
      "2022-03-29 15:18:26,864 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:26,866 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:26,869 - INFO - allennlp.common.params - evaluation_data.dataset.name = Natural Language for Visual Reasoning For Real dev set\n",
      "2022-03-29 15:18:26,877 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Evaluation requires a large amount of images to be accessible locally, so we cannot provide a command you can easily copy and paste.\n",
      "2022-03-29 15:18:26,881 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://github.com/lil-lab/nlvr/tree/master/nlvr2\n",
      "2022-03-29 15:18:26,884 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:26,887 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:26,890 - INFO - allennlp.common.params - training_data.dataset.name = Natural Language for Visual Reasoning For Real train set\n",
      "2022-03-29 15:18:26,891 - INFO - allennlp.common.params - training_data.dataset.url = https://github.com/lil-lab/nlvr/tree/master/nlvr2\n",
      "2022-03-29 15:18:26,895 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:26,897 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:26,899 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = On the validation set:\n",
      "F1: 33.7%\n",
      "Accuracy: 50.8%.\n",
      "These scores do not match the performance in the 12-in-1 paper because this was trained as a standalone task, not as part of a multitask setup. Please contact us if you want to match those scores!\n",
      "2022-03-29 15:18:26,904 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:26,907 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:26,910 - INFO - allennlp.common.params - model_caveats_and_recommendations = None\n",
      "2022-03-29 15:18:27,126 - INFO - allennlp.common.params - id = rc-bidaf\n",
      "2022-03-29 15:18:27,128 - INFO - allennlp.common.params - registered_model_name = bidaf\n",
      "2022-03-29 15:18:27,131 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:27,135 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:27,139 - INFO - allennlp.common.params - display_name = BiDAF\n",
      "2022-03-29 15:18:27,141 - INFO - allennlp.common.params - task_id = rc\n",
      "2022-03-29 15:18:27,144 - INFO - allennlp.common.params - model_usage.archive_file = bidaf-model-2020.03.19.tar.gz\n",
      "2022-03-29 15:18:27,146 - INFO - allennlp.common.params - model_usage.training_config = rc/bidaf.jsonnet\n",
      "2022-03-29 15:18:27,151 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 15:18:27,153 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:27,155 - INFO - allennlp.common.params - model_details.description = This is an implementation of the BiDAF model with GloVe embeddings. The basic layout is pretty simple: encode words as a combination of word embeddings and a character-level encoder, pass the word representations through a bi-LSTM/GRU, use a matrix of attentions to put question information into the passage word representations (this is the only part that is at all non-standard), pass this through another few layers of bi-LSTMs/GRUs, and do a softmax over span start and span end.\n",
      "2022-03-29 15:18:27,157 - INFO - allennlp.common.params - model_details.short_description = BiDAF model with GloVe embeddings.\n",
      "2022-03-29 15:18:27,159 - INFO - allennlp.common.params - model_details.developed_by = Seo et al\n",
      "2022-03-29 15:18:27,162 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 15:18:27,164 - INFO - allennlp.common.params - model_details.date = 2020-03-19\n",
      "2022-03-29 15:18:27,166 - INFO - allennlp.common.params - model_details.version = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:18:27,169 - INFO - allennlp.common.params - model_details.model_type = BiDAF\n",
      "2022-03-29 15:18:27,172 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Seo2017BidirectionalAF,\n",
      "title={Bidirectional Attention Flow for Machine Comprehension},\n",
      "author={Minjoon Seo and Aniruddha Kembhavi and Ali Farhadi and Hannaneh Hajishirzi},\n",
      "journal={ArXiv},\n",
      "year={2017},\n",
      "volume={abs/1611.01603}}\n",
      "\n",
      "2022-03-29 15:18:27,182 - INFO - allennlp.common.params - model_details.paper.title = Bidirectional Attention Flow for Machine Comprehension\n",
      "2022-03-29 15:18:27,185 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:8535316\n",
      "2022-03-29 15:18:27,188 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:27,191 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:27,194 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:27,196 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:27,200 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:27,204 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:27,208 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:27,211 - INFO - allennlp.common.params - metrics.model_performance_measures = Start, end, and overall span accuracy, Exact Match, F1 score\n",
      "2022-03-29 15:18:27,213 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:27,216 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:27,219 - INFO - allennlp.common.params - evaluation_data.dataset.name = SQuAD dev set\n",
      "2022-03-29 15:18:27,223 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/squad/squad-dev-v1.1.json\n",
      "2022-03-29 15:18:27,225 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://rajpurkar.github.io/SQuAD-explorer/explore/1.1/dev/\n",
      "2022-03-29 15:18:27,227 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:27,233 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:27,252 - INFO - allennlp.common.params - training_data.dataset.name = SQuAD training set\n",
      "2022-03-29 15:18:27,253 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/squad/squad-train-v1.1.json\n",
      "2022-03-29 15:18:27,258 - INFO - allennlp.common.params - training_data.dataset.url = https://rajpurkar.github.io/SQuAD-explorer/explore/1.1/dev/\n",
      "2022-03-29 15:18:27,261 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:27,266 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:27,270 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = On the validation set:\n",
      "Start accuracy: 61%\n",
      "End accuracy: 66%\n",
      "Overall span accuracy: 52%\n",
      "Exact match: 66%\n",
      "F1: 76%\n",
      "2022-03-29 15:18:27,272 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:27,285 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:27,291 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:27,429 - INFO - allennlp.common.params - id = vqa-vilbert\n",
      "2022-03-29 15:18:27,432 - INFO - allennlp.common.params - registered_model_name = vqa_vilbert\n",
      "2022-03-29 15:18:27,436 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:27,440 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:27,442 - INFO - allennlp.common.params - display_name = ViLBERT - Visual Question Answering\n",
      "2022-03-29 15:18:27,444 - INFO - allennlp.common.params - task_id = vqa\n",
      "2022-03-29 15:18:27,449 - INFO - allennlp.common.params - model_usage.archive_file = vilbert-vqa-pretrained.2021-03-15.tar.gz\n",
      "2022-03-29 15:18:27,450 - INFO - allennlp.common.params - model_usage.training_config = vision/vilbert_vqa_pretrained.jsonnet\n",
      "2022-03-29 15:18:27,452 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 15:18:27,454 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:27,456 - INFO - allennlp.common.params - model_details.description = ViLBERT (short for Vision-and-Language BERT), is a model for learning task-agnostic joint representations of image content and natural language.\n",
      "2022-03-29 15:18:27,459 - INFO - allennlp.common.params - model_details.short_description = ViLBERT (short for Vision-and-Language BERT), is a model for learning task-agnostic joint representations of image content and natural language.\n",
      "2022-03-29 15:18:27,461 - INFO - allennlp.common.params - model_details.developed_by = Lu et al\n",
      "2022-03-29 15:18:27,463 - INFO - allennlp.common.params - model_details.contributed_by = Dirk Groeneveld\n",
      "2022-03-29 15:18:27,465 - INFO - allennlp.common.params - model_details.date = 2021-03-15\n",
      "2022-03-29 15:18:27,466 - INFO - allennlp.common.params - model_details.version = 2\n",
      "2022-03-29 15:18:27,469 - INFO - allennlp.common.params - model_details.model_type = ViLBERT based on BERT large\n",
      "2022-03-29 15:18:27,471 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Lu2019ViLBERTPT,\n",
      "title={ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks},\n",
      "author={Jiasen Lu and Dhruv Batra and D. Parikh and Stefan Lee},\n",
      "booktitle={NeurIPS},\n",
      "year={2019}\n",
      "}\n",
      "2022-03-29 15:18:27,473 - INFO - allennlp.common.params - model_details.paper.title = ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks\n",
      "2022-03-29 15:18:27,475 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:199453025\n",
      "2022-03-29 15:18:27,478 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:27,480 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:27,482 - INFO - allennlp.common.params - intended_use.primary_uses = This model is developed for the AllenNLP demo.\n",
      "2022-03-29 15:18:27,485 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:27,487 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:27,490 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:27,495 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:27,498 - INFO - allennlp.common.params - metrics.model_performance_measures = F1-metric and VQA score\n",
      "2022-03-29 15:18:27,500 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:27,501 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:27,504 - INFO - allennlp.common.params - evaluation_data.dataset.name = VQA dataset\n",
      "2022-03-29 15:18:27,507 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Evaluation requires a large amount of images to be accessible locally, so we cannot provide a command you can easily copy and paste. The first time you run it, you will get an error message that tells you how to get the rest of the data.\n",
      "2022-03-29 15:18:27,509 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = balanced_real_val\n",
      "2022-03-29 15:18:27,511 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://visualqa.org/\n",
      "2022-03-29 15:18:27,513 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:27,517 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:27,522 - INFO - allennlp.common.params - training_data.dataset.name = VQA dataset\n",
      "2022-03-29 15:18:27,525 - INFO - allennlp.common.params - training_data.dataset.notes = Training requires a large amount of images to be accessible locally, so we cannot provide a command you can easily copy and paste. The first time you run it, you will get an error message that tells you how to get the rest of the data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:18:27,526 - INFO - allennlp.common.params - training_data.dataset.processed_url = balanced_real_train\n",
      "2022-03-29 15:18:27,529 - INFO - allennlp.common.params - training_data.dataset.url = https://visualqa.org/\n",
      "2022-03-29 15:18:27,531 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:27,534 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:27,536 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = On the validation set:\n",
      "F1: 40%\n",
      "VQA: 54%.\n",
      "These scores do not match the performance in the VilBERT paper. Please contact us if you want to match those scores!\n",
      "2022-03-29 15:18:27,538 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:27,541 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:27,544 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:27,819 - INFO - allennlp.common.params - id = semparse-wikitables\n",
      "2022-03-29 15:18:27,821 - INFO - allennlp.common.params - registered_model_name = None\n",
      "2022-03-29 15:18:27,824 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:27,828 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:27,831 - INFO - allennlp.common.params - display_name = WikiTables Semantic Parsing\n",
      "2022-03-29 15:18:27,833 - INFO - allennlp.common.params - task_id = semparse-tabular\n",
      "2022-03-29 15:18:27,841 - INFO - allennlp.common.params - model_usage.archive_file = wikitables-model-2020.02.10.tar.gz\n",
      "2022-03-29 15:18:27,843 - INFO - allennlp.common.params - model_usage.training_config = None\n",
      "2022-03-29 15:18:27,846 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-03-29 15:18:27,848 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:27,859 - INFO - allennlp.common.params - model_details.description = The model is a semantic parser trained on WikiTableQuestions.\n",
      "2022-03-29 15:18:27,861 - INFO - allennlp.common.params - model_details.short_description = The model is a semantic parser trained on WikiTableQuestions.\n",
      "2022-03-29 15:18:27,964 - INFO - allennlp.common.params - model_details.developed_by = Dasigi et al\n",
      "2022-03-29 15:18:27,974 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 15:18:27,990 - INFO - allennlp.common.params - model_details.date = 2020-02-10\n",
      "2022-03-29 15:18:27,992 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:27,994 - INFO - allennlp.common.params - model_details.model_type = None\n",
      "2022-03-29 15:18:27,996 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Dasigi2019IterativeSF,\n",
      "title={Iterative Search for Weakly Supervised Semantic Parsing},\n",
      "author={Pradeep Dasigi and Matt Gardner and Shikhar Murty and Luke Zettlemoyer and E. Hovy},\n",
      "booktitle={NAACL-HLT},\n",
      "year={2019}}\n",
      "\n",
      "2022-03-29 15:18:27,999 - INFO - allennlp.common.params - model_details.paper.title = Iterative Search for Weakly Supervised Semantic Parsing\n",
      "2022-03-29 15:18:28,002 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:174799945\n",
      "2022-03-29 15:18:28,004 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:28,006 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:28,015 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:28,022 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:28,025 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:28,034 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:28,046 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:28,062 - INFO - allennlp.common.params - metrics.model_performance_measures = 1. `lf_retrieval_acc`; the percentage of the time that our best output action sequence is in the set of action sequences provided by offline search.\n",
      "2. `denotation_acc`; the percentage of examples where we get the correct denotation.\n",
      "3. `lf_percent`; the percentage of time that decoding actually produces a finished logical form\n",
      "2022-03-29 15:18:28,065 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:28,067 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:28,071 - INFO - allennlp.common.params - evaluation_data.dataset.name = WikiTableQuestions\n",
      "2022-03-29 15:18:28,074 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-03-29 15:18:28,079 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://ppasupat.github.io/WikiTableQuestions/\n",
      "2022-03-29 15:18:28,082 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:28,088 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:28,096 - INFO - allennlp.common.params - training_data.dataset.name = WikiTableQuestions\n",
      "2022-03-29 15:18:28,101 - INFO - allennlp.common.params - training_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-03-29 15:18:28,103 - INFO - allennlp.common.params - training_data.dataset.url = https://ppasupat.github.io/WikiTableQuestions/\n",
      "2022-03-29 15:18:28,105 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:28,107 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:28,122 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 15:18:28,132 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:28,134 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:28,136 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:28,419 - INFO - allennlp.common.params - id = generation-bart\n",
      "2022-03-29 15:18:28,424 - INFO - allennlp.common.params - registered_model_name = bart\n",
      "2022-03-29 15:18:28,431 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:28,435 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:28,441 - INFO - allennlp.common.params - display_name = BART\n",
      "2022-03-29 15:18:28,449 - INFO - allennlp.common.params - task_id = None\n",
      "2022-03-29 15:18:28,457 - INFO - allennlp.common.params - model_usage.archive_file = bart-2020.07.25.tar.gz\n",
      "2022-03-29 15:18:28,460 - INFO - allennlp.common.params - model_usage.training_config = generation/bart_cnn_dm.jsonnet\n",
      "2022-03-29 15:18:28,465 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-03-29 15:18:28,466 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:28,469 - INFO - allennlp.common.params - model_details.description = The BART model here uses a language modeling head, and therefore can be used for generation. The BART encoder, implemented as a `Seq2SeqEncoder`, which assumes it operates on already embedded inputs.  This means that we remove the token and position embeddings from BART in this module.  For the typical use case of using BART to encode inputs to your model (where we include the token and position embeddings from BART), you should use `PretrainedTransformerEmbedder(bart_model_name, sub_module=\"encoder\")` instead of this.\n",
      "2022-03-29 15:18:28,470 - INFO - allennlp.common.params - model_details.short_description = BART with a language model head for generation.\n",
      "2022-03-29 15:18:28,474 - INFO - allennlp.common.params - model_details.developed_by = Lewis et al\n",
      "2022-03-29 15:18:28,476 - INFO - allennlp.common.params - model_details.contributed_by = Dirk Groeneveld\n",
      "2022-03-29 15:18:28,479 - INFO - allennlp.common.params - model_details.date = 2020-07-25\n",
      "2022-03-29 15:18:28,481 - INFO - allennlp.common.params - model_details.version = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:18:28,485 - INFO - allennlp.common.params - model_details.model_type = BART\n",
      "2022-03-29 15:18:28,501 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Lewis2020BARTDS,\n",
      "title={BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension},\n",
      "author={M. Lewis and Yinhan Liu and Naman Goyal and Marjan Ghazvininejad and A. Mohamed and Omer Levy and Ves Stoyanov and L. Zettlemoyer},\n",
      "booktitle={ACL},\n",
      "year={2020}}\n",
      "\n",
      "2022-03-29 15:18:28,504 - INFO - allennlp.common.params - model_details.paper.title = BART: Denosing Sequence-to-Sequence Pre-training for Natural Language Generation,Translation, and Comprehension\n",
      "2022-03-29 15:18:28,510 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:204960716\n",
      "2022-03-29 15:18:28,513 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:28,514 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:28,518 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:28,522 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:28,524 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:28,527 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:28,529 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:28,532 - INFO - allennlp.common.params - metrics.model_performance_measures = ROUGE and BLEU\n",
      "2022-03-29 15:18:28,534 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:28,536 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:28,539 - INFO - allennlp.common.params - evaluation_data.dataset.name = CNN/DailyMail\n",
      "2022-03-29 15:18:28,547 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-03-29 15:18:28,557 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://github.com/abisee/cnn-dailymail\n",
      "2022-03-29 15:18:28,561 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:28,567 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:28,571 - INFO - allennlp.common.params - training_data.dataset.name = CNN/DailyMail\n",
      "2022-03-29 15:18:28,574 - INFO - allennlp.common.params - training_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-03-29 15:18:28,579 - INFO - allennlp.common.params - training_data.dataset.url = https://github.com/abisee/cnn-dailymail\n",
      "2022-03-29 15:18:28,595 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:28,599 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:28,602 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 15:18:28,610 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:28,622 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:28,625 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:28,732 - INFO - allennlp.common.params - id = tagging-fine-grained-transformer-crf-tagger\n",
      "2022-03-29 15:18:28,734 - INFO - allennlp.common.params - registered_model_name = crf_tagger\n",
      "2022-03-29 15:18:28,735 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:28,739 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:28,748 - INFO - allennlp.common.params - display_name = Fine Grained Named Entity Recognition with Transformer\n",
      "2022-03-29 15:18:28,751 - INFO - allennlp.common.params - task_id = ner\n",
      "2022-03-29 15:18:28,756 - INFO - allennlp.common.params - model_usage.archive_file = fgner-transformer.2021-02-11.tar.gz\n",
      "2022-03-29 15:18:28,760 - INFO - allennlp.common.params - model_usage.training_config = tagging/fgner_transformer.jsonnet\n",
      "2022-03-29 15:18:28,768 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 15:18:28,769 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:28,773 - INFO - allennlp.common.params - model_details.description = Fine-grained NER model\n",
      "2022-03-29 15:18:28,777 - INFO - allennlp.common.params - model_details.short_description = Fine-grained NER model\n",
      "2022-03-29 15:18:28,790 - INFO - allennlp.common.params - model_details.developed_by = None\n",
      "2022-03-29 15:18:28,794 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 15:18:28,796 - INFO - allennlp.common.params - model_details.date = 2020-07-14\n",
      "2022-03-29 15:18:28,799 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:28,802 - INFO - allennlp.common.params - model_details.model_type = Transformer\n",
      "2022-03-29 15:18:28,803 - INFO - allennlp.common.params - model_details.paper = None\n",
      "2022-03-29 15:18:28,809 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:28,814 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:28,820 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:28,827 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:28,835 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:28,839 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:28,842 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:28,848 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy and Span-based F1 metric\n",
      "2022-03-29 15:18:28,853 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:28,858 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:28,919 - INFO - allennlp.common.params - evaluation_data.dataset.name = Ontonotes 5.0\n",
      "2022-03-29 15:18:28,922 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Unfortunately we cannot release this data due to licensing restrictions.\n",
      "2022-03-29 15:18:28,924 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "2022-03-29 15:18:28,930 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:28,933 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:28,941 - INFO - allennlp.common.params - training_data.dataset.name = Ontonotes 5.0\n",
      "2022-03-29 15:18:28,948 - INFO - allennlp.common.params - training_data.dataset.notes = Unfortunately we cannot release this data due to licensing restrictions.\n",
      "2022-03-29 15:18:28,950 - INFO - allennlp.common.params - training_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "2022-03-29 15:18:28,951 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:28,954 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:28,958 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = On the validation set:\n",
      "Accuracy: 98%\n",
      "F1: 88%\n",
      "2022-03-29 15:18:28,960 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:28,966 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:28,971 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:29,123 - INFO - allennlp.common.params - id = ve-vilbert\n",
      "2022-03-29 15:18:29,124 - INFO - allennlp.common.params - registered_model_name = ve_vilbert\n",
      "2022-03-29 15:18:29,125 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:29,128 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:29,129 - INFO - allennlp.common.params - display_name = Visual Entailment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:18:29,131 - INFO - allennlp.common.params - task_id = ve\n",
      "2022-03-29 15:18:29,133 - INFO - allennlp.common.params - model_usage.archive_file = visual-entailment-torchvision-2021.03.04.tar.gz\n",
      "2022-03-29 15:18:29,135 - INFO - allennlp.common.params - model_usage.training_config = vilbert_ve_pretrained.jsonnet\n",
      "2022-03-29 15:18:29,137 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-03-29 15:18:29,139 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:29,142 - INFO - allennlp.common.params - model_details.description = This model is based on the ViLBERT architecture. The image features are obtained using the ResNet backbone and Faster RCNN (region detection).\n",
      "2022-03-29 15:18:29,150 - INFO - allennlp.common.params - model_details.short_description = ViLBERT-based model for Visual Entailment.\n",
      "2022-03-29 15:18:29,156 - INFO - allennlp.common.params - model_details.developed_by = Lu et al\n",
      "2022-03-29 15:18:29,157 - INFO - allennlp.common.params - model_details.contributed_by = Akshita Bhagia\n",
      "2022-03-29 15:18:29,161 - INFO - allennlp.common.params - model_details.date = 2021-03-04\n",
      "2022-03-29 15:18:29,164 - INFO - allennlp.common.params - model_details.version = 2\n",
      "2022-03-29 15:18:29,165 - INFO - allennlp.common.params - model_details.model_type = ViLBERT based on BERT large\n",
      "2022-03-29 15:18:29,168 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Lu2019ViLBERTPT,\n",
      "title={ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks},\n",
      "author={Jiasen Lu and Dhruv Batra and D. Parikh and Stefan Lee},\n",
      "booktitle={NeurIPS},\n",
      "year={2019}\n",
      "2022-03-29 15:18:29,172 - INFO - allennlp.common.params - model_details.paper.title = ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks\n",
      "2022-03-29 15:18:29,174 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:199453025\n",
      "2022-03-29 15:18:29,184 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:29,191 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:29,194 - INFO - allennlp.common.params - intended_use.primary_uses = This model is developed for the AllenNLP demo.\n",
      "2022-03-29 15:18:29,196 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:29,198 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:29,200 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:29,202 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:29,204 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy and F1-score\n",
      "2022-03-29 15:18:29,207 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:29,218 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:29,225 - INFO - allennlp.common.params - evaluation_data.dataset.name = Stanford Natural Language Inference - Visual Entailment(SNLI-VE) dev set\n",
      "2022-03-29 15:18:29,229 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Evaluation requires a large amount of images to be accessible locally, so we cannot provide a command you can easily copy and paste.\n",
      "2022-03-29 15:18:29,231 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://github.com/necla-ml/SNLI-VE\n",
      "2022-03-29 15:18:29,233 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:29,240 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:29,260 - INFO - allennlp.common.params - training_data.dataset.name = Stanford Natural Language Inference - Visual Entailment(SNLI-VE) train set\n",
      "2022-03-29 15:18:29,264 - INFO - allennlp.common.params - training_data.dataset.url = https://github.com/necla-ml/SNLI-VE\n",
      "2022-03-29 15:18:29,266 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:29,268 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:29,271 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 15:18:29,273 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:29,275 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:29,286 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = This model is trained on the original SNLI-VE dataset. [Subsequent work](https://api.semanticscholar.org/CorpusID:215415945) has found that an estimated 31% of `neutral` labels in the dataset are incorrect. The `e-SNLI-VE-2.0` dataset contains the re-annotated validation and test sets.\n",
      "2022-03-29 15:18:29,417 - INFO - allennlp.common.params - id = pair-classification-esim\n",
      "2022-03-29 15:18:29,418 - INFO - allennlp.common.params - registered_model_name = esim\n",
      "2022-03-29 15:18:29,421 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:29,422 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:29,423 - INFO - allennlp.common.params - display_name = Enhanced LSTM for Natural Language Inference\n",
      "2022-03-29 15:18:29,428 - INFO - allennlp.common.params - task_id = textual_entailment\n",
      "2022-03-29 15:18:29,439 - INFO - allennlp.common.params - model_usage.archive_file = esim-elmo-2020.11.11.tar.gz\n",
      "2022-03-29 15:18:29,445 - INFO - allennlp.common.params - model_usage.training_config = esim.jsonnet\n",
      "2022-03-29 15:18:29,452 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-03-29 15:18:29,459 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:29,466 - INFO - allennlp.common.params - model_details.description = This `Model` implements the ESIM model, which is a sequential neural inference model based on chain LSTMs.\n",
      "2022-03-29 15:18:29,472 - INFO - allennlp.common.params - model_details.short_description = Enhanced LSTM trained on SNLI.\n",
      "2022-03-29 15:18:29,479 - INFO - allennlp.common.params - model_details.developed_by = Chen et al\n",
      "2022-03-29 15:18:29,481 - INFO - allennlp.common.params - model_details.contributed_by = Dirk Groeneveld\n",
      "2022-03-29 15:18:29,488 - INFO - allennlp.common.params - model_details.date = 2020-04-09\n",
      "2022-03-29 15:18:29,499 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:29,501 - INFO - allennlp.common.params - model_details.model_type = LSTM\n",
      "2022-03-29 15:18:29,504 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Chen2017EnhancedLF,\n",
      "title={Enhanced LSTM for Natural Language Inference},\n",
      "author={Qian Chen and Xiao-Dan Zhu and Z. Ling and Si Wei and Hui Jiang and Diana Inkpen},\n",
      "booktitle={ACL},\n",
      "year={2017}}\n",
      "\n",
      "2022-03-29 15:18:29,506 - INFO - allennlp.common.params - model_details.paper.title = Enhanced LSTM for Natural Language Inference\n",
      "2022-03-29 15:18:29,508 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:34032948\n",
      "2022-03-29 15:18:29,518 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:29,527 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:29,533 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:29,540 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:29,546 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:29,553 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:29,561 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:29,571 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy\n",
      "2022-03-29 15:18:29,575 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:29,583 - INFO - allennlp.common.params - metrics.variation_approaches = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:18:29,588 - INFO - allennlp.common.params - evaluation_data.dataset.name = Stanford Natural Language Inference (SNLI) dev set\n",
      "2022-03-29 15:18:29,590 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_test.jsonl\n",
      "2022-03-29 15:18:29,591 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "2022-03-29 15:18:29,592 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:29,593 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:29,597 - INFO - allennlp.common.params - training_data.dataset.name = Stanford Natural Language Inference (SNLI) train set\n",
      "2022-03-29 15:18:29,598 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_train.jsonl\n",
      "2022-03-29 15:18:29,598 - INFO - allennlp.common.params - training_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "2022-03-29 15:18:29,599 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:29,600 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:29,604 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 15:18:29,605 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:29,607 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:29,608 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:29,725 - INFO - allennlp.common.params - id = pair-classification-adversarial-binary-gender-bias-mitigated-roberta-snli\n",
      "2022-03-29 15:18:29,726 - INFO - allennlp.common.params - registered_model_name = adversarial_bias_mitigator\n",
      "2022-03-29 15:18:29,732 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:29,737 - INFO - allennlp.common.params - registered_predictor_name = textual_entailment\n",
      "2022-03-29 15:18:29,739 - INFO - allennlp.common.params - display_name = Adversarial Binary Gender Bias-Mitigated RoBERTa SNLI\n",
      "2022-03-29 15:18:29,741 - INFO - allennlp.common.params - task_id = textual_entailment\n",
      "2022-03-29 15:18:29,752 - INFO - allennlp.common.params - model_usage.archive_file = adversarial-binary-gender-bias-mitigated-snli-roberta.2021-06-17.tar.gz\n",
      "2022-03-29 15:18:29,759 - INFO - allennlp.common.params - model_usage.training_config = pair_classification/adversarial_binary_gender_bias_mitigated_snli_roberta.jsonnet\n",
      "2022-03-29 15:18:29,764 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp allennlp-models\n",
      "2022-03-29 15:18:29,766 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:29,775 - INFO - allennlp.common.params - model_details.description = This `Model` implements a basic text classifier and feedforward regression adversary with an adversarial bias mitigator wrapper. The text is embedded into a text field using a RoBERTa-large model. The resulting sequence is pooled using a cls_pooler `Seq2VecEncoder` and then passed to a linear classification layer, which projects into the label space. Subsequently, a `FeedForwardRegressionAdversary` attempts to recover the coefficient of the static text embedding in the binary gender bias subspace. While the adversary's parameter updates are computed normally, the predictor's parameters are updated such that the predictor will not aid the adversary and will make it more difficult for the adversary to recover protected variables.\n",
      "2022-03-29 15:18:29,778 - INFO - allennlp.common.params - model_details.short_description = RoBERTa finetuned on SNLI with adversarial binary gender bias mitigation.\n",
      "2022-03-29 15:18:29,780 - INFO - allennlp.common.params - model_details.developed_by = Zhang at al\n",
      "2022-03-29 15:18:29,782 - INFO - allennlp.common.params - model_details.contributed_by = Arjun Subramonian\n",
      "2022-03-29 15:18:29,786 - INFO - allennlp.common.params - model_details.date = 2021-06-17\n",
      "2022-03-29 15:18:29,793 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:29,798 - INFO - allennlp.common.params - model_details.model_type = RoBERTa\n",
      "2022-03-29 15:18:29,804 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Zhang2018MitigatingUB,\n",
      "title={Mitigating Unwanted Biases with Adversarial Learning},\n",
      "author={B. H. Zhang and B. Lemoine and Margaret Mitchell},\n",
      "journal={Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society},\n",
      "year={2018}\n",
      "}\n",
      "2022-03-29 15:18:29,810 - INFO - allennlp.common.params - model_details.paper.title = Mitigating Unwanted Biases with Adversarial Learning\n",
      "2022-03-29 15:18:29,813 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:9424845\n",
      "2022-03-29 15:18:29,815 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:29,818 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:29,824 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:29,827 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:29,830 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:29,834 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:29,838 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:29,843 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy, Net Neutral, Fraction Neutral, Threshold:tau\n",
      "2022-03-29 15:18:29,846 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:29,848 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:29,853 - INFO - allennlp.common.params - evaluation_data.dataset.name = On Measuring and Mitigating Biased Gender-Occupation Inferences SNLI Dataset\n",
      "2022-03-29 15:18:29,855 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://storage.googleapis.com/allennlp-public-models/binary-gender-bias-mitigated-snli-dataset.jsonl\n",
      "2022-03-29 15:18:29,860 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://github.com/sunipa/On-Measuring-and-Mitigating-Biased-Inferences-of-Word-Embeddings\n",
      "2022-03-29 15:18:29,867 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:29,875 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:29,886 - INFO - allennlp.common.params - training_data.dataset.name = Stanford Natural Language Inference (SNLI) train set\n",
      "2022-03-29 15:18:29,890 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_train.jsonl\n",
      "2022-03-29 15:18:29,894 - INFO - allennlp.common.params - training_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "2022-03-29 15:18:29,896 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:29,900 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:29,904 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = Net Neutral: 0.613096454815352, Fraction Neutral: 0.6704967487937075, Threshold:0.5: 0.6637061892722586, Threshold:0.7: 0.49490217463150243\n",
      "2022-03-29 15:18:29,908 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:29,919 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = Adversarial binary gender bias mitigation has been applied to this model. Nonetheless, the model will contain residual biases and bias mitigation does not guarantee entirely bias-free inferences.\n",
      "2022-03-29 15:18:29,924 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:30,064 - INFO - allennlp.common.params - id = nlvr2-vilbert\n",
      "2022-03-29 15:18:30,065 - INFO - allennlp.common.params - registered_model_name = nlvr2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:18:30,070 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:30,089 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:30,094 - INFO - allennlp.common.params - display_name = Visual Entailment - NLVR2\n",
      "2022-03-29 15:18:30,113 - INFO - allennlp.common.params - task_id = nlvr2\n",
      "2022-03-29 15:18:30,119 - INFO - allennlp.common.params - model_usage.archive_file = vilbert-nlvr2-2021.06.01.tar.gz\n",
      "2022-03-29 15:18:30,129 - INFO - allennlp.common.params - model_usage.training_config = vilbert_nlvr2_pretrained.jsonnet\n",
      "2022-03-29 15:18:30,136 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp>=2.5.1 allennlp-models>=2.5.1\n",
      "2022-03-29 15:18:30,145 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:30,163 - INFO - allennlp.common.params - model_details.description = This model is based on the ViLBERT multitask architecture. The image features are obtained using the ResNet backbone and Faster RCNN (region detection).\n",
      "2022-03-29 15:18:30,170 - INFO - allennlp.common.params - model_details.short_description = ViLBERT-based model for Visual Entailment.\n",
      "2022-03-29 15:18:30,195 - INFO - allennlp.common.params - model_details.developed_by = Lu et al\n",
      "2022-03-29 15:18:30,196 - INFO - allennlp.common.params - model_details.contributed_by = Jacob Morrison\n",
      "2022-03-29 15:18:30,217 - INFO - allennlp.common.params - model_details.date = 2021-05-27\n",
      "2022-03-29 15:18:30,218 - INFO - allennlp.common.params - model_details.version = 2\n",
      "2022-03-29 15:18:30,220 - INFO - allennlp.common.params - model_details.model_type = ViLBERT based on BERT large\n",
      "2022-03-29 15:18:30,222 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Lu2019ViLBERTPT,\n",
      "title={ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks},\n",
      "author={Jiasen Lu and Dhruv Batra and D. Parikh and Stefan Lee},\n",
      "booktitle={NeurIPS},\n",
      "year={2019}\n",
      "2022-03-29 15:18:30,225 - INFO - allennlp.common.params - model_details.paper.title = ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks\n",
      "2022-03-29 15:18:30,229 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:199453025\n",
      "2022-03-29 15:18:30,230 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:30,232 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:30,235 - INFO - allennlp.common.params - intended_use.primary_uses = This model is developed for the AllenNLP demo.\n",
      "2022-03-29 15:18:30,237 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:30,242 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:30,246 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:30,248 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:30,251 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy and F1-score\n",
      "2022-03-29 15:18:30,253 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:30,254 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:30,256 - INFO - allennlp.common.params - evaluation_data.dataset.name = Natural Language for Visual Reasoning For Real dev set\n",
      "2022-03-29 15:18:30,258 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Evaluation requires a large amount of images to be accessible locally, so we cannot provide a command you can easily copy and paste.\n",
      "2022-03-29 15:18:30,260 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://github.com/lil-lab/nlvr/tree/master/nlvr2\n",
      "2022-03-29 15:18:30,262 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:30,265 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:30,344 - INFO - allennlp.common.params - training_data.dataset.name = Natural Language for Visual Reasoning For Real train set\n",
      "2022-03-29 15:18:30,349 - INFO - allennlp.common.params - training_data.dataset.url = https://github.com/lil-lab/nlvr/tree/master/nlvr2\n",
      "2022-03-29 15:18:30,352 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:30,362 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:30,367 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = On the validation set:\n",
      "F1: 33.7%\n",
      "Accuracy: 50.8%.\n",
      "These scores do not match the performance in the 12-in-1 paper because this was trained as a standalone task, not as part of a multitask setup. Please contact us if you want to match those scores!\n",
      "2022-03-29 15:18:30,369 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:30,371 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:30,385 - INFO - allennlp.common.params - model_caveats_and_recommendations = None\n",
      "2022-03-29 15:18:30,560 - INFO - allennlp.common.params - id = rc-naqanet\n",
      "2022-03-29 15:18:30,561 - INFO - allennlp.common.params - registered_model_name = naqanet\n",
      "2022-03-29 15:18:30,561 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:30,563 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:30,586 - INFO - allennlp.common.params - display_name = Numerically Augmented QA Net\n",
      "2022-03-29 15:18:30,588 - INFO - allennlp.common.params - task_id = rc\n",
      "2022-03-29 15:18:30,604 - INFO - allennlp.common.params - model_usage.archive_file = naqanet-2021.02.26.tar.gz\n",
      "2022-03-29 15:18:30,609 - INFO - allennlp.common.params - model_usage.training_config = rc/naqanet.jsonnet\n",
      "2022-03-29 15:18:30,625 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 15:18:30,633 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:30,636 - INFO - allennlp.common.params - model_details.description = An augmented version of QANet model with some rudimentary numerical reasoning abilities. The main idea here is that instead of just predicting a passage span after doing all of the QANet modeling stuff, we add several different 'answer abilities': predicting a span from the question, predicting a count, or predicting an arithmetic expression.  Near the end of the QANet model, we have a variable that predicts what kind of answer type we need, and each branch has separate modeling logic to predict that answer type.  We then marginalize over all possible ways of getting to the right answer through each of these answer types.\n",
      "2022-03-29 15:18:30,648 - INFO - allennlp.common.params - model_details.short_description = An augmented version of QANet that adds rudimentary numerical reasoning ability, trained on DROP (Dua et al., 2019), as published in the original DROP paper.\n",
      "2022-03-29 15:18:30,652 - INFO - allennlp.common.params - model_details.developed_by = Dua et al\n",
      "2022-03-29 15:18:30,657 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 15:18:30,660 - INFO - allennlp.common.params - model_details.date = 2020-02-19\n",
      "2022-03-29 15:18:30,663 - INFO - allennlp.common.params - model_details.version = 2\n",
      "2022-03-29 15:18:30,677 - INFO - allennlp.common.params - model_details.model_type = QANet\n",
      "2022-03-29 15:18:30,680 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Dua2019DROPAR,\n",
      "title={DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs},\n",
      "author={Dheeru Dua and Yizhong Wang and Pradeep Dasigi and Gabriel Stanovsky and Sameer Singh and Matt Gardner},\n",
      "booktitle={NAACL-HLT},\n",
      "year={2019}}\n",
      "\n",
      "2022-03-29 15:18:30,681 - INFO - allennlp.common.params - model_details.paper.title = DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs\n",
      "2022-03-29 15:18:30,684 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:67855846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:18:30,690 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:30,700 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:30,711 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:30,713 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:30,714 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:30,720 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:30,730 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:30,736 - INFO - allennlp.common.params - metrics.model_performance_measures = Exact Match and F1-score\n",
      "2022-03-29 15:18:30,744 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:30,747 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:30,754 - INFO - allennlp.common.params - evaluation_data.dataset.name = DROP\n",
      "2022-03-29 15:18:30,768 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/drop/drop_dataset.zip!drop_dataset/drop_dataset_dev.json\n",
      "2022-03-29 15:18:30,771 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://allennlp.org/drop\n",
      "2022-03-29 15:18:30,777 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:30,780 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:30,834 - INFO - allennlp.common.params - training_data.dataset.name = DROP\n",
      "2022-03-29 15:18:30,856 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/drop/drop_dataset.zip!drop_dataset/drop_dataset_train.json\n",
      "2022-03-29 15:18:30,899 - INFO - allennlp.common.params - training_data.dataset.url = https://allennlp.org/drop\n",
      "2022-03-29 15:18:30,906 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:30,911 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:30,915 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = Validation F1-score: 0.509, Exact Match: 0.473\n",
      "2022-03-29 15:18:30,916 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:30,918 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:30,921 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:31,076 - INFO - allennlp.common.params - id = structured-prediction-constituency-parser\n",
      "2022-03-29 15:18:31,077 - INFO - allennlp.common.params - registered_model_name = constituency_parser\n",
      "2022-03-29 15:18:31,078 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:31,085 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:31,089 - INFO - allennlp.common.params - display_name = Constituency Parser with ELMo embeddings\n",
      "2022-03-29 15:18:31,100 - INFO - allennlp.common.params - task_id = constituency-parsing\n",
      "2022-03-29 15:18:31,120 - INFO - allennlp.common.params - model_usage.archive_file = elmo-constituency-parser-2020.02.10.tar.gz\n",
      "2022-03-29 15:18:31,132 - INFO - allennlp.common.params - model_usage.training_config = structured-prediction/constituency_parser_elmo.jsonnet\n",
      "2022-03-29 15:18:31,135 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 15:18:31,148 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:31,154 - INFO - allennlp.common.params - model_details.description = This is an implementation of a minimal neural model for constituency parsing based on an independent scoring of labels and spans. This `SpanConstituencyParser` simply encodes a sequence of text with a stacked `Seq2SeqEncoder`, extracts span representations using a `SpanExtractor`, and then predicts a label for each span in the sequence. These labels are non-terminal nodes in a constituency parse tree, which we then greedily reconstruct. The model uses ELMo embeddings, which are completely character-based and improves single model performance from 92.6 F1 to 94.11 F1 on the Penn Treebank, a 20% relative error reduction.\n",
      "2022-03-29 15:18:31,163 - INFO - allennlp.common.params - model_details.short_description = Constituency parser with character-based ELMo embeddings\n",
      "2022-03-29 15:18:31,181 - INFO - allennlp.common.params - model_details.developed_by = Joshi et al\n",
      "2022-03-29 15:18:31,187 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 15:18:31,204 - INFO - allennlp.common.params - model_details.date = 2020-02-10\n",
      "2022-03-29 15:18:31,206 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:31,218 - INFO - allennlp.common.params - model_details.model_type = Seq2SeqEncoder\n",
      "2022-03-29 15:18:31,232 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Joshi2018ExtendingAP,\n",
      "title={Extending a Parser to Distant Domains Using a Few Dozen Partially Annotated Examples},\n",
      "author={V. Joshi and Matthew E. Peters and Mark Hopkins},\n",
      "booktitle={ACL},\n",
      "year={2018}}\n",
      "\n",
      "2022-03-29 15:18:31,234 - INFO - allennlp.common.params - model_details.paper.title = Extending a Parser to Distant Domains Using a Few Dozen Partially Annotated Examples\n",
      "2022-03-29 15:18:31,244 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:21712653\n",
      "2022-03-29 15:18:31,246 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:31,250 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:31,253 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:31,260 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:31,263 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:31,265 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:31,267 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:31,271 - INFO - allennlp.common.params - metrics.model_performance_measures = Precision, Recall and F1-score for parse trees (EVALB_bracketing_scorer)\n",
      "2022-03-29 15:18:31,276 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:31,279 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:31,283 - INFO - allennlp.common.params - evaluation_data.dataset.name = PTB 3.0\n",
      "2022-03-29 15:18:31,284 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-03-29 15:18:31,287 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = /path/do/dataset\n",
      "2022-03-29 15:18:31,294 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://catalog.ldc.upenn.edu/LDC99T42\n",
      "2022-03-29 15:18:31,297 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:31,299 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:31,302 - INFO - allennlp.common.params - training_data.dataset.name = PTB 3.0\n",
      "2022-03-29 15:18:31,304 - INFO - allennlp.common.params - training_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-03-29 15:18:31,305 - INFO - allennlp.common.params - training_data.dataset.processed_url = /path/do/dataset\n",
      "2022-03-29 15:18:31,311 - INFO - allennlp.common.params - training_data.dataset.url = https://catalog.ldc.upenn.edu/LDC99T42\n",
      "2022-03-29 15:18:31,313 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:31,316 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:31,318 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = 94.11 F1 score\n",
      "2022-03-29 15:18:31,321 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:18:31,326 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:31,328 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:31,498 - INFO - allennlp.common.params - id = pair-classification-decomposable-attention-elmo\n",
      "2022-03-29 15:18:31,501 - INFO - allennlp.common.params - registered_model_name = decomposable_attention\n",
      "2022-03-29 15:18:31,505 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:31,507 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:31,515 - INFO - allennlp.common.params - display_name = ELMo-based Decomposable Attention\n",
      "2022-03-29 15:18:31,522 - INFO - allennlp.common.params - task_id = textual_entailment\n",
      "2022-03-29 15:18:31,545 - INFO - allennlp.common.params - model_usage.archive_file = decomposable-attention-elmo-2020.04.09.tar.gz\n",
      "2022-03-29 15:18:31,550 - INFO - allennlp.common.params - model_usage.training_config = decomposable_attention_elmo.jsonnet\n",
      "2022-03-29 15:18:31,556 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 15:18:31,560 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:31,563 - INFO - allennlp.common.params - model_details.description = This `Model` implements the Decomposable Attention model described in [A Decomposable Attention Model for Natural Language Inference](https://api.semanticscholar.org/CorpusID:8495258) by Parikh et al., 2016, with some optional enhancements before the decomposable attention actually happens.  Parikh's original model allowed for computing an \"intra-sentence\" attention before doing the decomposable entailment step.  We generalize this to any `Seq2SeqEncoder` that can be applied to the premise and/or the hypothesis before computing entailment.\n",
      "\n",
      "The basic outline of this model is to get an embedded representation of each word in thepremise and hypothesis, align words between the two, compare the aligned phrases, and make a final entailment decision based on this aggregated comparison.  Each step in this process uses a feedforward network to modify the representation.\n",
      "\n",
      "This model uses ELMo embeddings.\n",
      "2022-03-29 15:18:31,565 - INFO - allennlp.common.params - model_details.short_description = The decomposable attention model (Parikh et al, 2017) combined with ELMo embeddings trained on SNLI.\n",
      "2022-03-29 15:18:31,568 - INFO - allennlp.common.params - model_details.developed_by = Parikh et al\n",
      "2022-03-29 15:18:31,570 - INFO - allennlp.common.params - model_details.contributed_by = Dirk Groeneveld\n",
      "2022-03-29 15:18:31,573 - INFO - allennlp.common.params - model_details.date = 2020-04-09\n",
      "2022-03-29 15:18:31,575 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:31,583 - INFO - allennlp.common.params - model_details.model_type = Seq2Seq\n",
      "2022-03-29 15:18:31,588 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Parikh2016ADA,\n",
      "title={A Decomposable Attention Model for Natural Language Inference},\n",
      "author={Ankur P. Parikh and Oscar T{\"a}ckstr{\"o}m and Dipanjan Das and Jakob Uszkoreit},\n",
      "journal={ArXiv},\n",
      "year={2016},\n",
      "volume={abs/1606.01933}}\n",
      "\n",
      "2022-03-29 15:18:31,593 - INFO - allennlp.common.params - model_details.paper.title = A Decomposable Attention Model for Natural Language Inference\n",
      "2022-03-29 15:18:31,595 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:8495258\n",
      "2022-03-29 15:18:31,598 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:31,600 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:31,605 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:31,611 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:31,613 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:31,618 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:31,622 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:31,632 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy\n",
      "2022-03-29 15:18:31,635 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:31,638 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:31,642 - INFO - allennlp.common.params - evaluation_data.dataset.name = Stanford Natural Language Inference (SNLI) dev set\n",
      "2022-03-29 15:18:31,644 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_test.jsonl\n",
      "2022-03-29 15:18:31,646 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "2022-03-29 15:18:31,651 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:31,655 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:31,661 - INFO - allennlp.common.params - training_data.dataset.name = Stanford Natural Language Inference (SNLI) train set\n",
      "2022-03-29 15:18:31,664 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_train.jsonl\n",
      "2022-03-29 15:18:31,666 - INFO - allennlp.common.params - training_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "2022-03-29 15:18:31,668 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:31,672 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:31,676 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 15:18:31,679 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:31,682 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:31,688 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:31,886 - INFO - allennlp.common.params - id = pair-classification-roberta-rte\n",
      "2022-03-29 15:18:31,888 - INFO - allennlp.common.params - registered_model_name = basic_classifier\n",
      "2022-03-29 15:18:31,890 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:31,905 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:31,911 - INFO - allennlp.common.params - display_name = RoBERTa RTE\n",
      "2022-03-29 15:18:31,913 - INFO - allennlp.common.params - task_id = pair_classification\n",
      "2022-03-29 15:18:31,920 - INFO - allennlp.common.params - model_usage.archive_file = superglue-rte-roberta.2021-04-09.tar.gz\n",
      "2022-03-29 15:18:31,925 - INFO - allennlp.common.params - model_usage.training_config = pair-classification/superglue_rte_roberta.jsonnet\n",
      "2022-03-29 15:18:31,936 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.3.1 allennlp-models==2.3.1\n",
      "2022-03-29 15:18:31,939 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:31,953 - INFO - allennlp.common.params - model_details.description = The model implements a pair classification model patterned after the proposed model in [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (Devlin et al, 2018)](https://api.semanticscholar.org/CorpusID:52967399), fine-tuned on the MultiNLI corpus. It predicts labels with a linear layer on top of word piece embeddings.\n",
      "2022-03-29 15:18:31,957 - INFO - allennlp.common.params - model_details.short_description = A pair classification model patterned after the proposed model in Devlin et al, fine-tuned on the SuperGLUE RTE corpus\n",
      "2022-03-29 15:18:31,971 - INFO - allennlp.common.params - model_details.developed_by = Devlin et al\n",
      "2022-03-29 15:18:31,988 - INFO - allennlp.common.params - model_details.contributed_by = Jacob Morrison\n",
      "2022-03-29 15:18:31,991 - INFO - allennlp.common.params - model_details.date = 2021-04-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:18:32,014 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:32,016 - INFO - allennlp.common.params - model_details.model_type = RoBERTa\n",
      "2022-03-29 15:18:32,026 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and L. Zettlemoyer and V. Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n",
      "2022-03-29 15:18:32,047 - INFO - allennlp.common.params - model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach\n",
      "2022-03-29 15:18:32,057 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "2022-03-29 15:18:32,059 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:32,068 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:32,080 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:32,082 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:32,085 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:32,099 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:32,104 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:32,113 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy\n",
      "2022-03-29 15:18:32,121 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:32,124 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:32,133 - INFO - allennlp.common.params - evaluation_data.dataset.name = SuperGLUE Recognizing Textual Entailment validation set\n",
      "2022-03-29 15:18:32,137 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://dl.fbaipublicfiles.com/glue/superglue/data/v2/RTE.zip!RTE/val.jsonl\n",
      "2022-03-29 15:18:32,140 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://super.gluebenchmark.com/tasks\n",
      "2022-03-29 15:18:32,143 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:32,145 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:32,163 - INFO - allennlp.common.params - training_data.dataset.name = SuperGLUE Recognizing Textual Entailment training set\n",
      "2022-03-29 15:18:32,167 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://dl.fbaipublicfiles.com/glue/superglue/data/v2/RTE.zip!RTE/train.jsonl\n",
      "2022-03-29 15:18:32,171 - INFO - allennlp.common.params - training_data.dataset.url = https://super.gluebenchmark.com/tasks\n",
      "2022-03-29 15:18:32,214 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:32,217 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:32,225 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = Accuracy: 89.9% on the SuperGLUE RTE validation dataset.\n",
      "2022-03-29 15:18:32,232 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:32,251 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:32,254 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:32,382 - INFO - allennlp.common.params - id = evaluate_rc-lerc\n",
      "2022-03-29 15:18:32,383 - INFO - allennlp.common.params - registered_model_name = lerc\n",
      "2022-03-29 15:18:32,385 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:32,387 - INFO - allennlp.common.params - registered_predictor_name = lerc\n",
      "2022-03-29 15:18:32,390 - INFO - allennlp.common.params - display_name = Learned Evaluation for Reading Comprehension (LERC)\n",
      "2022-03-29 15:18:32,402 - INFO - allennlp.common.params - task_id = evaluate_rc\n",
      "2022-03-29 15:18:32,407 - INFO - allennlp.common.params - model_usage.archive_file = lerc-2020-11-18.tar.gz\n",
      "2022-03-29 15:18:32,412 - INFO - allennlp.common.params - model_usage.training_config = None\n",
      "2022-03-29 15:18:32,417 - INFO - allennlp.common.params - model_usage.install_instructions = The model is available at https://github.com/anthonywchen/MOCHA.\n",
      "2022-03-29 15:18:32,436 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:32,454 - INFO - allennlp.common.params - model_details.description = LERC is a BERT model that is trained to mimic human judgement scores on candidate answers in the MOCHA dataset. LERC outputs scores that range from 1 to 5, however, to stay consistent with metrics such as BLEU and ROUGE, we normalize the output of LERC to be between 0 and 1 in this demo.\n",
      "2022-03-29 15:18:32,471 - INFO - allennlp.common.params - model_details.short_description = A BERT model that scores candidate answers from 0 to 1.\n",
      "2022-03-29 15:18:32,479 - INFO - allennlp.common.params - model_details.developed_by = Chen et al\n",
      "2022-03-29 15:18:32,482 - INFO - allennlp.common.params - model_details.contributed_by = Anthony Chen\n",
      "2022-03-29 15:18:32,494 - INFO - allennlp.common.params - model_details.date = 2021-03-10\n",
      "2022-03-29 15:18:32,497 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:32,502 - INFO - allennlp.common.params - model_details.model_type = BERT\n",
      "2022-03-29 15:18:32,518 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Chen2020MOCHAAD,\n",
      "title={MOCHA: A Dataset for Training and Evaluating Generative Reading Comprehension Metrics},\n",
      "author={Anthony Chen and Gabriel Stanovsky and S. Singh and Matt Gardner},\n",
      "booktitle={EMNLP},\n",
      "year={2020}}\n",
      "\n",
      "2022-03-29 15:18:32,522 - INFO - allennlp.common.params - model_details.paper.title = MOCHA: A Dataset for Training and Evaluating Generative Reading Comprehension Metrics\n",
      "2022-03-29 15:18:32,535 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:222208714\n",
      "2022-03-29 15:18:32,538 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:32,542 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:32,570 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:32,573 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:32,576 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:32,581 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:32,587 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:32,615 - INFO - allennlp.common.params - metrics.model_performance_measures = Pearson Correlation\n",
      "2022-03-29 15:18:32,625 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:32,633 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:32,638 - INFO - allennlp.common.params - evaluation_data.dataset.name = MOCHA\n",
      "2022-03-29 15:18:32,645 - INFO - allennlp.common.params - evaluation_data.dataset.notes = To evaluate this model follow the instructions at https://github.com/anthonywchen/MOCHA.\n",
      "2022-03-29 15:18:32,650 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = None\n",
      "2022-03-29 15:18:32,663 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://allennlp.org/mocha\n",
      "2022-03-29 15:18:32,669 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:32,672 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:32,676 - INFO - allennlp.common.params - training_data.dataset.name = MOCHA\n",
      "2022-03-29 15:18:32,678 - INFO - allennlp.common.params - training_data.dataset.notes = To train this model follow the instructions at https://github.com/anthonywchen/MOCHA.\n",
      "2022-03-29 15:18:32,680 - INFO - allennlp.common.params - training_data.dataset.processed_url = None\n",
      "2022-03-29 15:18:32,688 - INFO - allennlp.common.params - training_data.dataset.url = https://allennlp.org/mocha\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:18:32,699 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:32,703 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:32,710 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 15:18:32,728 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:32,733 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:32,747 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:32,765 - WARNING - allennlp.common.model_card - lerc is not a registered model.\n",
      "2022-03-29 15:18:32,884 - INFO - allennlp.common.params - id = structured-prediction-srl\n",
      "2022-03-29 15:18:32,884 - INFO - allennlp.common.params - registered_model_name = srl\n",
      "2022-03-29 15:18:32,885 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:32,889 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:32,897 - INFO - allennlp.common.params - display_name = Open Information Extraction\n",
      "2022-03-29 15:18:32,900 - INFO - allennlp.common.params - task_id = srl\n",
      "2022-03-29 15:18:32,905 - INFO - allennlp.common.params - model_usage.archive_file = openie-model.2020.03.26.tar.gz\n",
      "2022-03-29 15:18:32,911 - INFO - allennlp.common.params - model_usage.training_config = structured-prediction/srl.jsonnet\n",
      "2022-03-29 15:18:32,917 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 15:18:32,930 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:32,932 - INFO - allennlp.common.params - model_details.description = A reimplementation of a deep BiLSTM sequence prediction model (Stanovsky et al., 2018).\n",
      "2022-03-29 15:18:32,935 - INFO - allennlp.common.params - model_details.short_description = A reimplementation of a deep BiLSTM sequence prediction model (Stanovsky et al., 2018)\n",
      "2022-03-29 15:18:32,943 - INFO - allennlp.common.params - model_details.developed_by = Stanovsky et al\n",
      "2022-03-29 15:18:32,951 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 15:18:32,953 - INFO - allennlp.common.params - model_details.date = 2020-03-26\n",
      "2022-03-29 15:18:32,955 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:32,970 - INFO - allennlp.common.params - model_details.model_type = BiLSTM\n",
      "2022-03-29 15:18:32,981 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Stanovsky2018SupervisedOI,\n",
      "title={Supervised Open Information Extraction},\n",
      "author={Gabriel Stanovsky and Julian Michael and Luke Zettlemoyer and I. Dagan},\n",
      "booktitle={NAACL-HLT},\n",
      "year={2018}}\n",
      "\n",
      "2022-03-29 15:18:32,983 - INFO - allennlp.common.params - model_details.paper.title = Supervised Open Information Extraction\n",
      "2022-03-29 15:18:32,986 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:44145304\n",
      "2022-03-29 15:18:32,996 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:33,002 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:33,005 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:33,008 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:33,013 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:33,021 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:33,032 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:33,038 - INFO - allennlp.common.params - metrics.model_performance_measures = CoNLL SRL metrics\n",
      "2022-03-29 15:18:33,050 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:33,055 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:33,057 - INFO - allennlp.common.params - evaluation_data.dataset.name = OIE2016, WEB and NYT, PENN\n",
      "2022-03-29 15:18:33,061 - INFO - allennlp.common.params - evaluation_data.dataset.notes = The Open Information extractor was evaluated on the OIE2016 corpus. Unfortunately we cannot release this data due to licensing restrictions by the LDC. You can get the data on the corpus homepage.\n",
      "2022-03-29 15:18:33,065 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://github.com/gabrielStanovsky/oie-benchmark\n",
      "2022-03-29 15:18:33,068 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:33,081 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:33,098 - INFO - allennlp.common.params - training_data.dataset.name = All Words Open IE\n",
      "2022-03-29 15:18:33,105 - INFO - allennlp.common.params - training_data.dataset.url = https://github.com/gabrielStanovsky/supervised-oie/tree/master/data\n",
      "2022-03-29 15:18:33,111 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:33,119 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:33,131 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 15:18:33,132 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:33,134 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:33,136 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:33,291 - INFO - allennlp.common.params - id = pair-classification-roberta-snli\n",
      "2022-03-29 15:18:33,293 - INFO - allennlp.common.params - registered_model_name = basic_classifier\n",
      "2022-03-29 15:18:33,298 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:33,300 - INFO - allennlp.common.params - registered_predictor_name = textual_entailment\n",
      "2022-03-29 15:18:33,303 - INFO - allennlp.common.params - display_name = RoBERTa SNLI\n",
      "2022-03-29 15:18:33,304 - INFO - allennlp.common.params - task_id = textual_entailment\n",
      "2022-03-29 15:18:33,306 - INFO - allennlp.common.params - model_usage.archive_file = snli-roberta.2021-03-11.tar.gz\n",
      "2022-03-29 15:18:33,308 - INFO - allennlp.common.params - model_usage.training_config = pair_classification/snli_roberta.jsonnet\n",
      "2022-03-29 15:18:33,311 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 15:18:33,321 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:33,327 - INFO - allennlp.common.params - model_details.description = This `Model` implements a basic text classifier. The text is embedded into a text field using a RoBERTa-large model. The resulting sequence is pooled using a cls_pooler `Seq2VecEncoder` and then passed to a linear classification layer, which projects into the label space.\n",
      "2022-03-29 15:18:33,328 - INFO - allennlp.common.params - model_details.short_description = RoBERTa finetuned on SNLI.\n",
      "2022-03-29 15:18:33,331 - INFO - allennlp.common.params - model_details.developed_by = Liu et al\n",
      "2022-03-29 15:18:33,332 - INFO - allennlp.common.params - model_details.contributed_by = Dirk Groeneveld\n",
      "2022-03-29 15:18:33,334 - INFO - allennlp.common.params - model_details.date = 2020-07-29\n",
      "2022-03-29 15:18:33,335 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:33,336 - INFO - allennlp.common.params - model_details.model_type = RoBERTa\n",
      "2022-03-29 15:18:33,339 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and Luke Zettlemoyer and Veselin Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n",
      "2022-03-29 15:18:33,340 - INFO - allennlp.common.params - model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:18:33,341 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "2022-03-29 15:18:33,344 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:33,346 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:33,349 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:33,351 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:33,353 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:33,360 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:33,362 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:33,364 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy\n",
      "2022-03-29 15:18:33,368 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:33,369 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:33,371 - INFO - allennlp.common.params - evaluation_data.dataset.name = Stanford Natural Language Inference (SNLI) dev set\n",
      "2022-03-29 15:18:33,372 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_test.jsonl\n",
      "2022-03-29 15:18:33,373 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "2022-03-29 15:18:33,375 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:33,376 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:33,378 - INFO - allennlp.common.params - training_data.dataset.name = Stanford Natural Language Inference (SNLI) train set\n",
      "2022-03-29 15:18:33,382 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_train.jsonl\n",
      "2022-03-29 15:18:33,387 - INFO - allennlp.common.params - training_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "2022-03-29 15:18:33,391 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:33,395 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:33,398 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = Net Neutral: 0.49562665820121765, Fraction Neutral: 0.5068705677986145, Threshold:0.5: 0.47600528597831726, Threshold:0.7: 0.3036800026893616\n",
      "2022-03-29 15:18:33,404 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:33,411 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:33,417 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:33,556 - INFO - allennlp.common.params - id = pair-classification-binary-gender-bias-mitigated-roberta-snli\n",
      "2022-03-29 15:18:33,557 - INFO - allennlp.common.params - registered_model_name = bias_mitigator_applicator\n",
      "2022-03-29 15:18:33,561 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:33,565 - INFO - allennlp.common.params - registered_predictor_name = textual_entailment\n",
      "2022-03-29 15:18:33,568 - INFO - allennlp.common.params - display_name = Binary Gender Bias-Mitigated RoBERTa SNLI\n",
      "2022-03-29 15:18:33,574 - INFO - allennlp.common.params - task_id = textual_entailment\n",
      "2022-03-29 15:18:33,586 - INFO - allennlp.common.params - model_usage.archive_file = binary-gender-bias-mitigated-snli-roberta.2021-05-20.tar.gz\n",
      "2022-03-29 15:18:33,589 - INFO - allennlp.common.params - model_usage.training_config = pair_classification/binary_gender_bias_mitigated_snli_roberta.jsonnet\n",
      "2022-03-29 15:18:33,594 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.5.0 allennlp-models==2.5.0\n",
      "2022-03-29 15:18:33,599 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:33,605 - INFO - allennlp.common.params - model_details.description = This `Model` implements a basic text classifier with a bias mitigator applicator wrapper. The text is embedded into a text field using a RoBERTa-large model. Following the static embedding layer, the embeddings are projected onto the subspace orthogonal to the binary gender bias subspace. The resulting sequence is pooled using a cls_pooler `Seq2VecEncoder` and then passed to a linear classification layer, which projects into the label space.\n",
      "2022-03-29 15:18:33,610 - INFO - allennlp.common.params - model_details.short_description = RoBERTa finetuned on SNLI with binary gender bias mitigation.\n",
      "2022-03-29 15:18:33,623 - INFO - allennlp.common.params - model_details.developed_by = Dev at al\n",
      "2022-03-29 15:18:33,624 - INFO - allennlp.common.params - model_details.contributed_by = Arjun Subramonian\n",
      "2022-03-29 15:18:33,626 - INFO - allennlp.common.params - model_details.date = 2021-05-20\n",
      "2022-03-29 15:18:33,630 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:33,637 - INFO - allennlp.common.params - model_details.model_type = RoBERTa\n",
      "2022-03-29 15:18:33,659 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Dev2020OnMA,\n",
      "title={On Measuring and Mitigating Biased Inferences of Word Embeddings},\n",
      "author={Sunipa Dev and Tao Li and J. M. Phillips and Vivek Srikumar},\n",
      "journal={Proceedings of the AAAI Conference on Artificial Intelligence},\n",
      "year={2020},\n",
      "volume={34},\n",
      "number={05},\n",
      "pages={7659-7666},\n",
      "DOI={10.1609/aaai.v34i05.6267}\n",
      "\n",
      "2022-03-29 15:18:33,666 - INFO - allennlp.common.params - model_details.paper.title = On Measuring and Mitigating Biased Inferences of Word Embeddings\n",
      "2022-03-29 15:18:33,675 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:201670701\n",
      "2022-03-29 15:18:33,693 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:33,709 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:33,717 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:33,719 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:33,725 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:33,730 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:33,734 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:33,741 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy, Net Neutral, Fraction Neutral, Threshold:tau\n",
      "2022-03-29 15:18:33,746 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:33,749 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:33,752 - INFO - allennlp.common.params - evaluation_data.dataset.name = On Measuring and Mitigating Biased Gender-Occupation Inferences SNLI Dataset\n",
      "2022-03-29 15:18:33,756 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://storage.googleapis.com/allennlp-public-models/binary-gender-bias-mitigated-snli-dataset.jsonl\n",
      "2022-03-29 15:18:33,760 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://github.com/sunipa/On-Measuring-and-Mitigating-Biased-Inferences-of-Word-Embeddings\n",
      "2022-03-29 15:18:33,765 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:33,770 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:33,775 - INFO - allennlp.common.params - training_data.dataset.name = Stanford Natural Language Inference (SNLI) train set\n",
      "2022-03-29 15:18:33,777 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_train.jsonl\n",
      "2022-03-29 15:18:33,778 - INFO - allennlp.common.params - training_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "2022-03-29 15:18:33,782 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:33,787 - INFO - allennlp.common.params - training_data.preprocessing = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:18:33,790 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = Net Neutral: 0.6417539715766907, Fraction Neutral: 0.7002295255661011, Threshold:0.5: 0.6902161836624146, Threshold:0.7: 0.49243637919425964\n",
      "2022-03-29 15:18:33,796 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:33,799 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = Binary gender bias mitigation has been applied to this model. Nonetheless, the model will contain residual biases and bias mitigation does not guarantee entirely bias-free inferences.\n",
      "2022-03-29 15:18:33,804 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:33,967 - INFO - allennlp.common.params - id = mc-roberta-piqa\n",
      "2022-03-29 15:18:33,968 - INFO - allennlp.common.params - registered_model_name = transformer_mc\n",
      "2022-03-29 15:18:33,969 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:33,972 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:33,974 - INFO - allennlp.common.params - display_name = Physical Interaction Question Answering\n",
      "2022-03-29 15:18:33,979 - INFO - allennlp.common.params - task_id = mc\n",
      "2022-03-29 15:18:34,007 - INFO - allennlp.common.params - model_usage.archive_file = piqa.2020-07-08.tar.gz\n",
      "2022-03-29 15:18:34,018 - INFO - allennlp.common.params - model_usage.training_config = mc/piqa.jsonnet\n",
      "2022-03-29 15:18:34,021 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-03-29 15:18:34,029 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:34,039 - INFO - allennlp.common.params - model_details.description = This is a multiple choice model patterned after the BERT architecture. It calculates a score for each sequence on top of the CLS token, and then chooses the alternative with the highest score.\n",
      "2022-03-29 15:18:34,045 - INFO - allennlp.common.params - model_details.short_description = RoBERTa-based multiple choice model for PIQA.\n",
      "2022-03-29 15:18:34,063 - INFO - allennlp.common.params - model_details.developed_by = Devlin et al\n",
      "2022-03-29 15:18:34,090 - INFO - allennlp.common.params - model_details.contributed_by = Dirk Groeneveld\n",
      "2022-03-29 15:18:34,096 - INFO - allennlp.common.params - model_details.date = 2020-07-08\n",
      "2022-03-29 15:18:34,098 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:34,109 - INFO - allennlp.common.params - model_details.model_type = RoBERTa large\n",
      "2022-03-29 15:18:34,114 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and Luke Zettlemoyer and Veselin Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n",
      "2022-03-29 15:18:34,116 - INFO - allennlp.common.params - model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al)\n",
      "2022-03-29 15:18:34,118 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "2022-03-29 15:18:34,121 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:34,125 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:34,143 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:34,156 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:34,160 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:34,164 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:34,172 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:34,176 - INFO - allennlp.common.params - metrics.model_performance_measures = The chosen metric is accuracy, since it is a multiple choice model.\n",
      "2022-03-29 15:18:34,185 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:34,194 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:34,198 - INFO - allennlp.common.params - evaluation_data.dataset.name = PIQA (validation set)\n",
      "2022-03-29 15:18:34,202 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-03-29 15:18:34,210 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://yonatanbisk.com/piqa/\n",
      "2022-03-29 15:18:34,214 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:34,216 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:34,221 - INFO - allennlp.common.params - training_data.dataset.name = PIQA (train set)\n",
      "2022-03-29 15:18:34,224 - INFO - allennlp.common.params - training_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-03-29 15:18:34,225 - INFO - allennlp.common.params - training_data.dataset.url = https://yonatanbisk.com/piqa/\n",
      "2022-03-29 15:18:34,227 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:34,230 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:34,239 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 15:18:34,242 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:34,247 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:34,251 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:34,373 - INFO - allennlp.common.params - id = rc-nmn\n",
      "2022-03-29 15:18:34,373 - INFO - allennlp.common.params - registered_model_name = None\n",
      "2022-03-29 15:18:34,374 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:34,376 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:34,377 - INFO - allennlp.common.params - display_name = Neural Module Network (NMN)\n",
      "2022-03-29 15:18:34,380 - INFO - allennlp.common.params - task_id = rc\n",
      "2022-03-29 15:18:34,382 - INFO - allennlp.common.params - model_usage.archive_file = drop-nmn-2020.04.04.tar.gz\n",
      "2022-03-29 15:18:34,387 - INFO - allennlp.common.params - model_usage.training_config = None\n",
      "2022-03-29 15:18:34,391 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-03-29 15:18:34,393 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:34,398 - INFO - allennlp.common.params - model_details.description = A neural module network trained on DROP.\n",
      "2022-03-29 15:18:34,403 - INFO - allennlp.common.params - model_details.short_description = A neural module network trained on DROP.\n",
      "2022-03-29 15:18:34,405 - INFO - allennlp.common.params - model_details.developed_by = Andreas et al\n",
      "2022-03-29 15:18:34,410 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 15:18:34,413 - INFO - allennlp.common.params - model_details.date = 2020-04-04\n",
      "2022-03-29 15:18:34,415 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:34,417 - INFO - allennlp.common.params - model_details.model_type = Neural Module Network\n",
      "2022-03-29 15:18:34,420 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Andreas2016NeuralMN,\n",
      "title={Neural Module Networks},\n",
      "author={Jacob Andreas and Marcus Rohrbach and Trevor Darrell and D. Klein},\n",
      "journal={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n",
      "year={2016},\n",
      "pages={39-48}}\n",
      "\n",
      "2022-03-29 15:18:34,422 - INFO - allennlp.common.params - model_details.paper.title = Neural Module Networks\n",
      "2022-03-29 15:18:34,426 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:5276660\n",
      "2022-03-29 15:18:34,430 - INFO - allennlp.common.params - model_details.license = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:18:34,433 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:34,436 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:34,438 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:34,443 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:34,445 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:34,447 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:34,449 - INFO - allennlp.common.params - metrics.model_performance_measures = None\n",
      "2022-03-29 15:18:34,453 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:34,455 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:34,457 - INFO - allennlp.common.params - evaluation_data.dataset = None\n",
      "2022-03-29 15:18:34,460 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:34,462 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:34,467 - INFO - allennlp.common.params - training_data.dataset.name = DROP\n",
      "2022-03-29 15:18:34,469 - INFO - allennlp.common.params - training_data.dataset.url = https://allennlp.org/drop\n",
      "2022-03-29 15:18:34,473 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:34,478 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:34,479 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 15:18:34,482 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:34,484 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:34,487 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:34,615 - INFO - allennlp.common.params - id = mc-roberta-commonsenseqa\n",
      "2022-03-29 15:18:34,620 - INFO - allennlp.common.params - registered_model_name = transformer_mc\n",
      "2022-03-29 15:18:34,626 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:34,629 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:34,631 - INFO - allennlp.common.params - display_name = RoBERTa Common Sense QA\n",
      "2022-03-29 15:18:34,637 - INFO - allennlp.common.params - task_id = mc\n",
      "2022-03-29 15:18:34,646 - INFO - allennlp.common.params - model_usage.archive_file = commonsenseqa.2020-07-08.tar.gz\n",
      "2022-03-29 15:18:34,649 - INFO - allennlp.common.params - model_usage.training_config = mc/commonsenseqa.jsonnet\n",
      "2022-03-29 15:18:34,652 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-03-29 15:18:34,654 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:34,659 - INFO - allennlp.common.params - model_details.description = This is a multiple choice model patterned after the BERT architecture. It calculates a score for each sequence on top of the CLS token, and then chooses the alternative with the highest score.\n",
      "2022-03-29 15:18:34,662 - INFO - allennlp.common.params - model_details.short_description = RoBERTa-based multiple choice model for CommonSenseQA.\n",
      "2022-03-29 15:18:34,665 - INFO - allennlp.common.params - model_details.developed_by = Liu et al\n",
      "2022-03-29 15:18:34,669 - INFO - allennlp.common.params - model_details.contributed_by = Dirk Groeneveld\n",
      "2022-03-29 15:18:34,671 - INFO - allennlp.common.params - model_details.date = 2020-07-08\n",
      "2022-03-29 15:18:34,673 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:34,675 - INFO - allennlp.common.params - model_details.model_type = RoBERTa large\n",
      "2022-03-29 15:18:34,679 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and Luke Zettlemoyer and Veselin Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n",
      "2022-03-29 15:18:34,681 - INFO - allennlp.common.params - model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al)\n",
      "2022-03-29 15:18:34,683 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "2022-03-29 15:18:34,687 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:34,690 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:34,692 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:34,697 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:34,702 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:34,704 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:34,708 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:34,712 - INFO - allennlp.common.params - metrics.model_performance_measures = The chosen metric is accuracy, since it is a multiple choice model.\n",
      "2022-03-29 15:18:34,714 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:34,716 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:34,719 - INFO - allennlp.common.params - evaluation_data.dataset.name = CommonSenseQA (validation set)\n",
      "2022-03-29 15:18:34,723 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-03-29 15:18:34,727 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://github.com/jonathanherzig/commonsenseqa\n",
      "2022-03-29 15:18:34,729 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:34,732 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:34,734 - INFO - allennlp.common.params - training_data.dataset.name = CommonSenseQA (train set)\n",
      "2022-03-29 15:18:34,738 - INFO - allennlp.common.params - training_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-03-29 15:18:34,742 - INFO - allennlp.common.params - training_data.dataset.url = https://github.com/jonathanherzig/commonsenseqa\n",
      "2022-03-29 15:18:34,744 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:34,746 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:34,749 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 15:18:34,751 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:34,756 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:34,761 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:34,893 - INFO - allennlp.common.params - id = pair-classification-roberta-mnli\n",
      "2022-03-29 15:18:34,912 - INFO - allennlp.common.params - registered_model_name = basic_classifier\n",
      "2022-03-29 15:18:34,920 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:34,937 - INFO - allennlp.common.params - registered_predictor_name = textual_entailment\n",
      "2022-03-29 15:18:34,970 - INFO - allennlp.common.params - display_name = RoBERTa MNLI\n",
      "2022-03-29 15:18:34,974 - INFO - allennlp.common.params - task_id = textual_entailment\n",
      "2022-03-29 15:18:34,978 - INFO - allennlp.common.params - model_usage.archive_file = mnli-roberta.2021-03-11.tar.gz\n",
      "2022-03-29 15:18:34,982 - INFO - allennlp.common.params - model_usage.training_config = pair_classification/mnli_roberta.jsonnet\n",
      "2022-03-29 15:18:34,987 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 15:18:34,991 - INFO - allennlp.common.params - model_usage.overrides = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:18:34,994 - INFO - allennlp.common.params - model_details.description = This `Model` implements a basic text classifier. The text is embedded into a text field using a RoBERTa-large model. The resulting sequence is pooled using a cls_pooler `Seq2VecEncoder` and then passed to a linear classification layer, which projects into the label space.\n",
      "2022-03-29 15:18:34,996 - INFO - allennlp.common.params - model_details.short_description = RoBERTa finetuned on MNLI.\n",
      "2022-03-29 15:18:34,998 - INFO - allennlp.common.params - model_details.developed_by = Liu et al\n",
      "2022-03-29 15:18:35,000 - INFO - allennlp.common.params - model_details.contributed_by = Dirk Groeneveld\n",
      "2022-03-29 15:18:35,010 - INFO - allennlp.common.params - model_details.date = 2020-07-29\n",
      "2022-03-29 15:18:35,013 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:35,026 - INFO - allennlp.common.params - model_details.model_type = RoBERTa\n",
      "2022-03-29 15:18:35,036 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and Luke Zettlemoyer and Veselin Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n",
      "2022-03-29 15:18:35,038 - INFO - allennlp.common.params - model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al)\n",
      "2022-03-29 15:18:35,040 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "2022-03-29 15:18:35,046 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:35,048 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:35,051 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:35,057 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:35,059 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:35,065 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:35,068 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:35,072 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy\n",
      "2022-03-29 15:18:35,076 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:35,080 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:35,084 - INFO - allennlp.common.params - evaluation_data.dataset.name = Multi-genre Natural Language Inference (MultiNLI) dev set\n",
      "2022-03-29 15:18:35,090 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/multinli/multinli_1.0_dev_mismatched.jsonl\n",
      "2022-03-29 15:18:35,096 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://cims.nyu.edu/~sbowman/multinli/\n",
      "2022-03-29 15:18:35,102 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:35,103 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:35,107 - INFO - allennlp.common.params - training_data.dataset.name = Multi-genre Natural Language Inference (MultiNLI) train set\n",
      "2022-03-29 15:18:35,111 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/multinli/multinli_1.0_train.jsonl\n",
      "2022-03-29 15:18:35,115 - INFO - allennlp.common.params - training_data.dataset.url = https://cims.nyu.edu/~sbowman/multinli/\n",
      "2022-03-29 15:18:35,118 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:35,123 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:35,127 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 15:18:35,129 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:35,134 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:35,138 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:35,283 - INFO - allennlp.common.params - id = rc-transformer-qa\n",
      "2022-03-29 15:18:35,285 - INFO - allennlp.common.params - registered_model_name = transformer_qa\n",
      "2022-03-29 15:18:35,287 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:35,299 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:35,303 - INFO - allennlp.common.params - display_name = Transformer QA\n",
      "2022-03-29 15:18:35,308 - INFO - allennlp.common.params - task_id = rc\n",
      "2022-03-29 15:18:35,313 - INFO - allennlp.common.params - model_usage.archive_file = transformer-qa.2021-02-11.tar.gz\n",
      "2022-03-29 15:18:35,324 - INFO - allennlp.common.params - model_usage.training_config = rc/transformer_qa.jsonnet\n",
      "2022-03-29 15:18:35,327 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 15:18:35,333 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:35,340 - INFO - allennlp.common.params - model_details.description = The model implements a reading comprehension model patterned after the proposed model in [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (Devlin et al, 2018)](https://api.semanticscholar.org/CorpusID:52967399), with improvements borrowed from the SQuAD model in the transformers project. It predicts start tokens and end tokens with a linear layer on top of word piece embeddings.\n",
      "2022-03-29 15:18:35,342 - INFO - allennlp.common.params - model_details.short_description = A reading comprehension model patterned after the proposed model in Devlin et al, with improvements borrowed from the SQuAD model in the transformers project\n",
      "2022-03-29 15:18:35,344 - INFO - allennlp.common.params - model_details.developed_by = Devlin et al\n",
      "2022-03-29 15:18:35,359 - INFO - allennlp.common.params - model_details.contributed_by = Dirk Groeneveld and Evan Pete Walsh\n",
      "2022-03-29 15:18:35,365 - INFO - allennlp.common.params - model_details.date = 2020-10-03\n",
      "2022-03-29 15:18:35,369 - INFO - allennlp.common.params - model_details.version = 2\n",
      "2022-03-29 15:18:35,375 - INFO - allennlp.common.params - model_details.model_type = RoBERTa\n",
      "2022-03-29 15:18:35,378 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and L. Zettlemoyer and V. Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n",
      "2022-03-29 15:18:35,391 - INFO - allennlp.common.params - model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach\n",
      "2022-03-29 15:18:35,395 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "2022-03-29 15:18:35,400 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:35,410 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:35,417 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:35,420 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:35,423 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:35,427 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:35,432 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:35,436 - INFO - allennlp.common.params - metrics.model_performance_measures = F1-score, Span Accuracy, Exact Match\n",
      "2022-03-29 15:18:35,445 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:35,449 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:35,453 - INFO - allennlp.common.params - evaluation_data.dataset.name = SQuAD dev set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:18:35,457 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/squad/squad-dev-v2.0.json\n",
      "2022-03-29 15:18:35,463 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://rajpurkar.github.io/SQuAD-explorer/explore/2.0/dev/\n",
      "2022-03-29 15:18:35,469 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:35,473 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:35,476 - INFO - allennlp.common.params - training_data.dataset.name = SQuAD training set\n",
      "2022-03-29 15:18:35,486 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/squad/squad-train-v2.0.json\n",
      "2022-03-29 15:18:35,488 - INFO - allennlp.common.params - training_data.dataset.url = https://rajpurkar.github.io/SQuAD-explorer/explore/2.0/dev/\n",
      "2022-03-29 15:18:35,493 - INFO - allennlp.common.params - training_data.motivation = For the pretrained RoBERTa model, document-level corpora were used rather than a shuffled sentence-level corpus such as the Billion Word Benchmark (Chelba et al., 2013) in order to extract long contiguous sequences\n",
      "2022-03-29 15:18:35,497 - INFO - allennlp.common.params - training_data.preprocessing = For the pretrained RoBERTa model, only the text passages were extracted from English Wikipedia; lists, tables, and headers were ignored.\n",
      "2022-03-29 15:18:35,503 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = On the validation set:\n",
      "F1: 88%\n",
      "Exact match: 84%\n",
      "These are metrics using the official evaluation. Note that the metrics that the model produces while training are calculated on a per-instance basis only. Since there could be more than one instance per question, these metrics are not the official numbers on the SQuAD task. To get official numbers, run the evaluation script at allennlp_models/rc/tools/transformer_qa_eval.py.\n",
      "2022-03-29 15:18:35,508 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:35,523 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:35,525 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:35,718 - INFO - allennlp.common.params - id = tagging-fine-grained-crf-tagger\n",
      "2022-03-29 15:18:35,723 - INFO - allennlp.common.params - registered_model_name = crf_tagger\n",
      "2022-03-29 15:18:35,725 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:35,726 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:35,728 - INFO - allennlp.common.params - display_name = Fine Grained Named Entity Recognition\n",
      "2022-03-29 15:18:35,733 - INFO - allennlp.common.params - task_id = ner\n",
      "2022-03-29 15:18:35,741 - INFO - allennlp.common.params - model_usage.archive_file = fine-grained-ner.2021-02-11.tar.gz\n",
      "2022-03-29 15:18:35,742 - INFO - allennlp.common.params - model_usage.training_config = tagging/fine-grained-ner.jsonnet\n",
      "2022-03-29 15:18:35,744 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 15:18:35,745 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:35,748 - INFO - allennlp.common.params - model_details.description = This model identifies a broad range of 16 semantic types in the input text. It is a reimplementation of Lample (2016) and uses a biLSTM with a CRF layer, character embeddings and ELMo embeddings.\n",
      "2022-03-29 15:18:35,752 - INFO - allennlp.common.params - model_details.short_description = This model identifies a broad range of 16 semantic types in the input text. It is a reimplementation of Lample (2016) and uses a biLSTM with a CRF layer, character embeddings and ELMo embeddings.\n",
      "2022-03-29 15:18:35,760 - INFO - allennlp.common.params - model_details.developed_by = Lample et al\n",
      "2022-03-29 15:18:35,766 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 15:18:35,772 - INFO - allennlp.common.params - model_details.date = 2020-06-24\n",
      "2022-03-29 15:18:35,780 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:35,807 - INFO - allennlp.common.params - model_details.model_type = BiLSTM\n",
      "2022-03-29 15:18:35,812 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Lample2016NeuralAF,\n",
      "title={Neural Architectures for Named Entity Recognition},\n",
      "author={Guillaume Lample and Miguel Ballesteros and Sandeep Subramanian and K. Kawakami and Chris Dyer},\n",
      "journal={ArXiv},\n",
      "year={2016},\n",
      "volume={abs/1603.01360}}\n",
      "\n",
      "2022-03-29 15:18:35,814 - INFO - allennlp.common.params - model_details.paper.title = Neural Architectures for Named Entity Recognition\n",
      "2022-03-29 15:18:35,825 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:6042994\n",
      "2022-03-29 15:18:35,826 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:35,829 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:35,842 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:35,860 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:35,863 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:35,876 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:35,881 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:35,899 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy and Span-based F1 metric\n",
      "2022-03-29 15:18:35,905 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:35,910 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:35,930 - INFO - allennlp.common.params - evaluation_data.dataset.name = Ontonotes 5.0\n",
      "2022-03-29 15:18:35,938 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Unfortunately we cannot release this data due to licensing restrictions.\n",
      "2022-03-29 15:18:35,968 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = /path/do/dataset\n",
      "2022-03-29 15:18:35,977 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "2022-03-29 15:18:35,997 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:36,006 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:36,008 - INFO - allennlp.common.params - training_data.dataset.name = Ontonotes 5.0\n",
      "2022-03-29 15:18:36,009 - INFO - allennlp.common.params - training_data.dataset.notes = Unfortunately we cannot release this data due to licensing restrictions.\n",
      "2022-03-29 15:18:36,013 - INFO - allennlp.common.params - training_data.dataset.processed_url = /path/do/dataset\n",
      "2022-03-29 15:18:36,016 - INFO - allennlp.common.params - training_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "2022-03-29 15:18:36,025 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:36,027 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:36,029 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = On the validation set:\n",
      "Accuracy: 97%\n",
      "F1: 88%\n",
      "2022-03-29 15:18:36,032 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:36,041 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:36,046 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:36,169 - INFO - allennlp.common.params - id = glove-sst\n",
      "2022-03-29 15:18:36,170 - INFO - allennlp.common.params - registered_model_name = None\n",
      "2022-03-29 15:18:36,170 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:36,172 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:36,175 - INFO - allennlp.common.params - display_name = GLoVe-LSTM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:18:36,178 - INFO - allennlp.common.params - task_id = sentiment-analysis\n",
      "2022-03-29 15:18:36,193 - INFO - allennlp.common.params - model_usage.archive_file = basic_stanford_sentiment_treebank-2020.06.09.tar.gz\n",
      "2022-03-29 15:18:36,209 - INFO - allennlp.common.params - model_usage.training_config = classification/basic_stanford_sentiment_treebank.jsonnet\n",
      "2022-03-29 15:18:36,215 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 15:18:36,232 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:36,237 - INFO - allennlp.common.params - model_details.description = This model uses GloVe embeddings and is trained on the binary classification setting of the Stanford Sentiment Treebank. It achieves about 87% on the test set.\n",
      "2022-03-29 15:18:36,245 - INFO - allennlp.common.params - model_details.short_description = LSTM binary classifier with GloVe embeddings.\n",
      "2022-03-29 15:18:36,258 - INFO - allennlp.common.params - model_details.developed_by = None\n",
      "2022-03-29 15:18:36,262 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 15:18:36,279 - INFO - allennlp.common.params - model_details.date = 2020-06-09\n",
      "2022-03-29 15:18:36,293 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:36,295 - INFO - allennlp.common.params - model_details.model_type = LSTM\n",
      "2022-03-29 15:18:36,297 - INFO - allennlp.common.params - model_details.paper = None\n",
      "2022-03-29 15:18:36,305 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:36,308 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:36,315 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:36,341 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:36,342 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:36,351 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:36,373 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:36,379 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy\n",
      "2022-03-29 15:18:36,390 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:36,393 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:36,399 - INFO - allennlp.common.params - evaluation_data.dataset.name = Stanford Sentiment Treebank\n",
      "2022-03-29 15:18:36,403 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/sst/test.txt\n",
      "2022-03-29 15:18:36,407 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://nlp.stanford.edu/sentiment/treebank.html\n",
      "2022-03-29 15:18:36,410 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:36,415 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:36,429 - INFO - allennlp.common.params - training_data.dataset.name = Stanford Sentiment Treebank\n",
      "2022-03-29 15:18:36,440 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/sst/train.txt\n",
      "2022-03-29 15:18:36,451 - INFO - allennlp.common.params - training_data.dataset.url = https://nlp.stanford.edu/sentiment/treebank.html\n",
      "2022-03-29 15:18:36,454 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:36,457 - INFO - allennlp.common.params - training_data.preprocessing = Binary classification setting\n",
      "2022-03-29 15:18:36,466 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = Accuracy: 87% on SST test set.\n",
      "2022-03-29 15:18:36,470 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:36,481 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:36,488 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'vgqa-vilbert': <allennlp.common.model_card.ModelCard at 0x7fd001ffd370>,\n",
       " 'structured-prediction-srl-bert': <allennlp.common.model_card.ModelCard at 0x7fd001ff3af0>,\n",
       " 'semparse-nlvr': <allennlp.common.model_card.ModelCard at 0x7fd002010f40>,\n",
       " 'structured-prediction-biaffine-parser': <allennlp.common.model_card.ModelCard at 0x7fd0020251f0>,\n",
       " 'mc-roberta-swag': <allennlp.common.model_card.ModelCard at 0x7fd001ff3a00>,\n",
       " 'lm-masked-language-model': <allennlp.common.model_card.ModelCard at 0x7fd001ff3d30>,\n",
       " 'roberta-sst': <allennlp.common.model_card.ModelCard at 0x7fd00202b430>,\n",
       " 'lm-next-token-lm-gpt2': <allennlp.common.model_card.ModelCard at 0x7fd002031bb0>,\n",
       " 'coref-spanbert': <allennlp.common.model_card.ModelCard at 0x7fd0020311f0>,\n",
       " 'rc-bidaf-elmo': <allennlp.common.model_card.ModelCard at 0x7fd002033f40>,\n",
       " 'tagging-elmo-crf-tagger': <allennlp.common.model_card.ModelCard at 0x7fd00202bca0>,\n",
       " 'semparse-text-to-sql': <allennlp.common.model_card.ModelCard at 0x7fd00203a9d0>,\n",
       " 'nlvr2-vilbert': <allennlp.common.model_card.ModelCard at 0x7fd002048100>,\n",
       " 'rc-bidaf': <allennlp.common.model_card.ModelCard at 0x7fd002031160>,\n",
       " 'vqa-vilbert': <allennlp.common.model_card.ModelCard at 0x7fd002040c10>,\n",
       " 'semparse-wikitables': <allennlp.common.model_card.ModelCard at 0x7fd00203a5e0>,\n",
       " 'generation-bart': <allennlp.common.model_card.ModelCard at 0x7fd0020427f0>,\n",
       " 'tagging-fine-grained-transformer-crf-tagger': <allennlp.common.model_card.ModelCard at 0x7fd00202be80>,\n",
       " 've-vilbert': <allennlp.common.model_card.ModelCard at 0x7fd002044eb0>,\n",
       " 'pair-classification-esim': <allennlp.common.model_card.ModelCard at 0x7fd0020441f0>,\n",
       " 'pair-classification-adversarial-binary-gender-bias-mitigated-roberta-snli': <allennlp.common.model_card.ModelCard at 0x7fd002042dc0>,\n",
       " 'rc-naqanet': <allennlp.common.model_card.ModelCard at 0x7fd002040730>,\n",
       " 'structured-prediction-constituency-parser': <allennlp.common.model_card.ModelCard at 0x7fd00204e700>,\n",
       " 'pair-classification-decomposable-attention-elmo': <allennlp.common.model_card.ModelCard at 0x7fd002040700>,\n",
       " 'pair-classification-roberta-rte': <allennlp.common.model_card.ModelCard at 0x7fd002042970>,\n",
       " 'evaluate_rc-lerc': <allennlp.common.model_card.ModelCard at 0x7fd002046100>,\n",
       " 'structured-prediction-srl': <allennlp.common.model_card.ModelCard at 0x7fd00204a310>,\n",
       " 'pair-classification-roberta-snli': <allennlp.common.model_card.ModelCard at 0x7fd002057280>,\n",
       " 'pair-classification-binary-gender-bias-mitigated-roberta-snli': <allennlp.common.model_card.ModelCard at 0x7fd002048d60>,\n",
       " 'mc-roberta-piqa': <allennlp.common.model_card.ModelCard at 0x7fd00205bd60>,\n",
       " 'rc-nmn': <allennlp.common.model_card.ModelCard at 0x7fd002057d00>,\n",
       " 'mc-roberta-commonsenseqa': <allennlp.common.model_card.ModelCard at 0x7fd00205fee0>,\n",
       " 'pair-classification-roberta-mnli': <allennlp.common.model_card.ModelCard at 0x7fd0020443d0>,\n",
       " 'rc-transformer-qa': <allennlp.common.model_card.ModelCard at 0x7fd002064eb0>,\n",
       " 'tagging-fine-grained-crf-tagger': <allennlp.common.model_card.ModelCard at 0x7fd002064490>,\n",
       " 'glove-sst': <allennlp.common.model_card.ModelCard at 0x7fd00205f070>}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "get_pretrained_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'vgqa-vilbert': <allennlp.common.model_card.ModelCard at 0x7fb2863658e0>,\n",
    " 'structured-prediction-srl-bert': <allennlp.common.model_card.ModelCard at 0x7fb286765f70>,\n",
    " 'semparse-nlvr': <allennlp.common.model_card.ModelCard at 0x7fb2867d5400>,\n",
    " 'structured-prediction-biaffine-parser': <allennlp.common.model_card.ModelCard at 0x7fb286720970>,\n",
    " 'mc-roberta-swag': <allennlp.common.model_card.ModelCard at 0x7fb2867de6d0>,\n",
    " 'lm-masked-language-model': <allennlp.common.model_card.ModelCard at 0x7fb2867dc5e0>,\n",
    " 'roberta-sst': <allennlp.common.model_card.ModelCard at 0x7fb287104fd0>,\n",
    " 'lm-next-token-lm-gpt2': <allennlp.common.model_card.ModelCard at 0x7fb2867201f0>,\n",
    " 'coref-spanbert': <allennlp.common.model_card.ModelCard at 0x7fb2867de550>,\n",
    " 'rc-bidaf-elmo': <allennlp.common.model_card.ModelCard at 0x7fb28710a1c0>,\n",
    " 'tagging-elmo-crf-tagger': <allennlp.common.model_card.ModelCard at 0x7fb2867d5e50>,\n",
    " 'semparse-text-to-sql': <allennlp.common.model_card.ModelCard at 0x7fb28710d700>,\n",
    " 'nlvr2-vilbert': <allennlp.common.model_card.ModelCard at 0x7fb287104190>,\n",
    " 'rc-bidaf': <allennlp.common.model_card.ModelCard at 0x7fb287114970>,\n",
    " 'vqa-vilbert': <allennlp.common.model_card.ModelCard at 0x7fb2867ca4c0>,\n",
    " 'semparse-wikitables': <allennlp.common.model_card.ModelCard at 0x7fb287104280>,\n",
    " 'generation-bart': <allennlp.common.model_card.ModelCard at 0x7fb287115220>,\n",
    " 'tagging-fine-grained-transformer-crf-tagger': <allennlp.common.model_card.ModelCard at 0x7fb2867b1a30>,\n",
    " 've-vilbert': <allennlp.common.model_card.ModelCard at 0x7fb2867de700>,\n",
    " 'pair-classification-esim': <allennlp.common.model_card.ModelCard at 0x7fb287114b80>,\n",
    " 'pair-classification-adversarial-binary-gender-bias-mitigated-roberta-snli': <allennlp.common.model_card.ModelCard at 0x7fb28711e400>,\n",
    " 'rc-naqanet': <allennlp.common.model_card.ModelCard at 0x7fb287118490>,\n",
    " 'structured-prediction-constituency-parser': <allennlp.common.model_card.ModelCard at 0x7fb2867ca520>,\n",
    " 'pair-classification-decomposable-attention-elmo': <allennlp.common.model_card.ModelCard at 0x7fb28711edf0>,\n",
    " 'pair-classification-roberta-rte': <allennlp.common.model_card.ModelCard at 0x7fb287125850>,\n",
    " 'evaluate_rc-lerc': <allennlp.common.model_card.ModelCard at 0x7fb287118880>,\n",
    " 'structured-prediction-srl': <allennlp.common.model_card.ModelCard at 0x7fb28712aca0>,\n",
    " 'pair-classification-roberta-snli': <allennlp.common.model_card.ModelCard at 0x7fb2867ca5e0>,\n",
    " 'pair-classification-binary-gender-bias-mitigated-roberta-snli': <allennlp.common.model_card.ModelCard at 0x7fb28711e2b0>,\n",
    " 'mc-roberta-piqa': <allennlp.common.model_card.ModelCard at 0x7fb287126430>,\n",
    " 'rc-nmn': <allennlp.common.model_card.ModelCard at 0x7fb287126520>,\n",
    " 'mc-roberta-commonsenseqa': <allennlp.common.model_card.ModelCard at 0x7fb2871341c0>,\n",
    " 'pair-classification-roberta-mnli': <allennlp.common.model_card.ModelCard at 0x7fb28711ffd0>,\n",
    " 'rc-transformer-qa': <allennlp.common.model_card.ModelCard at 0x7fb287138340>,\n",
    " 'tagging-fine-grained-crf-tagger': <allennlp.common.model_card.ModelCard at 0x7fb28712a5e0>,\n",
    " 'glove-sst': <allennlp.common.model_card.ModelCard at 0x7fb28713aeb0>}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:18:37,066 - INFO - allennlp.common.plugins - Plugin allennlp_models available\n",
      "2022-03-29 15:18:37,221 - INFO - allennlp.common.params - id = vgqa-vilbert\n",
      "2022-03-29 15:18:37,223 - INFO - allennlp.common.params - registered_model_name = vqa_vilbert_from_huggingface\n",
      "2022-03-29 15:18:37,224 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:37,225 - INFO - allennlp.common.params - registered_predictor_name = vgqa_vilbert\n",
      "2022-03-29 15:18:37,228 - INFO - allennlp.common.params - display_name = ViLBERT - Visual Genome Question Answering\n",
      "2022-03-29 15:18:37,230 - INFO - allennlp.common.params - task_id = vgqa\n",
      "2022-03-29 15:18:37,232 - INFO - allennlp.common.params - model_usage.archive_file = vilbert-vgqa-pretrained.2021-05-10.tar.gz\n",
      "2022-03-29 15:18:37,247 - INFO - allennlp.common.params - model_usage.training_config = vision/vilbert_vgqa_pretrained.jsonnet\n",
      "2022-03-29 15:18:37,256 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.5.0 allennlp-models==2.5.0\n",
      "2022-03-29 15:18:37,261 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:37,265 - INFO - allennlp.common.params - model_details.description = ViLBERT (short for Vision-and-Language BERT), is a model for learning task-agnostic joint representations of image content and natural language.\n",
      "2022-03-29 15:18:37,279 - INFO - allennlp.common.params - model_details.short_description = ViLBERT (short for Vision-and-Language BERT), is a model for learning task-agnostic joint representations of image content and natural language.\n",
      "2022-03-29 15:18:37,282 - INFO - allennlp.common.params - model_details.developed_by = Lu et al\n",
      "2022-03-29 15:18:37,288 - INFO - allennlp.common.params - model_details.contributed_by = Jacob Morrison\n",
      "2022-03-29 15:18:37,295 - INFO - allennlp.common.params - model_details.date = 2021-05-07\n",
      "2022-03-29 15:18:37,302 - INFO - allennlp.common.params - model_details.version = 2\n",
      "2022-03-29 15:18:37,305 - INFO - allennlp.common.params - model_details.model_type = ViLBERT based on BERT large\n",
      "2022-03-29 15:18:37,336 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Lu2019ViLBERTPT,\n",
      "title={ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks},\n",
      "author={Jiasen Lu and Dhruv Batra and D. Parikh and Stefan Lee},\n",
      "booktitle={NeurIPS},\n",
      "year={2019}\n",
      "}\n",
      "2022-03-29 15:18:37,350 - INFO - allennlp.common.params - model_details.paper.title = ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks\n",
      "2022-03-29 15:18:37,354 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:199453025\n",
      "2022-03-29 15:18:37,361 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:37,378 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:37,379 - INFO - allennlp.common.params - intended_use.primary_uses = This model is developed for the AllenNLP demo.\n",
      "2022-03-29 15:18:37,388 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:37,389 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:37,393 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:37,395 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:37,398 - INFO - allennlp.common.params - metrics.model_performance_measures = F1-metric and VQA score\n",
      "2022-03-29 15:18:37,403 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:37,405 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:37,410 - INFO - allennlp.common.params - evaluation_data.dataset.name = VGQA dataset\n",
      "2022-03-29 15:18:37,413 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Evaluation requires a large amount of images to be accessible locally, so we cannot provide a command you can easily copy and paste. The first time you run it, you will get an error message that tells you how to get the rest of the data.\n",
      "2022-03-29 15:18:37,417 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://visualgenome.org/static/data/dataset/question_answers.json.zip!question_answers.json[:5000]\n",
      "2022-03-29 15:18:37,420 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://visualgenome.org/\n",
      "2022-03-29 15:18:37,428 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:37,430 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:37,433 - INFO - allennlp.common.params - training_data.dataset.name = VGQA dataset\n",
      "2022-03-29 15:18:37,442 - INFO - allennlp.common.params - training_data.dataset.notes = Training requires a large amount of images to be accessible locally, so we cannot provide a command you can easily copy and paste. The first time you run it, you will get an error message that tells you how to get the rest of the data.\n",
      "2022-03-29 15:18:37,444 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://visualgenome.org/static/data/dataset/question_answers.json.zip!question_answers.json[5000:]\n",
      "2022-03-29 15:18:37,448 - INFO - allennlp.common.params - training_data.dataset.url = https://visualgenome.org/\n",
      "2022-03-29 15:18:37,454 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:37,456 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:37,458 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = On the validation set:\n",
      "F1: 29.6%\n",
      "VQA: 26.5%.\n",
      "These scores do not match the performance in the VilBERT paper. Please contact us if you want to match those scores!\n",
      "2022-03-29 15:18:37,462 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:37,468 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:37,471 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:37,631 - INFO - allennlp.common.params - id = structured-prediction-srl-bert\n",
      "2022-03-29 15:18:37,634 - INFO - allennlp.common.params - registered_model_name = srl_bert\n",
      "2022-03-29 15:18:37,643 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:37,650 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:37,652 - INFO - allennlp.common.params - display_name = SRL BERT\n",
      "2022-03-29 15:18:37,653 - INFO - allennlp.common.params - task_id = srl\n",
      "2022-03-29 15:18:37,656 - INFO - allennlp.common.params - model_usage.archive_file = structured-prediction-srl-bert.2020.12.15.tar.gz\n",
      "2022-03-29 15:18:37,657 - INFO - allennlp.common.params - model_usage.training_config = structured_prediction/bert_base_srl.jsonnet\n",
      "2022-03-29 15:18:37,658 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 15:18:37,663 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:37,666 - INFO - allennlp.common.params - model_details.description = An implementation of a BERT based model (Shi et al, 2019) with some modifications (no additional parameters apart from a linear classification layer), which is currently the state of the art single model for English PropBank SRL (Newswire sentences). It achieves 86.49 test F1 on the Ontonotes 5.0 dataset.\n",
      "2022-03-29 15:18:37,667 - INFO - allennlp.common.params - model_details.short_description = A BERT based model (Shi et al, 2019) with some modifications (no additional parameters apart from a linear classification layer)\n",
      "2022-03-29 15:18:37,669 - INFO - allennlp.common.params - model_details.developed_by = Shi et al\n",
      "2022-03-29 15:18:37,670 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 15:18:37,672 - INFO - allennlp.common.params - model_details.date = 2020-09-03\n",
      "2022-03-29 15:18:37,674 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:37,676 - INFO - allennlp.common.params - model_details.model_type = BERT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:18:37,679 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Shi2019SimpleBM,\n",
      "title={Simple BERT Models for Relation Extraction and Semantic Role Labeling},\n",
      "author={Peng Shi and Jimmy Lin},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1904.05255}}\n",
      "\n",
      "2022-03-29 15:18:37,680 - INFO - allennlp.common.params - model_details.paper.title = Simple BERT Models for Relation Extraction and Semantic Role Labeling\n",
      "2022-03-29 15:18:37,682 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:131773936\n",
      "2022-03-29 15:18:37,686 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:37,689 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:37,691 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:37,717 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:37,719 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:37,721 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:37,723 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:37,724 - INFO - allennlp.common.params - metrics.model_performance_measures = Precision, recall and F1-score\n",
      "2022-03-29 15:18:37,726 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:37,728 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:37,730 - INFO - allennlp.common.params - evaluation_data.dataset.name = Ontonotes 5.0\n",
      "2022-03-29 15:18:37,735 - INFO - allennlp.common.params - evaluation_data.dataset.notes = We cannot release this data due to licensing restrictions.\n",
      "2022-03-29 15:18:37,739 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "2022-03-29 15:18:37,743 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:37,745 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:37,747 - INFO - allennlp.common.params - training_data.dataset.name = Ontonotes 5.0\n",
      "2022-03-29 15:18:37,754 - INFO - allennlp.common.params - training_data.dataset.notes = We cannot release this data due to licensing restrictions.\n",
      "2022-03-29 15:18:37,755 - INFO - allennlp.common.params - training_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "2022-03-29 15:18:37,757 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:37,758 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:37,760 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = 86.49 test F1 on the Ontonotes 5.0 dataset\n",
      "2022-03-29 15:18:37,762 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:37,764 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:37,766 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:37,998 - INFO - allennlp.common.params - id = semparse-nlvr\n",
      "2022-03-29 15:18:38,000 - INFO - allennlp.common.params - registered_model_name = None\n",
      "2022-03-29 15:18:38,004 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:38,006 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:38,010 - INFO - allennlp.common.params - display_name = NLVR Semantic Parsing\n",
      "2022-03-29 15:18:38,013 - INFO - allennlp.common.params - task_id = semparse-nlvr\n",
      "2022-03-29 15:18:38,025 - INFO - allennlp.common.params - model_usage.archive_file = https://allennlp.s3.amazonaws.com/models/nlvr-erm-model-2020.02.10-rule-vocabulary-updated.tar.gz\n",
      "2022-03-29 15:18:38,030 - INFO - allennlp.common.params - model_usage.training_config = None\n",
      "2022-03-29 15:18:38,036 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-03-29 15:18:38,039 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:38,043 - INFO - allennlp.common.params - model_details.description = The model is a semantic parser trained on Cornell NLVR.\n",
      "2022-03-29 15:18:38,046 - INFO - allennlp.common.params - model_details.short_description = The model is a semantic parser trained on Cornell NLVR.\n",
      "2022-03-29 15:18:38,066 - INFO - allennlp.common.params - model_details.developed_by = Dasigi et al\n",
      "2022-03-29 15:18:38,069 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 15:18:38,095 - INFO - allennlp.common.params - model_details.date = None\n",
      "2022-03-29 15:18:38,102 - INFO - allennlp.common.params - model_details.version = None\n",
      "2022-03-29 15:18:38,140 - INFO - allennlp.common.params - model_details.model_type = None\n",
      "2022-03-29 15:18:38,142 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Dasigi2019IterativeSF,\n",
      "title={Iterative Search for Weakly Supervised Semantic Parsing},\n",
      "author={Pradeep Dasigi and Matt Gardner and Shikhar Murty and Luke Zettlemoyer and E. Hovy},\n",
      "booktitle={NAACL-HLT},\n",
      "year={2019}}\n",
      "\n",
      "2022-03-29 15:18:38,143 - INFO - allennlp.common.params - model_details.paper.title = Iterative Search for Weakly Supervised Semantic Parsing\n",
      "2022-03-29 15:18:38,144 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:174799945\n",
      "2022-03-29 15:18:38,202 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:38,204 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:38,210 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:38,215 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:38,218 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:38,231 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:38,239 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:38,244 - INFO - allennlp.common.params - metrics.model_performance_measures = Denotation accuracy and consistency\n",
      "2022-03-29 15:18:38,247 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:38,249 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:38,258 - INFO - allennlp.common.params - evaluation_data.dataset.name = Cornell NLVR\n",
      "2022-03-29 15:18:38,260 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-03-29 15:18:38,264 - INFO - allennlp.common.params - evaluation_data.dataset.url = http://lil.nlp.cornell.edu/nlvr/\n",
      "2022-03-29 15:18:38,267 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:38,270 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:38,273 - INFO - allennlp.common.params - training_data.dataset.name = Cornell NLVR\n",
      "2022-03-29 15:18:38,278 - INFO - allennlp.common.params - training_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-03-29 15:18:38,284 - INFO - allennlp.common.params - training_data.dataset.url = http://lil.nlp.cornell.edu/nlvr/\n",
      "2022-03-29 15:18:38,297 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:38,306 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:38,309 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 15:18:38,313 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:38,320 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:38,325 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:38,462 - INFO - allennlp.common.params - id = structured-prediction-biaffine-parser\n",
      "2022-03-29 15:18:38,465 - INFO - allennlp.common.params - registered_model_name = biaffine_parser\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:18:38,467 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:38,469 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:38,471 - INFO - allennlp.common.params - display_name = Deep Biaffine Attention for Neural Dependency Parsing\n",
      "2022-03-29 15:18:38,476 - INFO - allennlp.common.params - task_id = dependency-parsing\n",
      "2022-03-29 15:18:38,483 - INFO - allennlp.common.params - model_usage.archive_file = biaffine-dependency-parser-ptb-2020.04.06.tar.gz\n",
      "2022-03-29 15:18:38,487 - INFO - allennlp.common.params - model_usage.training_config = structured_prediction/dependency_parser.jsonnet\n",
      "2022-03-29 15:18:38,491 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 15:18:38,496 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:38,502 - INFO - allennlp.common.params - model_details.description = This dependency parser follows the model of [Deep Biaffine Attention for Neural Dependency Parsing (Dozat and Manning, 2016)](https://api.semanticscholar.org/CorpusID:7942973) .\n",
      "\n",
      "Word representations are generated using a bidirectional LSTM, followed by separate biaffine classifiers for pairs of words, predicting whether a directed arc exists between the two words and the dependency label the arc should have. Decoding can either be done greedily, or the optimal Minimum Spanning Tree can be decoded using Edmond's algorithm by viewing the dependency tree as a MST on a fully connected graph, where nodes are words and edges are scored dependency arcs.\n",
      "2022-03-29 15:18:38,504 - INFO - allennlp.common.params - model_details.short_description = A neural model for dependency parsing using biaffine classifiers on top of a bidirectional LSTM.\n",
      "2022-03-29 15:18:38,506 - INFO - allennlp.common.params - model_details.developed_by = Dozat et al\n",
      "2022-03-29 15:18:38,508 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 15:18:38,511 - INFO - allennlp.common.params - model_details.date = 2020-04-06\n",
      "2022-03-29 15:18:38,513 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:38,515 - INFO - allennlp.common.params - model_details.model_type = None\n",
      "2022-03-29 15:18:38,517 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Dozat2017DeepBA,\n",
      "title={Deep Biaffine Attention for Neural Dependency Parsing},\n",
      "author={Timothy Dozat and Christopher D. Manning},\n",
      "journal={ArXiv},\n",
      "year={2017},\n",
      "volume={abs/1611.01734}}\n",
      "\n",
      "2022-03-29 15:18:38,518 - INFO - allennlp.common.params - model_details.paper.title = Deep Biaffine Attention for Neural Dependency Parsing (Dozat and Manning, 2016)\n",
      "2022-03-29 15:18:38,520 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:7942973\n",
      "2022-03-29 15:18:38,521 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:38,523 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:38,524 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:38,525 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:38,526 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:38,529 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:38,530 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:38,533 - INFO - allennlp.common.params - metrics.model_performance_measures = Attachment scores and exact matches (UAS, LAS, UEM, LEM)\n",
      "2022-03-29 15:18:38,535 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:38,540 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:38,543 - INFO - allennlp.common.params - evaluation_data.dataset.name = PTB 3.0\n",
      "2022-03-29 15:18:38,546 - INFO - allennlp.common.params - evaluation_data.dataset.notes = The dependency parser was evaluated on the Penn Tree Bank dataset. Unfortunately we cannot release this data due to licensing restrictions by the LDC. You can download the PTB data from the LDC website.\n",
      "2022-03-29 15:18:38,548 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = /path/to/dataset\n",
      "2022-03-29 15:18:38,549 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://catalog.ldc.upenn.edu/LDC99T42\n",
      "2022-03-29 15:18:38,550 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:38,551 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:38,554 - INFO - allennlp.common.params - training_data.dataset.name = PTB 3.0\n",
      "2022-03-29 15:18:38,557 - INFO - allennlp.common.params - training_data.dataset.notes = The dependency parser was evaluated on the Penn Tree Bank dataset. Unfortunately we cannot release this data due to licensing restrictions by the LDC. You can download the PTB data from the LDC website.\n",
      "2022-03-29 15:18:38,561 - INFO - allennlp.common.params - training_data.dataset.processed_url = /path/to/dataset\n",
      "2022-03-29 15:18:38,563 - INFO - allennlp.common.params - training_data.dataset.url = https://catalog.ldc.upenn.edu/LDC99T42\n",
      "2022-03-29 15:18:38,564 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:38,567 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:38,573 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = The parser achieves 95.57% and 94.44% unlabeled and labeled attachement score using gold POS tags. For predicted POS tags, it achieves 94.81% UAS and 92.86% LAS respectively.\n",
      "2022-03-29 15:18:38,576 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:38,577 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:38,581 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:38,727 - INFO - allennlp.common.params - id = mc-roberta-swag\n",
      "2022-03-29 15:18:38,729 - INFO - allennlp.common.params - registered_model_name = transformer_mc\n",
      "2022-03-29 15:18:38,729 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:38,731 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:38,732 - INFO - allennlp.common.params - display_name = RoBERTa SWAG\n",
      "2022-03-29 15:18:38,733 - INFO - allennlp.common.params - task_id = mc\n",
      "2022-03-29 15:18:38,735 - INFO - allennlp.common.params - model_usage.archive_file = swag.2020-07-08.tar.gz\n",
      "2022-03-29 15:18:38,737 - INFO - allennlp.common.params - model_usage.training_config = mc/swag.jsonnet\n",
      "2022-03-29 15:18:38,740 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-03-29 15:18:38,744 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:38,746 - INFO - allennlp.common.params - model_details.description = This is a multiple choice model patterned after the BERT architecture. It calculates a score for each sequence on top of the CLS token, and then chooses the alternative with the highest score.\n",
      "2022-03-29 15:18:38,747 - INFO - allennlp.common.params - model_details.short_description = RoBERTa-based multiple choice model for SWAG.\n",
      "2022-03-29 15:18:38,749 - INFO - allennlp.common.params - model_details.developed_by = Devlin et al\n",
      "2022-03-29 15:18:38,750 - INFO - allennlp.common.params - model_details.contributed_by = Dirk Groeneveld\n",
      "2022-03-29 15:18:38,751 - INFO - allennlp.common.params - model_details.date = 2020-07-08\n",
      "2022-03-29 15:18:38,752 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:38,753 - INFO - allennlp.common.params - model_details.model_type = RoBERTa large\n",
      "2022-03-29 15:18:38,754 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and Luke Zettlemoyer and Veselin Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:18:38,757 - INFO - allennlp.common.params - model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al)\n",
      "2022-03-29 15:18:38,759 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "2022-03-29 15:18:38,766 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:38,770 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:38,780 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:38,783 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:38,794 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:38,809 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:38,822 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:38,824 - INFO - allennlp.common.params - metrics.model_performance_measures = The chosen metric is accuracy, since it is a multiple choice model.\n",
      "2022-03-29 15:18:38,835 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:38,839 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:38,844 - INFO - allennlp.common.params - evaluation_data.dataset.name = SWAG (validation set)\n",
      "2022-03-29 15:18:38,846 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-03-29 15:18:38,850 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://rowanzellers.com/swag/\n",
      "2022-03-29 15:18:38,857 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:38,879 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:38,894 - INFO - allennlp.common.params - training_data.dataset.name = SWAG (train set)\n",
      "2022-03-29 15:18:38,899 - INFO - allennlp.common.params - training_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-03-29 15:18:38,901 - INFO - allennlp.common.params - training_data.dataset.url = https://rowanzellers.com/swag/\n",
      "2022-03-29 15:18:38,903 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:38,905 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:38,911 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 15:18:38,913 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:38,928 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:38,937 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:39,108 - INFO - allennlp.common.params - id = lm-masked-language-model\n",
      "2022-03-29 15:18:39,109 - INFO - allennlp.common.params - registered_model_name = masked_language_model\n",
      "2022-03-29 15:18:39,110 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:39,111 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:39,117 - INFO - allennlp.common.params - display_name = BERT-based Masked Language Model\n",
      "2022-03-29 15:18:39,120 - INFO - allennlp.common.params - task_id = masked-language-modeling\n",
      "2022-03-29 15:18:39,124 - INFO - allennlp.common.params - model_usage.archive_file = bert-masked-lm-2020-10-07.tar.gz\n",
      "2022-03-29 15:18:39,127 - INFO - allennlp.common.params - model_usage.training_config = lm/bidirectional_language_model.jsonnet\n",
      "2022-03-29 15:18:39,131 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 15:18:39,163 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:39,167 - INFO - allennlp.common.params - model_details.description = The `MaskedLanguageModel` embeds some input tokens (including some which are masked), contextualizes them, then predicts targets for the masked tokens, computing a loss against known targets.\n",
      "2022-03-29 15:18:39,194 - INFO - allennlp.common.params - model_details.short_description = BERT-based masked language model\n",
      "2022-03-29 15:18:39,195 - INFO - allennlp.common.params - model_details.developed_by = Devlin et al\n",
      "2022-03-29 15:18:39,209 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 15:18:39,220 - INFO - allennlp.common.params - model_details.date = 2020-10-07\n",
      "2022-03-29 15:18:39,244 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:39,253 - INFO - allennlp.common.params - model_details.model_type = BERT\n",
      "2022-03-29 15:18:39,256 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Devlin2019BERTPO,\n",
      "title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},\n",
      "author={J. Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},\n",
      "booktitle={NAACL-HLT},\n",
      "year={2019}}\n",
      "\n",
      "2022-03-29 15:18:39,258 - INFO - allennlp.common.params - model_details.paper.title = BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\n",
      "2022-03-29 15:18:39,262 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:52967399\n",
      "2022-03-29 15:18:39,266 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:39,279 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:39,287 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:39,293 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:39,297 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:39,311 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:39,322 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:39,326 - INFO - allennlp.common.params - metrics.model_performance_measures = Perplexity\n",
      "2022-03-29 15:18:39,345 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:39,400 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:39,408 - INFO - allennlp.common.params - evaluation_data.dataset = BooksCorpus (800M words) and English Wikipedia (2,500M words).\n",
      "2022-03-29 15:18:39,412 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:39,427 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:39,433 - INFO - allennlp.common.params - training_data.dataset = BooksCorpus (800M words) and English Wikipedia (2,500M words).\n",
      "2022-03-29 15:18:39,457 - INFO - allennlp.common.params - training_data.motivation = Document-level corpus is used rather than shuffled sentence-level corpus, to extract long contiguous sequences.\n",
      "2022-03-29 15:18:39,458 - INFO - allennlp.common.params - training_data.preprocessing = For Wikipedia, text passages are extracted and lists, tables, and headers are ignored.\n",
      "2022-03-29 15:18:39,473 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 15:18:39,484 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:39,486 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = BERT demonstrates gender bias in that it thinks the doctor is more likely a man ('his') than a woman ('her'). An important issue in NLP is how to understand and address such biases in our linguistic models.\n",
      "2022-03-29 15:18:39,516 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = NOTE: This was developed for use in a demo, not for training.  It's possible that it will still work for training a masked LM, but it is very likely that some other code would be much more efficient for that.  This `does` compute correct gradients of the loss, because we use that in our demo, so in principle it should be able to train a model, we just don't necessarily endorse that use.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:18:39,700 - INFO - allennlp.common.params - id = roberta-sst\n",
      "2022-03-29 15:18:39,701 - INFO - allennlp.common.params - registered_model_name = None\n",
      "2022-03-29 15:18:39,708 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:39,718 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:39,719 - INFO - allennlp.common.params - display_name = RoBERTa large\n",
      "2022-03-29 15:18:39,727 - INFO - allennlp.common.params - task_id = sentiment-analysis\n",
      "2022-03-29 15:18:39,758 - INFO - allennlp.common.params - model_usage.archive_file = stanford-sentiment-treebank-roberta.2021-03-11.tar.gz\n",
      "2022-03-29 15:18:39,766 - INFO - allennlp.common.params - model_usage.training_config = classification/stanford_sentiment_treebank_roberta.jsonnet\n",
      "2022-03-29 15:18:39,790 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.4.0 allennlp-models==2.4.0\n",
      "2022-03-29 15:18:39,798 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:39,821 - INFO - allennlp.common.params - model_details.description = This model is trained on RoBERTa large with the binary classification setting of the Stanford Sentiment Treebank. It achieves 95.11% accuracy on the test set.\n",
      "2022-03-29 15:18:39,832 - INFO - allennlp.common.params - model_details.short_description = RoBERTa-based binary classifier for Stanford Sentiment Treebank\n",
      "2022-03-29 15:18:39,860 - INFO - allennlp.common.params - model_details.developed_by = Devlin et al\n",
      "2022-03-29 15:18:39,865 - INFO - allennlp.common.params - model_details.contributed_by = Zhaofeng Wu\n",
      "2022-03-29 15:18:39,867 - INFO - allennlp.common.params - model_details.date = 2020-06-08\n",
      "2022-03-29 15:18:39,876 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:39,879 - INFO - allennlp.common.params - model_details.model_type = RoBERTa large\n",
      "2022-03-29 15:18:39,895 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and Luke Zettlemoyer and Veselin Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n",
      "2022-03-29 15:18:39,917 - INFO - allennlp.common.params - model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al)\n",
      "2022-03-29 15:18:39,926 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "2022-03-29 15:18:39,929 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:39,932 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:39,949 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:39,958 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:39,959 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:39,963 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:39,965 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:39,977 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy\n",
      "2022-03-29 15:18:39,979 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:39,981 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:39,995 - INFO - allennlp.common.params - evaluation_data.dataset.name = Stanford Sentiment Treebank\n",
      "2022-03-29 15:18:39,998 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/sst/test.txt\n",
      "2022-03-29 15:18:39,999 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://nlp.stanford.edu/sentiment/treebank.html\n",
      "2022-03-29 15:18:40,001 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:40,004 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:40,011 - INFO - allennlp.common.params - training_data.dataset.name = Stanford Sentiment Treebank\n",
      "2022-03-29 15:18:40,012 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/sst/train.txt\n",
      "2022-03-29 15:18:40,012 - INFO - allennlp.common.params - training_data.dataset.url = https://nlp.stanford.edu/sentiment/treebank.html\n",
      "2022-03-29 15:18:40,014 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:40,017 - INFO - allennlp.common.params - training_data.preprocessing = Binary classification setting\n",
      "2022-03-29 15:18:40,024 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = Accuracy: 95.11% on SST test set.\n",
      "2022-03-29 15:18:40,028 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:40,034 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:40,047 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:40,249 - INFO - allennlp.common.params - id = lm-next-token-lm-gpt2\n",
      "2022-03-29 15:18:40,249 - INFO - allennlp.common.params - registered_model_name = next_token_lm\n",
      "2022-03-29 15:18:40,251 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:40,253 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:40,254 - INFO - allennlp.common.params - display_name = GPT2-based Next Token Language Model\n",
      "2022-03-29 15:18:40,260 - INFO - allennlp.common.params - task_id = language-modeling\n",
      "2022-03-29 15:18:40,264 - INFO - allennlp.common.params - model_usage.archive_file = gpt2-next-word-lm-2020.06.30.tar.gz\n",
      "2022-03-29 15:18:40,266 - INFO - allennlp.common.params - model_usage.training_config = None\n",
      "2022-03-29 15:18:40,268 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-03-29 15:18:40,270 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:40,272 - INFO - allennlp.common.params - model_details.description = This is the public 345M parameter OpenAI GPT-2 language model for generating sentences. The model embeds some input tokens, contextualizes them, then predicts the next word, computing a loss against known target. \n",
      "If `BeamSearch` is given, this model will predict a sequence of next tokens.\n",
      "2022-03-29 15:18:40,275 - INFO - allennlp.common.params - model_details.short_description = OpenAI's GPT-2 language model that generates the next token.\n",
      "2022-03-29 15:18:40,279 - INFO - allennlp.common.params - model_details.developed_by = Radford et al\n",
      "2022-03-29 15:18:40,282 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 15:18:40,286 - INFO - allennlp.common.params - model_details.date = 2020-06-30\n",
      "2022-03-29 15:18:40,289 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:40,291 - INFO - allennlp.common.params - model_details.model_type = GPT2\n",
      "2022-03-29 15:18:40,293 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Radford2019LanguageMA,\n",
      "title={Language Models are Unsupervised Multitask Learners},\n",
      "author={A. Radford and Jeffrey Wu and R. Child and David Luan and Dario Amodei and Ilya Sutskever},\n",
      "year={2019}}\n",
      "\n",
      "2022-03-29 15:18:40,297 - INFO - allennlp.common.params - model_details.paper.title = Language Models are Unsupervised Multitask Learners\n",
      "2022-03-29 15:18:40,298 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:160025533\n",
      "2022-03-29 15:18:40,301 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:40,304 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:40,306 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:40,309 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:40,314 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:18:40,316 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:40,319 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:40,321 - INFO - allennlp.common.params - metrics.model_performance_measures = Perplexity\n",
      "2022-03-29 15:18:40,323 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:40,325 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:40,330 - INFO - allennlp.common.params - evaluation_data.dataset.name = WebText corpus\n",
      "2022-03-29 15:18:40,332 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://github.com/openai/gpt-2-output-dataset\n",
      "2022-03-29 15:18:40,334 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:40,336 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:40,339 - INFO - allennlp.common.params - training_data.dataset.name = WebText corpus\n",
      "2022-03-29 15:18:40,342 - INFO - allennlp.common.params - training_data.dataset.url = https://github.com/openai/gpt-2-output-dataset\n",
      "2022-03-29 15:18:40,343 - INFO - allennlp.common.params - training_data.motivation = WebText emphasizes document quality. Only human-curated/filtered documents are scraped. Reddit outbound links which receive at least 3 karma points are taken as a proxy for human filtered webpages that are interesting.\n",
      "2022-03-29 15:18:40,346 - INFO - allennlp.common.params - training_data.preprocessing = Dragnet and [Newspaper](https://github.com/codelucas/newspaper) content extractors are used. Wikipedia articles are removed.\n",
      "2022-03-29 15:18:40,350 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 15:18:40,351 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:40,353 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:40,355 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:40,520 - INFO - allennlp.common.params - id = coref-spanbert\n",
      "2022-03-29 15:18:40,522 - INFO - allennlp.common.params - registered_model_name = coref\n",
      "2022-03-29 15:18:40,523 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:40,525 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:40,527 - INFO - allennlp.common.params - display_name = Coreference Resolution\n",
      "2022-03-29 15:18:40,529 - INFO - allennlp.common.params - task_id = coref\n",
      "2022-03-29 15:18:40,533 - INFO - allennlp.common.params - model_usage.archive_file = coref-spanbert-large-2021.03.10.tar.gz\n",
      "2022-03-29 15:18:40,536 - INFO - allennlp.common.params - model_usage.training_config = coref/coref_spanbert_large.jsonnet\n",
      "2022-03-29 15:18:40,546 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 15:18:40,550 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:40,555 - INFO - allennlp.common.params - model_details.description = The basic outline of this model is to get an embedded representation of each span in the document. These span representations are scored  and used to prune away spans that are unlikely to occur in a coreference  cluster. For the remaining spans, the model decides which antecedent span (if any) they are coreferent with. The resulting coreference links, after applying transitivity, imply a clustering of the spans in the document. The GloVe embeddings in the original paper have been substituted with SpanBERT embeddings.\n",
      "2022-03-29 15:18:40,558 - INFO - allennlp.common.params - model_details.short_description = Higher-order coref with coarse-to-fine inference (with SpanBERT embeddings).\n",
      "2022-03-29 15:18:40,562 - INFO - allennlp.common.params - model_details.developed_by = Lee et al\n",
      "2022-03-29 15:18:40,566 - INFO - allennlp.common.params - model_details.contributed_by = Zhaofeng Wu\n",
      "2022-03-29 15:18:40,580 - INFO - allennlp.common.params - model_details.date = 2020-02-27\n",
      "2022-03-29 15:18:40,582 - INFO - allennlp.common.params - model_details.version = 2\n",
      "2022-03-29 15:18:40,586 - INFO - allennlp.common.params - model_details.model_type = SpanBERT\n",
      "2022-03-29 15:18:40,588 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Lee2018HigherorderCR,\n",
      "title={Higher-order Coreference Resolution with Coarse-to-fine Inference},\n",
      "author={Kenton Lee and Luheng He and L. Zettlemoyer},\n",
      "booktitle={NAACL-HLT},\n",
      "year={2018}}\n",
      "\n",
      "2022-03-29 15:18:40,590 - INFO - allennlp.common.params - model_details.paper.title = Higher-order Coreference Resolution with Coarse-to-fine Inference\n",
      "2022-03-29 15:18:40,592 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:4891749\n",
      "2022-03-29 15:18:40,594 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:40,595 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:40,603 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:40,610 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:40,612 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:40,615 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:40,616 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:40,624 - INFO - allennlp.common.params - metrics.model_performance_measures = CoNLL coref scores and Mention Recall\n",
      "2022-03-29 15:18:40,627 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:40,633 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:40,639 - INFO - allennlp.common.params - evaluation_data.dataset.name = Ontonotes 5.0\n",
      "2022-03-29 15:18:40,648 - INFO - allennlp.common.params - evaluation_data.dataset.notes = The Coreference model was evaluated on the CoNLL 2012 dataset. Unfortunately we cannot release this data due to licensing restrictions by the LDC. To compile the data in the right format for evaluating the Coreference model, please see scripts/compile_coref_data.sh. This script requires the Ontonotes 5.0 dataset, available on the LDC website.\n",
      "2022-03-29 15:18:40,649 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = /path/to/dataset\n",
      "2022-03-29 15:18:40,651 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "2022-03-29 15:18:40,654 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:40,656 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:40,664 - INFO - allennlp.common.params - training_data.dataset.name = Ontonotes 5.0\n",
      "2022-03-29 15:18:40,666 - INFO - allennlp.common.params - training_data.dataset.notes = The Coreference model was evaluated on the CoNLL 2012 dataset. Unfortunately we cannot release this data due to licensing restrictions by the LDC. To compile the data in the right format for evaluating the Coreference model, please see scripts/compile_coref_data.sh. This script requires the Ontonotes 5.0 dataset, available on the LDC website.\n",
      "2022-03-29 15:18:40,667 - INFO - allennlp.common.params - training_data.dataset.processed_url = /path/to/dataset\n",
      "2022-03-29 15:18:40,678 - INFO - allennlp.common.params - training_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "2022-03-29 15:18:40,681 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:40,683 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:40,713 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 15:18:40,718 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:40,726 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:40,730 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:18:40,846 - INFO - allennlp.common.params - id = rc-bidaf-elmo\n",
      "2022-03-29 15:18:40,847 - INFO - allennlp.common.params - registered_model_name = bidaf\n",
      "2022-03-29 15:18:40,849 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:40,851 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:40,860 - INFO - allennlp.common.params - display_name = ELMo-BiDAF\n",
      "2022-03-29 15:18:40,864 - INFO - allennlp.common.params - task_id = rc\n",
      "2022-03-29 15:18:40,885 - INFO - allennlp.common.params - model_usage.archive_file = bidaf-elmo.2021-02-11.tar.gz\n",
      "2022-03-29 15:18:40,894 - INFO - allennlp.common.params - model_usage.training_config = rc/bidaf_elmo.jsonnet\n",
      "2022-03-29 15:18:40,903 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 15:18:40,907 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:40,912 - INFO - allennlp.common.params - model_details.description = This is an implementation of the BiDAF model with ELMo embeddings. The basic layout is pretty simple: encode words as a combination of word embeddings and a character-level encoder, pass the word representations through a bi-LSTM/GRU, use a matrix of attentions to put question information into the passage word representations (this is the only part that is at all non-standard), pass this through another few layers of bi-LSTMs/GRUs, and do a softmax over span start and span end.\n",
      "2022-03-29 15:18:40,916 - INFO - allennlp.common.params - model_details.short_description = BiDAF model with ELMo embeddings instead of GloVe.\n",
      "2022-03-29 15:18:40,922 - INFO - allennlp.common.params - model_details.developed_by = Seo et al\n",
      "2022-03-29 15:18:40,926 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 15:18:40,930 - INFO - allennlp.common.params - model_details.date = 2020-03-19\n",
      "2022-03-29 15:18:40,933 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:40,937 - INFO - allennlp.common.params - model_details.model_type = BiDAF\n",
      "2022-03-29 15:18:40,940 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Seo2017BidirectionalAF,\n",
      "title={Bidirectional Attention Flow for Machine Comprehension},\n",
      "author={Minjoon Seo and Aniruddha Kembhavi and Ali Farhadi and Hannaneh Hajishirzi},\n",
      "journal={ArXiv},\n",
      "year={2017},\n",
      "volume={abs/1611.01603}}\n",
      "\n",
      "2022-03-29 15:18:40,948 - INFO - allennlp.common.params - model_details.paper.title = Bidirectional Attention Flow for Machine Comprehension\n",
      "2022-03-29 15:18:40,953 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:8535316\n",
      "2022-03-29 15:18:40,955 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:40,959 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:40,962 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:40,965 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:40,970 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:40,972 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:40,977 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:41,015 - INFO - allennlp.common.params - metrics.model_performance_measures = Start, end and overall span accuracy, Exact Match, F1 score\n",
      "2022-03-29 15:18:41,072 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:41,074 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:41,077 - INFO - allennlp.common.params - evaluation_data.dataset.name = SQuAD dev set\n",
      "2022-03-29 15:18:41,081 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/squad/squad-dev-v1.1.json\n",
      "2022-03-29 15:18:41,086 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://rajpurkar.github.io/SQuAD-explorer/explore/1.1/dev/\n",
      "2022-03-29 15:18:41,088 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:41,091 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:41,101 - INFO - allennlp.common.params - training_data.dataset.name = SQuAD training set\n",
      "2022-03-29 15:18:41,104 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/squad/squad-train-v1.1.json\n",
      "2022-03-29 15:18:41,106 - INFO - allennlp.common.params - training_data.dataset.url = https://rajpurkar.github.io/SQuAD-explorer/explore/1.1/dev/\n",
      "2022-03-29 15:18:41,109 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:41,112 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:41,114 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = On the validation set:\n",
      "Start accuracy: 66%\n",
      "End accuracy: 69%\n",
      "Overall span accuracy: 57%\n",
      "Exact match: 71%\n",
      "F1: 80%\n",
      "2022-03-29 15:18:41,116 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:41,120 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:41,125 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = This model is based on ELMo. ELMo is not deterministic, meaning that you will see slight differences every time you run it. Also, ELMo likes to be warmed up, so we recommend processing dummy input before processing real workloads with it.\n",
      "2022-03-29 15:18:41,283 - INFO - allennlp.common.params - id = tagging-elmo-crf-tagger\n",
      "2022-03-29 15:18:41,288 - INFO - allennlp.common.params - registered_model_name = crf_tagger\n",
      "2022-03-29 15:18:41,290 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:41,292 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:41,296 - INFO - allennlp.common.params - display_name = ELMo-based Named Entity Recognition\n",
      "2022-03-29 15:18:41,299 - INFO - allennlp.common.params - task_id = ner\n",
      "2022-03-29 15:18:41,303 - INFO - allennlp.common.params - model_usage.archive_file = ner-elmo.2021-02-12.tar.gz\n",
      "2022-03-29 15:18:41,306 - INFO - allennlp.common.params - model_usage.training_config = tagging/ner_elmo.jsonnet\n",
      "2022-03-29 15:18:41,308 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 15:18:41,311 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:41,314 - INFO - allennlp.common.params - model_details.description = This model is the baseline model described in [Semi-supervised sequence tagging with bidirectional language models](https://api.semanticscholar.org/CorpusID:7197241). It uses a Gated Recurrent Unit (GRU) character encoder as well as a GRU phrase encoder, and it starts with pretrained GloVe vectors for its token embeddings. It was trained on the CoNLL-2003 NER dataset.\n",
      "2022-03-29 15:18:41,317 - INFO - allennlp.common.params - model_details.short_description = NER tagger using a Gated Recurrent Unit (GRU) character encoder as well as a GRU phrase encoder, with GloVe embeddings.\n",
      "2022-03-29 15:18:41,319 - INFO - allennlp.common.params - model_details.developed_by = Peters et al\n",
      "2022-03-29 15:18:41,323 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 15:18:41,327 - INFO - allennlp.common.params - model_details.date = 2020-02-10\n",
      "2022-03-29 15:18:41,330 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:41,334 - INFO - allennlp.common.params - model_details.model_type = Gated Recurrent Unit (GRU)\n",
      "2022-03-29 15:18:41,336 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Peters2017SemisupervisedST,\n",
      "title={Semi-supervised sequence tagging with bidirectional language models},\n",
      "author={Matthew E. Peters and Waleed Ammar and Chandra Bhagavatula and R. Power},\n",
      "booktitle={ACL},\n",
      "year={2017}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:18:41,339 - INFO - allennlp.common.params - model_details.paper.title = Semi-supervised sequence tagging with bidirectional language models\n",
      "2022-03-29 15:18:41,341 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:7197241\n",
      "2022-03-29 15:18:41,345 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:41,349 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:41,353 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:41,355 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:41,358 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:41,362 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:41,364 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:41,369 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy and Span-based F1 metric\n",
      "2022-03-29 15:18:41,372 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:41,376 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:41,378 - INFO - allennlp.common.params - evaluation_data.dataset.name = CoNLL-2003 NER dataset\n",
      "2022-03-29 15:18:41,384 - INFO - allennlp.common.params - evaluation_data.dataset.notes = The NER model was evaluated on the CoNLL-2003 NER dataset. Unfortunately we cannot release this data due to licensing restrictions.\n",
      "2022-03-29 15:18:41,387 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = path/to/dataset\n",
      "2022-03-29 15:18:41,395 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://www.clips.uantwerpen.be/conll2003/ner/\n",
      "2022-03-29 15:18:41,401 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:41,405 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:41,410 - INFO - allennlp.common.params - training_data.dataset.name = CoNLL-2003 NER dataset\n",
      "2022-03-29 15:18:41,419 - INFO - allennlp.common.params - training_data.dataset.notes = The NER model was trained on the CoNLL-2003 NER dataset. Unfortunately we cannot release this data due to licensing restrictions.\n",
      "2022-03-29 15:18:41,421 - INFO - allennlp.common.params - training_data.dataset.processed_url = /path/to/dataset\n",
      "2022-03-29 15:18:41,425 - INFO - allennlp.common.params - training_data.dataset.url = https://www.clips.uantwerpen.be/conll2003/ner/\n",
      "2022-03-29 15:18:41,428 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:41,432 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:41,439 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = Achieves 99% accuracy and 96% F1 on the CoNLL-2003 validation set.\n",
      "2022-03-29 15:18:41,445 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:41,448 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:41,452 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = This model is based on ELMo. ELMo is not deterministic, meaning that you will see slight differences every time you run it. Also, ELMo likes to be warmed up, so we recommend processing dummy input before processing real workloads with it.\n",
      "2022-03-29 15:18:41,607 - INFO - allennlp.common.params - id = semparse-text-to-sql\n",
      "2022-03-29 15:18:41,609 - INFO - allennlp.common.params - registered_model_name = None\n",
      "2022-03-29 15:18:41,616 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:41,626 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:41,644 - INFO - allennlp.common.params - display_name = Text to SQL (ATIS)\n",
      "2022-03-29 15:18:41,650 - INFO - allennlp.common.params - task_id = semparse-text-to-sql\n",
      "2022-03-29 15:18:41,665 - INFO - allennlp.common.params - model_usage.archive_file = https://allennlp.s3.amazonaws.com/models/atis-parser-2020.02.10.tar.gz\n",
      "2022-03-29 15:18:41,673 - INFO - allennlp.common.params - model_usage.training_config = None\n",
      "2022-03-29 15:18:41,682 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-03-29 15:18:41,688 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:41,699 - INFO - allennlp.common.params - model_details.description = This model is an implementation of an encoder-decoder architecture with LSTMs and constrained type decoding trained on the ATIS dataset. This model is still a proof-of-concept of what you can do with semantic parsing in AllenNLP and its performance is not state-of-the-art (this naive model gets around 40% exact denotation accuracy on the contextual ATIS dataset).\n",
      "2022-03-29 15:18:41,704 - INFO - allennlp.common.params - model_details.short_description = This model is an implementation of an encoder-decoder architecture with LSTMs and constrained type decoding trained on the ATIS dataset.\n",
      "2022-03-29 15:18:41,713 - INFO - allennlp.common.params - model_details.developed_by = Dasigi et al\n",
      "2022-03-29 15:18:41,728 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 15:18:41,739 - INFO - allennlp.common.params - model_details.date = 2020-02-10\n",
      "2022-03-29 15:18:41,751 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:41,755 - INFO - allennlp.common.params - model_details.model_type = None\n",
      "2022-03-29 15:18:41,758 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Dasigi2019IterativeSF,\n",
      "title={Iterative Search for Weakly Supervised Semantic Parsing},\n",
      "author={Pradeep Dasigi and Matt Gardner and Shikhar Murty and Luke Zettlemoyer and E. Hovy},\n",
      "booktitle={NAACL-HLT},\n",
      "year={2019}}\n",
      "\n",
      "2022-03-29 15:18:41,782 - INFO - allennlp.common.params - model_details.paper.title = Iterative Search for Weakly Supervised Semantic Parsing\n",
      "2022-03-29 15:18:41,810 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:174799945\n",
      "2022-03-29 15:18:41,814 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:41,821 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:41,826 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:41,829 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:41,832 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:41,837 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:41,840 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:41,846 - INFO - allennlp.common.params - metrics.model_performance_measures = 1. `exact_match`; the percentage of the time that our best output action sequence matches the SQL query exactly.\n",
      "2. `denotation_acc`; the percentage of examples where we get the correct denotation.\n",
      "3. `valid_sql_query`; the percentage of time that decoding actually produces avalid SQL query.\n",
      "4. `action_similarity`; how similar the action sequence predicted is to the actual action sequence.\n",
      "2022-03-29 15:18:41,852 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:41,854 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:41,870 - INFO - allennlp.common.params - evaluation_data.dataset.name = ATIS\n",
      "2022-03-29 15:18:41,875 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-03-29 15:18:41,891 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://api.semanticscholar.org/CorpusID:1094063\n",
      "2022-03-29 15:18:41,895 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:41,897 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:41,899 - INFO - allennlp.common.params - training_data.dataset.name = ATIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:18:41,901 - INFO - allennlp.common.params - training_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-03-29 15:18:41,917 - INFO - allennlp.common.params - training_data.dataset.url = https://api.semanticscholar.org/CorpusID:1094063\n",
      "2022-03-29 15:18:41,924 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:41,926 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:41,931 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 15:18:41,944 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:41,948 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:41,960 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:42,064 - INFO - allennlp.common.params - id = nlvr2-vilbert\n",
      "2022-03-29 15:18:42,065 - INFO - allennlp.common.params - registered_model_name = nlvr2\n",
      "2022-03-29 15:18:42,071 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:42,081 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:42,090 - INFO - allennlp.common.params - display_name = Visual Entailment - NLVR2\n",
      "2022-03-29 15:18:42,099 - INFO - allennlp.common.params - task_id = nlvr2\n",
      "2022-03-29 15:18:42,107 - INFO - allennlp.common.params - model_usage.archive_file = vilbert-nlvr2-head-2021.06.01.tar.gz\n",
      "2022-03-29 15:18:42,111 - INFO - allennlp.common.params - model_usage.training_config = vilbert_nlvr2_pretrained.jsonnet\n",
      "2022-03-29 15:18:42,115 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp>=2.5.1 allennlp-models>=2.5.1\n",
      "2022-03-29 15:18:42,117 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:42,120 - INFO - allennlp.common.params - model_details.description = This model uses a VilBERT-based backbone with an NLVR2-specific model head. The image features are obtained using the ResNet backbone and Faster RCNN (region detection).\n",
      "2022-03-29 15:18:42,123 - INFO - allennlp.common.params - model_details.short_description = ViLBERT-based model for Visual Entailment.\n",
      "2022-03-29 15:18:42,124 - INFO - allennlp.common.params - model_details.developed_by = Lu et al\n",
      "2022-03-29 15:18:42,131 - INFO - allennlp.common.params - model_details.contributed_by = Jacob Morrison\n",
      "2022-03-29 15:18:42,133 - INFO - allennlp.common.params - model_details.date = 2021-05-27\n",
      "2022-03-29 15:18:42,142 - INFO - allennlp.common.params - model_details.version = 2\n",
      "2022-03-29 15:18:42,155 - INFO - allennlp.common.params - model_details.model_type = ViLBERT based on BERT large\n",
      "2022-03-29 15:18:42,157 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Lu2019ViLBERTPT,\n",
      "title={ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks},\n",
      "author={Jiasen Lu and Dhruv Batra and D. Parikh and Stefan Lee},\n",
      "booktitle={NeurIPS},\n",
      "year={2019}\n",
      "2022-03-29 15:18:42,166 - INFO - allennlp.common.params - model_details.paper.title = ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks\n",
      "2022-03-29 15:18:42,177 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:199453025\n",
      "2022-03-29 15:18:42,196 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:42,202 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:42,209 - INFO - allennlp.common.params - intended_use.primary_uses = This model is developed for the AllenNLP demo.\n",
      "2022-03-29 15:18:42,213 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:42,222 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:42,228 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:42,252 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:42,263 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy and F1-score\n",
      "2022-03-29 15:18:42,275 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:42,287 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:42,295 - INFO - allennlp.common.params - evaluation_data.dataset.name = Natural Language for Visual Reasoning For Real dev set\n",
      "2022-03-29 15:18:42,306 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Evaluation requires a large amount of images to be accessible locally, so we cannot provide a command you can easily copy and paste.\n",
      "2022-03-29 15:18:42,312 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://github.com/lil-lab/nlvr/tree/master/nlvr2\n",
      "2022-03-29 15:18:42,326 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:42,330 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:42,343 - INFO - allennlp.common.params - training_data.dataset.name = Natural Language for Visual Reasoning For Real train set\n",
      "2022-03-29 15:18:42,353 - INFO - allennlp.common.params - training_data.dataset.url = https://github.com/lil-lab/nlvr/tree/master/nlvr2\n",
      "2022-03-29 15:18:42,361 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:42,374 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:42,376 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = On the validation set:\n",
      "F1: 33.7%\n",
      "Accuracy: 50.8%.\n",
      "These scores do not match the performance in the 12-in-1 paper because this was trained as a standalone task, not as part of a multitask setup. Please contact us if you want to match those scores!\n",
      "2022-03-29 15:18:42,382 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:42,391 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:42,396 - INFO - allennlp.common.params - model_caveats_and_recommendations = None\n",
      "2022-03-29 15:18:42,505 - INFO - allennlp.common.params - id = rc-bidaf\n",
      "2022-03-29 15:18:42,507 - INFO - allennlp.common.params - registered_model_name = bidaf\n",
      "2022-03-29 15:18:42,509 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:42,516 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:42,517 - INFO - allennlp.common.params - display_name = BiDAF\n",
      "2022-03-29 15:18:42,519 - INFO - allennlp.common.params - task_id = rc\n",
      "2022-03-29 15:18:42,522 - INFO - allennlp.common.params - model_usage.archive_file = bidaf-model-2020.03.19.tar.gz\n",
      "2022-03-29 15:18:42,528 - INFO - allennlp.common.params - model_usage.training_config = rc/bidaf.jsonnet\n",
      "2022-03-29 15:18:42,533 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 15:18:42,539 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:42,542 - INFO - allennlp.common.params - model_details.description = This is an implementation of the BiDAF model with GloVe embeddings. The basic layout is pretty simple: encode words as a combination of word embeddings and a character-level encoder, pass the word representations through a bi-LSTM/GRU, use a matrix of attentions to put question information into the passage word representations (this is the only part that is at all non-standard), pass this through another few layers of bi-LSTMs/GRUs, and do a softmax over span start and span end.\n",
      "2022-03-29 15:18:42,551 - INFO - allennlp.common.params - model_details.short_description = BiDAF model with GloVe embeddings.\n",
      "2022-03-29 15:18:42,554 - INFO - allennlp.common.params - model_details.developed_by = Seo et al\n",
      "2022-03-29 15:18:42,560 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 15:18:42,563 - INFO - allennlp.common.params - model_details.date = 2020-03-19\n",
      "2022-03-29 15:18:42,570 - INFO - allennlp.common.params - model_details.version = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:18:42,572 - INFO - allennlp.common.params - model_details.model_type = BiDAF\n",
      "2022-03-29 15:18:42,575 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Seo2017BidirectionalAF,\n",
      "title={Bidirectional Attention Flow for Machine Comprehension},\n",
      "author={Minjoon Seo and Aniruddha Kembhavi and Ali Farhadi and Hannaneh Hajishirzi},\n",
      "journal={ArXiv},\n",
      "year={2017},\n",
      "volume={abs/1611.01603}}\n",
      "\n",
      "2022-03-29 15:18:42,577 - INFO - allennlp.common.params - model_details.paper.title = Bidirectional Attention Flow for Machine Comprehension\n",
      "2022-03-29 15:18:42,582 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:8535316\n",
      "2022-03-29 15:18:42,588 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:42,597 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:42,600 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:42,604 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:42,607 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:42,613 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:42,618 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:42,623 - INFO - allennlp.common.params - metrics.model_performance_measures = Start, end, and overall span accuracy, Exact Match, F1 score\n",
      "2022-03-29 15:18:42,627 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:42,636 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:42,640 - INFO - allennlp.common.params - evaluation_data.dataset.name = SQuAD dev set\n",
      "2022-03-29 15:18:42,644 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/squad/squad-dev-v1.1.json\n",
      "2022-03-29 15:18:42,650 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://rajpurkar.github.io/SQuAD-explorer/explore/1.1/dev/\n",
      "2022-03-29 15:18:42,653 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:42,655 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:42,657 - INFO - allennlp.common.params - training_data.dataset.name = SQuAD training set\n",
      "2022-03-29 15:18:42,659 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/squad/squad-train-v1.1.json\n",
      "2022-03-29 15:18:42,660 - INFO - allennlp.common.params - training_data.dataset.url = https://rajpurkar.github.io/SQuAD-explorer/explore/1.1/dev/\n",
      "2022-03-29 15:18:42,664 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:42,666 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:42,669 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = On the validation set:\n",
      "Start accuracy: 61%\n",
      "End accuracy: 66%\n",
      "Overall span accuracy: 52%\n",
      "Exact match: 66%\n",
      "F1: 76%\n",
      "2022-03-29 15:18:42,677 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:42,682 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:42,687 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:42,865 - INFO - allennlp.common.params - id = vqa-vilbert\n",
      "2022-03-29 15:18:42,870 - INFO - allennlp.common.params - registered_model_name = vqa_vilbert\n",
      "2022-03-29 15:18:42,876 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:42,879 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:42,895 - INFO - allennlp.common.params - display_name = ViLBERT - Visual Question Answering\n",
      "2022-03-29 15:18:42,899 - INFO - allennlp.common.params - task_id = vqa\n",
      "2022-03-29 15:18:42,902 - INFO - allennlp.common.params - model_usage.archive_file = vilbert-vqa-pretrained.2021-03-15.tar.gz\n",
      "2022-03-29 15:18:42,927 - INFO - allennlp.common.params - model_usage.training_config = vision/vilbert_vqa_pretrained.jsonnet\n",
      "2022-03-29 15:18:42,934 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 15:18:42,947 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:42,959 - INFO - allennlp.common.params - model_details.description = ViLBERT (short for Vision-and-Language BERT), is a model for learning task-agnostic joint representations of image content and natural language.\n",
      "2022-03-29 15:18:42,967 - INFO - allennlp.common.params - model_details.short_description = ViLBERT (short for Vision-and-Language BERT), is a model for learning task-agnostic joint representations of image content and natural language.\n",
      "2022-03-29 15:18:42,974 - INFO - allennlp.common.params - model_details.developed_by = Lu et al\n",
      "2022-03-29 15:18:42,983 - INFO - allennlp.common.params - model_details.contributed_by = Dirk Groeneveld\n",
      "2022-03-29 15:18:42,991 - INFO - allennlp.common.params - model_details.date = 2021-03-15\n",
      "2022-03-29 15:18:42,997 - INFO - allennlp.common.params - model_details.version = 2\n",
      "2022-03-29 15:18:43,002 - INFO - allennlp.common.params - model_details.model_type = ViLBERT based on BERT large\n",
      "2022-03-29 15:18:43,007 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Lu2019ViLBERTPT,\n",
      "title={ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks},\n",
      "author={Jiasen Lu and Dhruv Batra and D. Parikh and Stefan Lee},\n",
      "booktitle={NeurIPS},\n",
      "year={2019}\n",
      "}\n",
      "2022-03-29 15:18:43,012 - INFO - allennlp.common.params - model_details.paper.title = ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks\n",
      "2022-03-29 15:18:43,017 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:199453025\n",
      "2022-03-29 15:18:43,020 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:43,022 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:43,024 - INFO - allennlp.common.params - intended_use.primary_uses = This model is developed for the AllenNLP demo.\n",
      "2022-03-29 15:18:43,026 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:43,028 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:43,030 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:43,031 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:43,033 - INFO - allennlp.common.params - metrics.model_performance_measures = F1-metric and VQA score\n",
      "2022-03-29 15:18:43,042 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:43,045 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:43,048 - INFO - allennlp.common.params - evaluation_data.dataset.name = VQA dataset\n",
      "2022-03-29 15:18:43,049 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Evaluation requires a large amount of images to be accessible locally, so we cannot provide a command you can easily copy and paste. The first time you run it, you will get an error message that tells you how to get the rest of the data.\n",
      "2022-03-29 15:18:43,052 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = balanced_real_val\n",
      "2022-03-29 15:18:43,056 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://visualqa.org/\n",
      "2022-03-29 15:18:43,060 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:43,062 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:43,064 - INFO - allennlp.common.params - training_data.dataset.name = VQA dataset\n",
      "2022-03-29 15:18:43,065 - INFO - allennlp.common.params - training_data.dataset.notes = Training requires a large amount of images to be accessible locally, so we cannot provide a command you can easily copy and paste. The first time you run it, you will get an error message that tells you how to get the rest of the data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:18:43,067 - INFO - allennlp.common.params - training_data.dataset.processed_url = balanced_real_train\n",
      "2022-03-29 15:18:43,072 - INFO - allennlp.common.params - training_data.dataset.url = https://visualqa.org/\n",
      "2022-03-29 15:18:43,075 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:43,076 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:43,078 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = On the validation set:\n",
      "F1: 40%\n",
      "VQA: 54%.\n",
      "These scores do not match the performance in the VilBERT paper. Please contact us if you want to match those scores!\n",
      "2022-03-29 15:18:43,079 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:43,083 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:43,091 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:43,245 - INFO - allennlp.common.params - id = semparse-wikitables\n",
      "2022-03-29 15:18:43,246 - INFO - allennlp.common.params - registered_model_name = None\n",
      "2022-03-29 15:18:43,246 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:43,247 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:43,249 - INFO - allennlp.common.params - display_name = WikiTables Semantic Parsing\n",
      "2022-03-29 15:18:43,252 - INFO - allennlp.common.params - task_id = semparse-tabular\n",
      "2022-03-29 15:18:43,257 - INFO - allennlp.common.params - model_usage.archive_file = wikitables-model-2020.02.10.tar.gz\n",
      "2022-03-29 15:18:43,259 - INFO - allennlp.common.params - model_usage.training_config = None\n",
      "2022-03-29 15:18:43,262 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-03-29 15:18:43,271 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:43,289 - INFO - allennlp.common.params - model_details.description = The model is a semantic parser trained on WikiTableQuestions.\n",
      "2022-03-29 15:18:43,292 - INFO - allennlp.common.params - model_details.short_description = The model is a semantic parser trained on WikiTableQuestions.\n",
      "2022-03-29 15:18:43,298 - INFO - allennlp.common.params - model_details.developed_by = Dasigi et al\n",
      "2022-03-29 15:18:43,313 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 15:18:43,322 - INFO - allennlp.common.params - model_details.date = 2020-02-10\n",
      "2022-03-29 15:18:43,331 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:43,344 - INFO - allennlp.common.params - model_details.model_type = None\n",
      "2022-03-29 15:18:43,346 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Dasigi2019IterativeSF,\n",
      "title={Iterative Search for Weakly Supervised Semantic Parsing},\n",
      "author={Pradeep Dasigi and Matt Gardner and Shikhar Murty and Luke Zettlemoyer and E. Hovy},\n",
      "booktitle={NAACL-HLT},\n",
      "year={2019}}\n",
      "\n",
      "2022-03-29 15:18:43,350 - INFO - allennlp.common.params - model_details.paper.title = Iterative Search for Weakly Supervised Semantic Parsing\n",
      "2022-03-29 15:18:43,354 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:174799945\n",
      "2022-03-29 15:18:43,359 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:43,362 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:43,374 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:43,381 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:43,386 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:43,391 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:43,394 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:43,399 - INFO - allennlp.common.params - metrics.model_performance_measures = 1. `lf_retrieval_acc`; the percentage of the time that our best output action sequence is in the set of action sequences provided by offline search.\n",
      "2. `denotation_acc`; the percentage of examples where we get the correct denotation.\n",
      "3. `lf_percent`; the percentage of time that decoding actually produces a finished logical form\n",
      "2022-03-29 15:18:43,405 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:43,409 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:43,422 - INFO - allennlp.common.params - evaluation_data.dataset.name = WikiTableQuestions\n",
      "2022-03-29 15:18:43,437 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-03-29 15:18:43,445 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://ppasupat.github.io/WikiTableQuestions/\n",
      "2022-03-29 15:18:43,450 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:43,458 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:43,463 - INFO - allennlp.common.params - training_data.dataset.name = WikiTableQuestions\n",
      "2022-03-29 15:18:43,467 - INFO - allennlp.common.params - training_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-03-29 15:18:43,469 - INFO - allennlp.common.params - training_data.dataset.url = https://ppasupat.github.io/WikiTableQuestions/\n",
      "2022-03-29 15:18:43,471 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:43,473 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:43,476 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 15:18:43,480 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:43,483 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:43,485 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:43,616 - INFO - allennlp.common.params - id = generation-bart\n",
      "2022-03-29 15:18:43,622 - INFO - allennlp.common.params - registered_model_name = bart\n",
      "2022-03-29 15:18:43,626 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:43,628 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:43,630 - INFO - allennlp.common.params - display_name = BART\n",
      "2022-03-29 15:18:43,640 - INFO - allennlp.common.params - task_id = None\n",
      "2022-03-29 15:18:43,663 - INFO - allennlp.common.params - model_usage.archive_file = bart-2020.07.25.tar.gz\n",
      "2022-03-29 15:18:43,665 - INFO - allennlp.common.params - model_usage.training_config = generation/bart_cnn_dm.jsonnet\n",
      "2022-03-29 15:18:43,668 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-03-29 15:18:43,670 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:43,674 - INFO - allennlp.common.params - model_details.description = The BART model here uses a language modeling head, and therefore can be used for generation. The BART encoder, implemented as a `Seq2SeqEncoder`, which assumes it operates on already embedded inputs.  This means that we remove the token and position embeddings from BART in this module.  For the typical use case of using BART to encode inputs to your model (where we include the token and position embeddings from BART), you should use `PretrainedTransformerEmbedder(bart_model_name, sub_module=\"encoder\")` instead of this.\n",
      "2022-03-29 15:18:43,682 - INFO - allennlp.common.params - model_details.short_description = BART with a language model head for generation.\n",
      "2022-03-29 15:18:43,688 - INFO - allennlp.common.params - model_details.developed_by = Lewis et al\n",
      "2022-03-29 15:18:43,694 - INFO - allennlp.common.params - model_details.contributed_by = Dirk Groeneveld\n",
      "2022-03-29 15:18:43,697 - INFO - allennlp.common.params - model_details.date = 2020-07-25\n",
      "2022-03-29 15:18:43,700 - INFO - allennlp.common.params - model_details.version = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:18:43,703 - INFO - allennlp.common.params - model_details.model_type = BART\n",
      "2022-03-29 15:18:43,706 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Lewis2020BARTDS,\n",
      "title={BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension},\n",
      "author={M. Lewis and Yinhan Liu and Naman Goyal and Marjan Ghazvininejad and A. Mohamed and Omer Levy and Ves Stoyanov and L. Zettlemoyer},\n",
      "booktitle={ACL},\n",
      "year={2020}}\n",
      "\n",
      "2022-03-29 15:18:43,708 - INFO - allennlp.common.params - model_details.paper.title = BART: Denosing Sequence-to-Sequence Pre-training for Natural Language Generation,Translation, and Comprehension\n",
      "2022-03-29 15:18:43,712 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:204960716\n",
      "2022-03-29 15:18:43,719 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:43,722 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:43,724 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:43,728 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:43,735 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:43,737 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:43,740 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:43,743 - INFO - allennlp.common.params - metrics.model_performance_measures = ROUGE and BLEU\n",
      "2022-03-29 15:18:43,745 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:43,749 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:43,752 - INFO - allennlp.common.params - evaluation_data.dataset.name = CNN/DailyMail\n",
      "2022-03-29 15:18:43,755 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-03-29 15:18:43,760 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://github.com/abisee/cnn-dailymail\n",
      "2022-03-29 15:18:43,764 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:43,770 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:43,773 - INFO - allennlp.common.params - training_data.dataset.name = CNN/DailyMail\n",
      "2022-03-29 15:18:43,775 - INFO - allennlp.common.params - training_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-03-29 15:18:43,780 - INFO - allennlp.common.params - training_data.dataset.url = https://github.com/abisee/cnn-dailymail\n",
      "2022-03-29 15:18:43,785 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:43,792 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:43,794 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 15:18:43,798 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:43,802 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:43,806 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:43,932 - INFO - allennlp.common.params - id = tagging-fine-grained-transformer-crf-tagger\n",
      "2022-03-29 15:18:43,935 - INFO - allennlp.common.params - registered_model_name = crf_tagger\n",
      "2022-03-29 15:18:43,939 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:43,943 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:43,947 - INFO - allennlp.common.params - display_name = Fine Grained Named Entity Recognition with Transformer\n",
      "2022-03-29 15:18:43,948 - INFO - allennlp.common.params - task_id = ner\n",
      "2022-03-29 15:18:43,950 - INFO - allennlp.common.params - model_usage.archive_file = fgner-transformer.2021-02-11.tar.gz\n",
      "2022-03-29 15:18:43,954 - INFO - allennlp.common.params - model_usage.training_config = tagging/fgner_transformer.jsonnet\n",
      "2022-03-29 15:18:43,955 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 15:18:43,957 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:43,960 - INFO - allennlp.common.params - model_details.description = Fine-grained NER model\n",
      "2022-03-29 15:18:43,961 - INFO - allennlp.common.params - model_details.short_description = Fine-grained NER model\n",
      "2022-03-29 15:18:43,964 - INFO - allennlp.common.params - model_details.developed_by = None\n",
      "2022-03-29 15:18:43,967 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 15:18:43,970 - INFO - allennlp.common.params - model_details.date = 2020-07-14\n",
      "2022-03-29 15:18:43,972 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:43,973 - INFO - allennlp.common.params - model_details.model_type = Transformer\n",
      "2022-03-29 15:18:43,975 - INFO - allennlp.common.params - model_details.paper = None\n",
      "2022-03-29 15:18:43,977 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:43,978 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:43,982 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:43,985 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:43,988 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:43,992 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:43,997 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:44,001 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy and Span-based F1 metric\n",
      "2022-03-29 15:18:44,002 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:44,004 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:44,007 - INFO - allennlp.common.params - evaluation_data.dataset.name = Ontonotes 5.0\n",
      "2022-03-29 15:18:44,010 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Unfortunately we cannot release this data due to licensing restrictions.\n",
      "2022-03-29 15:18:44,014 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "2022-03-29 15:18:44,016 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:44,018 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:44,020 - INFO - allennlp.common.params - training_data.dataset.name = Ontonotes 5.0\n",
      "2022-03-29 15:18:44,021 - INFO - allennlp.common.params - training_data.dataset.notes = Unfortunately we cannot release this data due to licensing restrictions.\n",
      "2022-03-29 15:18:44,023 - INFO - allennlp.common.params - training_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "2022-03-29 15:18:44,027 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:44,030 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:44,035 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = On the validation set:\n",
      "Accuracy: 98%\n",
      "F1: 88%\n",
      "2022-03-29 15:18:44,038 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:44,041 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:44,047 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:44,184 - INFO - allennlp.common.params - id = ve-vilbert\n",
      "2022-03-29 15:18:44,190 - INFO - allennlp.common.params - registered_model_name = ve_vilbert\n",
      "2022-03-29 15:18:44,196 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:44,202 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:44,207 - INFO - allennlp.common.params - display_name = Visual Entailment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:18:44,211 - INFO - allennlp.common.params - task_id = ve\n",
      "2022-03-29 15:18:44,217 - INFO - allennlp.common.params - model_usage.archive_file = visual-entailment-torchvision-2021.03.04.tar.gz\n",
      "2022-03-29 15:18:44,232 - INFO - allennlp.common.params - model_usage.training_config = vilbert_ve_pretrained.jsonnet\n",
      "2022-03-29 15:18:44,246 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-03-29 15:18:44,266 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:44,274 - INFO - allennlp.common.params - model_details.description = This model is based on the ViLBERT architecture. The image features are obtained using the ResNet backbone and Faster RCNN (region detection).\n",
      "2022-03-29 15:18:44,278 - INFO - allennlp.common.params - model_details.short_description = ViLBERT-based model for Visual Entailment.\n",
      "2022-03-29 15:18:44,301 - INFO - allennlp.common.params - model_details.developed_by = Lu et al\n",
      "2022-03-29 15:18:44,308 - INFO - allennlp.common.params - model_details.contributed_by = Akshita Bhagia\n",
      "2022-03-29 15:18:44,311 - INFO - allennlp.common.params - model_details.date = 2021-03-04\n",
      "2022-03-29 15:18:44,316 - INFO - allennlp.common.params - model_details.version = 2\n",
      "2022-03-29 15:18:44,323 - INFO - allennlp.common.params - model_details.model_type = ViLBERT based on BERT large\n",
      "2022-03-29 15:18:44,326 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Lu2019ViLBERTPT,\n",
      "title={ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks},\n",
      "author={Jiasen Lu and Dhruv Batra and D. Parikh and Stefan Lee},\n",
      "booktitle={NeurIPS},\n",
      "year={2019}\n",
      "2022-03-29 15:18:44,327 - INFO - allennlp.common.params - model_details.paper.title = ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks\n",
      "2022-03-29 15:18:44,332 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:199453025\n",
      "2022-03-29 15:18:44,334 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:44,336 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:44,339 - INFO - allennlp.common.params - intended_use.primary_uses = This model is developed for the AllenNLP demo.\n",
      "2022-03-29 15:18:44,341 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:44,344 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:44,346 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:44,348 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:44,350 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy and F1-score\n",
      "2022-03-29 15:18:44,353 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:44,358 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:44,361 - INFO - allennlp.common.params - evaluation_data.dataset.name = Stanford Natural Language Inference - Visual Entailment(SNLI-VE) dev set\n",
      "2022-03-29 15:18:44,363 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Evaluation requires a large amount of images to be accessible locally, so we cannot provide a command you can easily copy and paste.\n",
      "2022-03-29 15:18:44,365 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://github.com/necla-ml/SNLI-VE\n",
      "2022-03-29 15:18:44,367 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:44,370 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:44,373 - INFO - allennlp.common.params - training_data.dataset.name = Stanford Natural Language Inference - Visual Entailment(SNLI-VE) train set\n",
      "2022-03-29 15:18:44,377 - INFO - allennlp.common.params - training_data.dataset.url = https://github.com/necla-ml/SNLI-VE\n",
      "2022-03-29 15:18:44,380 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:44,382 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:44,391 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 15:18:44,397 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:44,401 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:44,409 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = This model is trained on the original SNLI-VE dataset. [Subsequent work](https://api.semanticscholar.org/CorpusID:215415945) has found that an estimated 31% of `neutral` labels in the dataset are incorrect. The `e-SNLI-VE-2.0` dataset contains the re-annotated validation and test sets.\n",
      "2022-03-29 15:18:44,546 - INFO - allennlp.common.params - id = pair-classification-esim\n",
      "2022-03-29 15:18:44,549 - INFO - allennlp.common.params - registered_model_name = esim\n",
      "2022-03-29 15:18:44,552 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:44,558 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:44,565 - INFO - allennlp.common.params - display_name = Enhanced LSTM for Natural Language Inference\n",
      "2022-03-29 15:18:44,578 - INFO - allennlp.common.params - task_id = textual_entailment\n",
      "2022-03-29 15:18:44,584 - INFO - allennlp.common.params - model_usage.archive_file = esim-elmo-2020.11.11.tar.gz\n",
      "2022-03-29 15:18:44,590 - INFO - allennlp.common.params - model_usage.training_config = esim.jsonnet\n",
      "2022-03-29 15:18:44,596 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-03-29 15:18:44,600 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:44,613 - INFO - allennlp.common.params - model_details.description = This `Model` implements the ESIM model, which is a sequential neural inference model based on chain LSTMs.\n",
      "2022-03-29 15:18:44,627 - INFO - allennlp.common.params - model_details.short_description = Enhanced LSTM trained on SNLI.\n",
      "2022-03-29 15:18:44,630 - INFO - allennlp.common.params - model_details.developed_by = Chen et al\n",
      "2022-03-29 15:18:44,635 - INFO - allennlp.common.params - model_details.contributed_by = Dirk Groeneveld\n",
      "2022-03-29 15:18:44,647 - INFO - allennlp.common.params - model_details.date = 2020-04-09\n",
      "2022-03-29 15:18:44,655 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:44,661 - INFO - allennlp.common.params - model_details.model_type = LSTM\n",
      "2022-03-29 15:18:44,666 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Chen2017EnhancedLF,\n",
      "title={Enhanced LSTM for Natural Language Inference},\n",
      "author={Qian Chen and Xiao-Dan Zhu and Z. Ling and Si Wei and Hui Jiang and Diana Inkpen},\n",
      "booktitle={ACL},\n",
      "year={2017}}\n",
      "\n",
      "2022-03-29 15:18:44,669 - INFO - allennlp.common.params - model_details.paper.title = Enhanced LSTM for Natural Language Inference\n",
      "2022-03-29 15:18:44,671 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:34032948\n",
      "2022-03-29 15:18:44,673 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:44,675 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:44,678 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:44,679 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:44,680 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:44,681 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:44,684 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:44,685 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy\n",
      "2022-03-29 15:18:44,687 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:44,688 - INFO - allennlp.common.params - metrics.variation_approaches = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:18:44,697 - INFO - allennlp.common.params - evaluation_data.dataset.name = Stanford Natural Language Inference (SNLI) dev set\n",
      "2022-03-29 15:18:44,698 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_test.jsonl\n",
      "2022-03-29 15:18:44,700 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "2022-03-29 15:18:44,701 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:44,702 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:44,704 - INFO - allennlp.common.params - training_data.dataset.name = Stanford Natural Language Inference (SNLI) train set\n",
      "2022-03-29 15:18:44,707 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_train.jsonl\n",
      "2022-03-29 15:18:44,709 - INFO - allennlp.common.params - training_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "2022-03-29 15:18:44,711 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:44,712 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:44,714 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 15:18:44,715 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:44,717 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:44,722 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:44,876 - INFO - allennlp.common.params - id = pair-classification-adversarial-binary-gender-bias-mitigated-roberta-snli\n",
      "2022-03-29 15:18:44,879 - INFO - allennlp.common.params - registered_model_name = adversarial_bias_mitigator\n",
      "2022-03-29 15:18:44,881 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:44,884 - INFO - allennlp.common.params - registered_predictor_name = textual_entailment\n",
      "2022-03-29 15:18:44,892 - INFO - allennlp.common.params - display_name = Adversarial Binary Gender Bias-Mitigated RoBERTa SNLI\n",
      "2022-03-29 15:18:44,900 - INFO - allennlp.common.params - task_id = textual_entailment\n",
      "2022-03-29 15:18:44,907 - INFO - allennlp.common.params - model_usage.archive_file = adversarial-binary-gender-bias-mitigated-snli-roberta.2021-06-17.tar.gz\n",
      "2022-03-29 15:18:44,924 - INFO - allennlp.common.params - model_usage.training_config = pair_classification/adversarial_binary_gender_bias_mitigated_snli_roberta.jsonnet\n",
      "2022-03-29 15:18:44,927 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp allennlp-models\n",
      "2022-03-29 15:18:44,933 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:44,939 - INFO - allennlp.common.params - model_details.description = This `Model` implements a basic text classifier and feedforward regression adversary with an adversarial bias mitigator wrapper. The text is embedded into a text field using a RoBERTa-large model. The resulting sequence is pooled using a cls_pooler `Seq2VecEncoder` and then passed to a linear classification layer, which projects into the label space. Subsequently, a `FeedForwardRegressionAdversary` attempts to recover the coefficient of the static text embedding in the binary gender bias subspace. While the adversary's parameter updates are computed normally, the predictor's parameters are updated such that the predictor will not aid the adversary and will make it more difficult for the adversary to recover protected variables.\n",
      "2022-03-29 15:18:44,954 - INFO - allennlp.common.params - model_details.short_description = RoBERTa finetuned on SNLI with adversarial binary gender bias mitigation.\n",
      "2022-03-29 15:18:44,958 - INFO - allennlp.common.params - model_details.developed_by = Zhang at al\n",
      "2022-03-29 15:18:44,962 - INFO - allennlp.common.params - model_details.contributed_by = Arjun Subramonian\n",
      "2022-03-29 15:18:44,966 - INFO - allennlp.common.params - model_details.date = 2021-06-17\n",
      "2022-03-29 15:18:44,975 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:44,987 - INFO - allennlp.common.params - model_details.model_type = RoBERTa\n",
      "2022-03-29 15:18:44,989 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Zhang2018MitigatingUB,\n",
      "title={Mitigating Unwanted Biases with Adversarial Learning},\n",
      "author={B. H. Zhang and B. Lemoine and Margaret Mitchell},\n",
      "journal={Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society},\n",
      "year={2018}\n",
      "}\n",
      "2022-03-29 15:18:44,993 - INFO - allennlp.common.params - model_details.paper.title = Mitigating Unwanted Biases with Adversarial Learning\n",
      "2022-03-29 15:18:44,997 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:9424845\n",
      "2022-03-29 15:18:45,007 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:45,016 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:45,021 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:45,025 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:45,028 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:45,030 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:45,033 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:45,035 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy, Net Neutral, Fraction Neutral, Threshold:tau\n",
      "2022-03-29 15:18:45,042 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:45,046 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:45,050 - INFO - allennlp.common.params - evaluation_data.dataset.name = On Measuring and Mitigating Biased Gender-Occupation Inferences SNLI Dataset\n",
      "2022-03-29 15:18:45,054 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://storage.googleapis.com/allennlp-public-models/binary-gender-bias-mitigated-snli-dataset.jsonl\n",
      "2022-03-29 15:18:45,057 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://github.com/sunipa/On-Measuring-and-Mitigating-Biased-Inferences-of-Word-Embeddings\n",
      "2022-03-29 15:18:45,060 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:45,065 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:45,067 - INFO - allennlp.common.params - training_data.dataset.name = Stanford Natural Language Inference (SNLI) train set\n",
      "2022-03-29 15:18:45,069 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_train.jsonl\n",
      "2022-03-29 15:18:45,076 - INFO - allennlp.common.params - training_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "2022-03-29 15:18:45,078 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:45,079 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:45,082 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = Net Neutral: 0.613096454815352, Fraction Neutral: 0.6704967487937075, Threshold:0.5: 0.6637061892722586, Threshold:0.7: 0.49490217463150243\n",
      "2022-03-29 15:18:45,085 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:45,089 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = Adversarial binary gender bias mitigation has been applied to this model. Nonetheless, the model will contain residual biases and bias mitigation does not guarantee entirely bias-free inferences.\n",
      "2022-03-29 15:18:45,091 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:45,200 - INFO - allennlp.common.params - id = nlvr2-vilbert\n",
      "2022-03-29 15:18:45,202 - INFO - allennlp.common.params - registered_model_name = nlvr2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:18:45,203 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:45,204 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:45,205 - INFO - allennlp.common.params - display_name = Visual Entailment - NLVR2\n",
      "2022-03-29 15:18:45,206 - INFO - allennlp.common.params - task_id = nlvr2\n",
      "2022-03-29 15:18:45,207 - INFO - allennlp.common.params - model_usage.archive_file = vilbert-nlvr2-2021.06.01.tar.gz\n",
      "2022-03-29 15:18:45,211 - INFO - allennlp.common.params - model_usage.training_config = vilbert_nlvr2_pretrained.jsonnet\n",
      "2022-03-29 15:18:45,213 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp>=2.5.1 allennlp-models>=2.5.1\n",
      "2022-03-29 15:18:45,215 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:45,219 - INFO - allennlp.common.params - model_details.description = This model is based on the ViLBERT multitask architecture. The image features are obtained using the ResNet backbone and Faster RCNN (region detection).\n",
      "2022-03-29 15:18:45,223 - INFO - allennlp.common.params - model_details.short_description = ViLBERT-based model for Visual Entailment.\n",
      "2022-03-29 15:18:45,225 - INFO - allennlp.common.params - model_details.developed_by = Lu et al\n",
      "2022-03-29 15:18:45,227 - INFO - allennlp.common.params - model_details.contributed_by = Jacob Morrison\n",
      "2022-03-29 15:18:45,232 - INFO - allennlp.common.params - model_details.date = 2021-05-27\n",
      "2022-03-29 15:18:45,235 - INFO - allennlp.common.params - model_details.version = 2\n",
      "2022-03-29 15:18:45,238 - INFO - allennlp.common.params - model_details.model_type = ViLBERT based on BERT large\n",
      "2022-03-29 15:18:45,242 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Lu2019ViLBERTPT,\n",
      "title={ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks},\n",
      "author={Jiasen Lu and Dhruv Batra and D. Parikh and Stefan Lee},\n",
      "booktitle={NeurIPS},\n",
      "year={2019}\n",
      "2022-03-29 15:18:45,244 - INFO - allennlp.common.params - model_details.paper.title = ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks\n",
      "2022-03-29 15:18:45,245 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:199453025\n",
      "2022-03-29 15:18:45,247 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:45,252 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:45,254 - INFO - allennlp.common.params - intended_use.primary_uses = This model is developed for the AllenNLP demo.\n",
      "2022-03-29 15:18:45,255 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:45,257 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:45,260 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:45,262 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:45,265 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy and F1-score\n",
      "2022-03-29 15:18:45,268 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:45,270 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:45,275 - INFO - allennlp.common.params - evaluation_data.dataset.name = Natural Language for Visual Reasoning For Real dev set\n",
      "2022-03-29 15:18:45,278 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Evaluation requires a large amount of images to be accessible locally, so we cannot provide a command you can easily copy and paste.\n",
      "2022-03-29 15:18:45,280 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://github.com/lil-lab/nlvr/tree/master/nlvr2\n",
      "2022-03-29 15:18:45,281 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:45,283 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:45,287 - INFO - allennlp.common.params - training_data.dataset.name = Natural Language for Visual Reasoning For Real train set\n",
      "2022-03-29 15:18:45,288 - INFO - allennlp.common.params - training_data.dataset.url = https://github.com/lil-lab/nlvr/tree/master/nlvr2\n",
      "2022-03-29 15:18:45,290 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:45,294 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:45,296 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = On the validation set:\n",
      "F1: 33.7%\n",
      "Accuracy: 50.8%.\n",
      "These scores do not match the performance in the 12-in-1 paper because this was trained as a standalone task, not as part of a multitask setup. Please contact us if you want to match those scores!\n",
      "2022-03-29 15:18:45,298 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:45,301 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:45,303 - INFO - allennlp.common.params - model_caveats_and_recommendations = None\n",
      "2022-03-29 15:18:45,447 - INFO - allennlp.common.params - id = rc-naqanet\n",
      "2022-03-29 15:18:45,447 - INFO - allennlp.common.params - registered_model_name = naqanet\n",
      "2022-03-29 15:18:45,450 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:45,451 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:45,452 - INFO - allennlp.common.params - display_name = Numerically Augmented QA Net\n",
      "2022-03-29 15:18:45,453 - INFO - allennlp.common.params - task_id = rc\n",
      "2022-03-29 15:18:45,455 - INFO - allennlp.common.params - model_usage.archive_file = naqanet-2021.02.26.tar.gz\n",
      "2022-03-29 15:18:45,456 - INFO - allennlp.common.params - model_usage.training_config = rc/naqanet.jsonnet\n",
      "2022-03-29 15:18:45,458 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 15:18:45,460 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:45,461 - INFO - allennlp.common.params - model_details.description = An augmented version of QANet model with some rudimentary numerical reasoning abilities. The main idea here is that instead of just predicting a passage span after doing all of the QANet modeling stuff, we add several different 'answer abilities': predicting a span from the question, predicting a count, or predicting an arithmetic expression.  Near the end of the QANet model, we have a variable that predicts what kind of answer type we need, and each branch has separate modeling logic to predict that answer type.  We then marginalize over all possible ways of getting to the right answer through each of these answer types.\n",
      "2022-03-29 15:18:45,463 - INFO - allennlp.common.params - model_details.short_description = An augmented version of QANet that adds rudimentary numerical reasoning ability, trained on DROP (Dua et al., 2019), as published in the original DROP paper.\n",
      "2022-03-29 15:18:45,464 - INFO - allennlp.common.params - model_details.developed_by = Dua et al\n",
      "2022-03-29 15:18:45,465 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 15:18:45,465 - INFO - allennlp.common.params - model_details.date = 2020-02-19\n",
      "2022-03-29 15:18:45,466 - INFO - allennlp.common.params - model_details.version = 2\n",
      "2022-03-29 15:18:45,467 - INFO - allennlp.common.params - model_details.model_type = QANet\n",
      "2022-03-29 15:18:45,469 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Dua2019DROPAR,\n",
      "title={DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs},\n",
      "author={Dheeru Dua and Yizhong Wang and Pradeep Dasigi and Gabriel Stanovsky and Sameer Singh and Matt Gardner},\n",
      "booktitle={NAACL-HLT},\n",
      "year={2019}}\n",
      "\n",
      "2022-03-29 15:18:45,470 - INFO - allennlp.common.params - model_details.paper.title = DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs\n",
      "2022-03-29 15:18:45,471 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:67855846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:18:45,472 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:45,473 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:45,474 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:45,477 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:45,479 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:45,481 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:45,482 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:45,485 - INFO - allennlp.common.params - metrics.model_performance_measures = Exact Match and F1-score\n",
      "2022-03-29 15:18:45,486 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:45,488 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:45,490 - INFO - allennlp.common.params - evaluation_data.dataset.name = DROP\n",
      "2022-03-29 15:18:45,491 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/drop/drop_dataset.zip!drop_dataset/drop_dataset_dev.json\n",
      "2022-03-29 15:18:45,492 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://allennlp.org/drop\n",
      "2022-03-29 15:18:45,493 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:45,494 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:45,496 - INFO - allennlp.common.params - training_data.dataset.name = DROP\n",
      "2022-03-29 15:18:45,497 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/drop/drop_dataset.zip!drop_dataset/drop_dataset_train.json\n",
      "2022-03-29 15:18:45,497 - INFO - allennlp.common.params - training_data.dataset.url = https://allennlp.org/drop\n",
      "2022-03-29 15:18:45,498 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:45,499 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:45,501 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = Validation F1-score: 0.509, Exact Match: 0.473\n",
      "2022-03-29 15:18:45,502 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:45,503 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:45,504 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:45,617 - INFO - allennlp.common.params - id = structured-prediction-constituency-parser\n",
      "2022-03-29 15:18:45,620 - INFO - allennlp.common.params - registered_model_name = constituency_parser\n",
      "2022-03-29 15:18:45,625 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:45,630 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:45,633 - INFO - allennlp.common.params - display_name = Constituency Parser with ELMo embeddings\n",
      "2022-03-29 15:18:45,636 - INFO - allennlp.common.params - task_id = constituency-parsing\n",
      "2022-03-29 15:18:45,639 - INFO - allennlp.common.params - model_usage.archive_file = elmo-constituency-parser-2020.02.10.tar.gz\n",
      "2022-03-29 15:18:45,642 - INFO - allennlp.common.params - model_usage.training_config = structured-prediction/constituency_parser_elmo.jsonnet\n",
      "2022-03-29 15:18:45,644 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 15:18:45,646 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:45,650 - INFO - allennlp.common.params - model_details.description = This is an implementation of a minimal neural model for constituency parsing based on an independent scoring of labels and spans. This `SpanConstituencyParser` simply encodes a sequence of text with a stacked `Seq2SeqEncoder`, extracts span representations using a `SpanExtractor`, and then predicts a label for each span in the sequence. These labels are non-terminal nodes in a constituency parse tree, which we then greedily reconstruct. The model uses ELMo embeddings, which are completely character-based and improves single model performance from 92.6 F1 to 94.11 F1 on the Penn Treebank, a 20% relative error reduction.\n",
      "2022-03-29 15:18:45,652 - INFO - allennlp.common.params - model_details.short_description = Constituency parser with character-based ELMo embeddings\n",
      "2022-03-29 15:18:45,657 - INFO - allennlp.common.params - model_details.developed_by = Joshi et al\n",
      "2022-03-29 15:18:45,659 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 15:18:45,663 - INFO - allennlp.common.params - model_details.date = 2020-02-10\n",
      "2022-03-29 15:18:45,667 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:45,671 - INFO - allennlp.common.params - model_details.model_type = Seq2SeqEncoder\n",
      "2022-03-29 15:18:45,676 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Joshi2018ExtendingAP,\n",
      "title={Extending a Parser to Distant Domains Using a Few Dozen Partially Annotated Examples},\n",
      "author={V. Joshi and Matthew E. Peters and Mark Hopkins},\n",
      "booktitle={ACL},\n",
      "year={2018}}\n",
      "\n",
      "2022-03-29 15:18:45,680 - INFO - allennlp.common.params - model_details.paper.title = Extending a Parser to Distant Domains Using a Few Dozen Partially Annotated Examples\n",
      "2022-03-29 15:18:45,684 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:21712653\n",
      "2022-03-29 15:18:45,687 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:45,695 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:45,699 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:45,704 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:45,705 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:45,707 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:45,709 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:45,712 - INFO - allennlp.common.params - metrics.model_performance_measures = Precision, Recall and F1-score for parse trees (EVALB_bracketing_scorer)\n",
      "2022-03-29 15:18:45,716 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:45,720 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:45,722 - INFO - allennlp.common.params - evaluation_data.dataset.name = PTB 3.0\n",
      "2022-03-29 15:18:45,724 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-03-29 15:18:45,726 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = /path/do/dataset\n",
      "2022-03-29 15:18:45,729 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://catalog.ldc.upenn.edu/LDC99T42\n",
      "2022-03-29 15:18:45,731 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:45,733 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:45,739 - INFO - allennlp.common.params - training_data.dataset.name = PTB 3.0\n",
      "2022-03-29 15:18:45,741 - INFO - allennlp.common.params - training_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-03-29 15:18:45,743 - INFO - allennlp.common.params - training_data.dataset.processed_url = /path/do/dataset\n",
      "2022-03-29 15:18:45,745 - INFO - allennlp.common.params - training_data.dataset.url = https://catalog.ldc.upenn.edu/LDC99T42\n",
      "2022-03-29 15:18:45,748 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:45,750 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:45,756 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = 94.11 F1 score\n",
      "2022-03-29 15:18:45,761 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:18:45,765 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:45,768 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:45,911 - INFO - allennlp.common.params - id = pair-classification-decomposable-attention-elmo\n",
      "2022-03-29 15:18:45,919 - INFO - allennlp.common.params - registered_model_name = decomposable_attention\n",
      "2022-03-29 15:18:45,938 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:45,959 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:45,966 - INFO - allennlp.common.params - display_name = ELMo-based Decomposable Attention\n",
      "2022-03-29 15:18:45,979 - INFO - allennlp.common.params - task_id = textual_entailment\n",
      "2022-03-29 15:18:46,005 - INFO - allennlp.common.params - model_usage.archive_file = decomposable-attention-elmo-2020.04.09.tar.gz\n",
      "2022-03-29 15:18:46,023 - INFO - allennlp.common.params - model_usage.training_config = decomposable_attention_elmo.jsonnet\n",
      "2022-03-29 15:18:46,035 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 15:18:46,045 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:46,055 - INFO - allennlp.common.params - model_details.description = This `Model` implements the Decomposable Attention model described in [A Decomposable Attention Model for Natural Language Inference](https://api.semanticscholar.org/CorpusID:8495258) by Parikh et al., 2016, with some optional enhancements before the decomposable attention actually happens.  Parikh's original model allowed for computing an \"intra-sentence\" attention before doing the decomposable entailment step.  We generalize this to any `Seq2SeqEncoder` that can be applied to the premise and/or the hypothesis before computing entailment.\n",
      "\n",
      "The basic outline of this model is to get an embedded representation of each word in thepremise and hypothesis, align words between the two, compare the aligned phrases, and make a final entailment decision based on this aggregated comparison.  Each step in this process uses a feedforward network to modify the representation.\n",
      "\n",
      "This model uses ELMo embeddings.\n",
      "2022-03-29 15:18:46,068 - INFO - allennlp.common.params - model_details.short_description = The decomposable attention model (Parikh et al, 2017) combined with ELMo embeddings trained on SNLI.\n",
      "2022-03-29 15:18:46,070 - INFO - allennlp.common.params - model_details.developed_by = Parikh et al\n",
      "2022-03-29 15:18:46,085 - INFO - allennlp.common.params - model_details.contributed_by = Dirk Groeneveld\n",
      "2022-03-29 15:18:46,093 - INFO - allennlp.common.params - model_details.date = 2020-04-09\n",
      "2022-03-29 15:18:46,103 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:46,107 - INFO - allennlp.common.params - model_details.model_type = Seq2Seq\n",
      "2022-03-29 15:18:46,126 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Parikh2016ADA,\n",
      "title={A Decomposable Attention Model for Natural Language Inference},\n",
      "author={Ankur P. Parikh and Oscar T{\"a}ckstr{\"o}m and Dipanjan Das and Jakob Uszkoreit},\n",
      "journal={ArXiv},\n",
      "year={2016},\n",
      "volume={abs/1606.01933}}\n",
      "\n",
      "2022-03-29 15:18:46,142 - INFO - allennlp.common.params - model_details.paper.title = A Decomposable Attention Model for Natural Language Inference\n",
      "2022-03-29 15:18:46,143 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:8495258\n",
      "2022-03-29 15:18:46,148 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:46,151 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:46,154 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:46,158 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:46,161 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:46,167 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:46,172 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:46,176 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy\n",
      "2022-03-29 15:18:46,179 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:46,182 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:46,184 - INFO - allennlp.common.params - evaluation_data.dataset.name = Stanford Natural Language Inference (SNLI) dev set\n",
      "2022-03-29 15:18:46,186 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_test.jsonl\n",
      "2022-03-29 15:18:46,189 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "2022-03-29 15:18:46,190 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:46,192 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:46,196 - INFO - allennlp.common.params - training_data.dataset.name = Stanford Natural Language Inference (SNLI) train set\n",
      "2022-03-29 15:18:46,200 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_train.jsonl\n",
      "2022-03-29 15:18:46,204 - INFO - allennlp.common.params - training_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "2022-03-29 15:18:46,207 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:46,209 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:46,212 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 15:18:46,215 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:46,217 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:46,222 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:46,339 - INFO - allennlp.common.params - id = pair-classification-roberta-rte\n",
      "2022-03-29 15:18:46,339 - INFO - allennlp.common.params - registered_model_name = basic_classifier\n",
      "2022-03-29 15:18:46,340 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:46,343 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:46,346 - INFO - allennlp.common.params - display_name = RoBERTa RTE\n",
      "2022-03-29 15:18:46,350 - INFO - allennlp.common.params - task_id = pair_classification\n",
      "2022-03-29 15:18:46,360 - INFO - allennlp.common.params - model_usage.archive_file = superglue-rte-roberta.2021-04-09.tar.gz\n",
      "2022-03-29 15:18:46,363 - INFO - allennlp.common.params - model_usage.training_config = pair-classification/superglue_rte_roberta.jsonnet\n",
      "2022-03-29 15:18:46,374 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.3.1 allennlp-models==2.3.1\n",
      "2022-03-29 15:18:46,391 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:46,412 - INFO - allennlp.common.params - model_details.description = The model implements a pair classification model patterned after the proposed model in [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (Devlin et al, 2018)](https://api.semanticscholar.org/CorpusID:52967399), fine-tuned on the MultiNLI corpus. It predicts labels with a linear layer on top of word piece embeddings.\n",
      "2022-03-29 15:18:46,428 - INFO - allennlp.common.params - model_details.short_description = A pair classification model patterned after the proposed model in Devlin et al, fine-tuned on the SuperGLUE RTE corpus\n",
      "2022-03-29 15:18:46,433 - INFO - allennlp.common.params - model_details.developed_by = Devlin et al\n",
      "2022-03-29 15:18:46,440 - INFO - allennlp.common.params - model_details.contributed_by = Jacob Morrison\n",
      "2022-03-29 15:18:46,451 - INFO - allennlp.common.params - model_details.date = 2021-04-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:18:46,455 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:46,468 - INFO - allennlp.common.params - model_details.model_type = RoBERTa\n",
      "2022-03-29 15:18:46,476 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and L. Zettlemoyer and V. Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n",
      "2022-03-29 15:18:46,485 - INFO - allennlp.common.params - model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach\n",
      "2022-03-29 15:18:46,489 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "2022-03-29 15:18:46,495 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:46,497 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:46,507 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:46,522 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:46,533 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:46,537 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:46,539 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:46,550 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy\n",
      "2022-03-29 15:18:46,553 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:46,555 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:46,564 - INFO - allennlp.common.params - evaluation_data.dataset.name = SuperGLUE Recognizing Textual Entailment validation set\n",
      "2022-03-29 15:18:46,566 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://dl.fbaipublicfiles.com/glue/superglue/data/v2/RTE.zip!RTE/val.jsonl\n",
      "2022-03-29 15:18:46,568 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://super.gluebenchmark.com/tasks\n",
      "2022-03-29 15:18:46,569 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:46,577 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:46,580 - INFO - allennlp.common.params - training_data.dataset.name = SuperGLUE Recognizing Textual Entailment training set\n",
      "2022-03-29 15:18:46,582 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://dl.fbaipublicfiles.com/glue/superglue/data/v2/RTE.zip!RTE/train.jsonl\n",
      "2022-03-29 15:18:46,583 - INFO - allennlp.common.params - training_data.dataset.url = https://super.gluebenchmark.com/tasks\n",
      "2022-03-29 15:18:46,585 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:46,599 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:46,606 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = Accuracy: 89.9% on the SuperGLUE RTE validation dataset.\n",
      "2022-03-29 15:18:46,609 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:46,612 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:46,614 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:46,787 - INFO - allennlp.common.params - id = evaluate_rc-lerc\n",
      "2022-03-29 15:18:46,791 - INFO - allennlp.common.params - registered_model_name = lerc\n",
      "2022-03-29 15:18:46,793 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:46,800 - INFO - allennlp.common.params - registered_predictor_name = lerc\n",
      "2022-03-29 15:18:46,804 - INFO - allennlp.common.params - display_name = Learned Evaluation for Reading Comprehension (LERC)\n",
      "2022-03-29 15:18:46,808 - INFO - allennlp.common.params - task_id = evaluate_rc\n",
      "2022-03-29 15:18:46,817 - INFO - allennlp.common.params - model_usage.archive_file = lerc-2020-11-18.tar.gz\n",
      "2022-03-29 15:18:46,821 - INFO - allennlp.common.params - model_usage.training_config = None\n",
      "2022-03-29 15:18:46,822 - INFO - allennlp.common.params - model_usage.install_instructions = The model is available at https://github.com/anthonywchen/MOCHA.\n",
      "2022-03-29 15:18:46,823 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:46,825 - INFO - allennlp.common.params - model_details.description = LERC is a BERT model that is trained to mimic human judgement scores on candidate answers in the MOCHA dataset. LERC outputs scores that range from 1 to 5, however, to stay consistent with metrics such as BLEU and ROUGE, we normalize the output of LERC to be between 0 and 1 in this demo.\n",
      "2022-03-29 15:18:46,832 - INFO - allennlp.common.params - model_details.short_description = A BERT model that scores candidate answers from 0 to 1.\n",
      "2022-03-29 15:18:46,833 - INFO - allennlp.common.params - model_details.developed_by = Chen et al\n",
      "2022-03-29 15:18:46,834 - INFO - allennlp.common.params - model_details.contributed_by = Anthony Chen\n",
      "2022-03-29 15:18:46,835 - INFO - allennlp.common.params - model_details.date = 2021-03-10\n",
      "2022-03-29 15:18:46,837 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:46,838 - INFO - allennlp.common.params - model_details.model_type = BERT\n",
      "2022-03-29 15:18:46,839 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Chen2020MOCHAAD,\n",
      "title={MOCHA: A Dataset for Training and Evaluating Generative Reading Comprehension Metrics},\n",
      "author={Anthony Chen and Gabriel Stanovsky and S. Singh and Matt Gardner},\n",
      "booktitle={EMNLP},\n",
      "year={2020}}\n",
      "\n",
      "2022-03-29 15:18:46,841 - INFO - allennlp.common.params - model_details.paper.title = MOCHA: A Dataset for Training and Evaluating Generative Reading Comprehension Metrics\n",
      "2022-03-29 15:18:46,842 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:222208714\n",
      "2022-03-29 15:18:46,844 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:46,845 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:46,846 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:46,847 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:46,851 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:46,854 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:46,855 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:46,857 - INFO - allennlp.common.params - metrics.model_performance_measures = Pearson Correlation\n",
      "2022-03-29 15:18:46,861 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:46,869 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:46,870 - INFO - allennlp.common.params - evaluation_data.dataset.name = MOCHA\n",
      "2022-03-29 15:18:46,871 - INFO - allennlp.common.params - evaluation_data.dataset.notes = To evaluate this model follow the instructions at https://github.com/anthonywchen/MOCHA.\n",
      "2022-03-29 15:18:46,872 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = None\n",
      "2022-03-29 15:18:46,874 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://allennlp.org/mocha\n",
      "2022-03-29 15:18:46,877 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:46,879 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:46,881 - INFO - allennlp.common.params - training_data.dataset.name = MOCHA\n",
      "2022-03-29 15:18:46,883 - INFO - allennlp.common.params - training_data.dataset.notes = To train this model follow the instructions at https://github.com/anthonywchen/MOCHA.\n",
      "2022-03-29 15:18:46,884 - INFO - allennlp.common.params - training_data.dataset.processed_url = None\n",
      "2022-03-29 15:18:46,885 - INFO - allennlp.common.params - training_data.dataset.url = https://allennlp.org/mocha\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:18:46,886 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:46,887 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:46,893 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 15:18:46,897 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:46,903 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:46,905 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:46,914 - WARNING - allennlp.common.model_card - lerc is not a registered model.\n",
      "2022-03-29 15:18:47,037 - INFO - allennlp.common.params - id = structured-prediction-srl\n",
      "2022-03-29 15:18:47,038 - INFO - allennlp.common.params - registered_model_name = srl\n",
      "2022-03-29 15:18:47,039 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:47,040 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:47,042 - INFO - allennlp.common.params - display_name = Open Information Extraction\n",
      "2022-03-29 15:18:47,043 - INFO - allennlp.common.params - task_id = srl\n",
      "2022-03-29 15:18:47,045 - INFO - allennlp.common.params - model_usage.archive_file = openie-model.2020.03.26.tar.gz\n",
      "2022-03-29 15:18:47,046 - INFO - allennlp.common.params - model_usage.training_config = structured-prediction/srl.jsonnet\n",
      "2022-03-29 15:18:47,047 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 15:18:47,048 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:47,050 - INFO - allennlp.common.params - model_details.description = A reimplementation of a deep BiLSTM sequence prediction model (Stanovsky et al., 2018).\n",
      "2022-03-29 15:18:47,052 - INFO - allennlp.common.params - model_details.short_description = A reimplementation of a deep BiLSTM sequence prediction model (Stanovsky et al., 2018)\n",
      "2022-03-29 15:18:47,053 - INFO - allennlp.common.params - model_details.developed_by = Stanovsky et al\n",
      "2022-03-29 15:18:47,054 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 15:18:47,058 - INFO - allennlp.common.params - model_details.date = 2020-03-26\n",
      "2022-03-29 15:18:47,063 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:47,070 - INFO - allennlp.common.params - model_details.model_type = BiLSTM\n",
      "2022-03-29 15:18:47,073 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@inproceedings{Stanovsky2018SupervisedOI,\n",
      "title={Supervised Open Information Extraction},\n",
      "author={Gabriel Stanovsky and Julian Michael and Luke Zettlemoyer and I. Dagan},\n",
      "booktitle={NAACL-HLT},\n",
      "year={2018}}\n",
      "\n",
      "2022-03-29 15:18:47,076 - INFO - allennlp.common.params - model_details.paper.title = Supervised Open Information Extraction\n",
      "2022-03-29 15:18:47,078 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:44145304\n",
      "2022-03-29 15:18:47,081 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:47,082 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:47,084 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:47,085 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:47,089 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:47,096 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:47,107 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:47,109 - INFO - allennlp.common.params - metrics.model_performance_measures = CoNLL SRL metrics\n",
      "2022-03-29 15:18:47,110 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:47,111 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:47,113 - INFO - allennlp.common.params - evaluation_data.dataset.name = OIE2016, WEB and NYT, PENN\n",
      "2022-03-29 15:18:47,115 - INFO - allennlp.common.params - evaluation_data.dataset.notes = The Open Information extractor was evaluated on the OIE2016 corpus. Unfortunately we cannot release this data due to licensing restrictions by the LDC. You can get the data on the corpus homepage.\n",
      "2022-03-29 15:18:47,116 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://github.com/gabrielStanovsky/oie-benchmark\n",
      "2022-03-29 15:18:47,117 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:47,119 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:47,124 - INFO - allennlp.common.params - training_data.dataset.name = All Words Open IE\n",
      "2022-03-29 15:18:47,133 - INFO - allennlp.common.params - training_data.dataset.url = https://github.com/gabrielStanovsky/supervised-oie/tree/master/data\n",
      "2022-03-29 15:18:47,135 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:47,136 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:47,139 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 15:18:47,141 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:47,143 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:47,148 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:47,301 - INFO - allennlp.common.params - id = pair-classification-roberta-snli\n",
      "2022-03-29 15:18:47,308 - INFO - allennlp.common.params - registered_model_name = basic_classifier\n",
      "2022-03-29 15:18:47,310 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:47,315 - INFO - allennlp.common.params - registered_predictor_name = textual_entailment\n",
      "2022-03-29 15:18:47,318 - INFO - allennlp.common.params - display_name = RoBERTa SNLI\n",
      "2022-03-29 15:18:47,325 - INFO - allennlp.common.params - task_id = textual_entailment\n",
      "2022-03-29 15:18:47,347 - INFO - allennlp.common.params - model_usage.archive_file = snli-roberta.2021-03-11.tar.gz\n",
      "2022-03-29 15:18:47,364 - INFO - allennlp.common.params - model_usage.training_config = pair_classification/snli_roberta.jsonnet\n",
      "2022-03-29 15:18:47,369 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 15:18:47,375 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:47,380 - INFO - allennlp.common.params - model_details.description = This `Model` implements a basic text classifier. The text is embedded into a text field using a RoBERTa-large model. The resulting sequence is pooled using a cls_pooler `Seq2VecEncoder` and then passed to a linear classification layer, which projects into the label space.\n",
      "2022-03-29 15:18:47,390 - INFO - allennlp.common.params - model_details.short_description = RoBERTa finetuned on SNLI.\n",
      "2022-03-29 15:18:47,411 - INFO - allennlp.common.params - model_details.developed_by = Liu et al\n",
      "2022-03-29 15:18:47,425 - INFO - allennlp.common.params - model_details.contributed_by = Dirk Groeneveld\n",
      "2022-03-29 15:18:47,433 - INFO - allennlp.common.params - model_details.date = 2020-07-29\n",
      "2022-03-29 15:18:47,434 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:47,436 - INFO - allennlp.common.params - model_details.model_type = RoBERTa\n",
      "2022-03-29 15:18:47,447 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and Luke Zettlemoyer and Veselin Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n",
      "2022-03-29 15:18:47,448 - INFO - allennlp.common.params - model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:18:47,450 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "2022-03-29 15:18:47,452 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:47,453 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:47,460 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:47,466 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:47,476 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:47,478 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:47,480 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:47,485 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy\n",
      "2022-03-29 15:18:47,495 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:47,499 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:47,502 - INFO - allennlp.common.params - evaluation_data.dataset.name = Stanford Natural Language Inference (SNLI) dev set\n",
      "2022-03-29 15:18:47,506 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_test.jsonl\n",
      "2022-03-29 15:18:47,510 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "2022-03-29 15:18:47,512 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:47,518 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:47,524 - INFO - allennlp.common.params - training_data.dataset.name = Stanford Natural Language Inference (SNLI) train set\n",
      "2022-03-29 15:18:47,536 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_train.jsonl\n",
      "2022-03-29 15:18:47,540 - INFO - allennlp.common.params - training_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "2022-03-29 15:18:47,546 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:47,548 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:47,550 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = Net Neutral: 0.49562665820121765, Fraction Neutral: 0.5068705677986145, Threshold:0.5: 0.47600528597831726, Threshold:0.7: 0.3036800026893616\n",
      "2022-03-29 15:18:47,554 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:47,568 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:47,579 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:47,707 - INFO - allennlp.common.params - id = pair-classification-binary-gender-bias-mitigated-roberta-snli\n",
      "2022-03-29 15:18:47,711 - INFO - allennlp.common.params - registered_model_name = bias_mitigator_applicator\n",
      "2022-03-29 15:18:47,716 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:47,726 - INFO - allennlp.common.params - registered_predictor_name = textual_entailment\n",
      "2022-03-29 15:18:47,731 - INFO - allennlp.common.params - display_name = Binary Gender Bias-Mitigated RoBERTa SNLI\n",
      "2022-03-29 15:18:47,738 - INFO - allennlp.common.params - task_id = textual_entailment\n",
      "2022-03-29 15:18:47,749 - INFO - allennlp.common.params - model_usage.archive_file = binary-gender-bias-mitigated-snli-roberta.2021-05-20.tar.gz\n",
      "2022-03-29 15:18:47,752 - INFO - allennlp.common.params - model_usage.training_config = pair_classification/binary_gender_bias_mitigated_snli_roberta.jsonnet\n",
      "2022-03-29 15:18:47,756 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.5.0 allennlp-models==2.5.0\n",
      "2022-03-29 15:18:47,762 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:47,772 - INFO - allennlp.common.params - model_details.description = This `Model` implements a basic text classifier with a bias mitigator applicator wrapper. The text is embedded into a text field using a RoBERTa-large model. Following the static embedding layer, the embeddings are projected onto the subspace orthogonal to the binary gender bias subspace. The resulting sequence is pooled using a cls_pooler `Seq2VecEncoder` and then passed to a linear classification layer, which projects into the label space.\n",
      "2022-03-29 15:18:47,777 - INFO - allennlp.common.params - model_details.short_description = RoBERTa finetuned on SNLI with binary gender bias mitigation.\n",
      "2022-03-29 15:18:47,781 - INFO - allennlp.common.params - model_details.developed_by = Dev at al\n",
      "2022-03-29 15:18:47,783 - INFO - allennlp.common.params - model_details.contributed_by = Arjun Subramonian\n",
      "2022-03-29 15:18:47,787 - INFO - allennlp.common.params - model_details.date = 2021-05-20\n",
      "2022-03-29 15:18:47,789 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:47,793 - INFO - allennlp.common.params - model_details.model_type = RoBERTa\n",
      "2022-03-29 15:18:47,801 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Dev2020OnMA,\n",
      "title={On Measuring and Mitigating Biased Inferences of Word Embeddings},\n",
      "author={Sunipa Dev and Tao Li and J. M. Phillips and Vivek Srikumar},\n",
      "journal={Proceedings of the AAAI Conference on Artificial Intelligence},\n",
      "year={2020},\n",
      "volume={34},\n",
      "number={05},\n",
      "pages={7659-7666},\n",
      "DOI={10.1609/aaai.v34i05.6267}\n",
      "\n",
      "2022-03-29 15:18:47,801 - INFO - allennlp.common.params - model_details.paper.title = On Measuring and Mitigating Biased Inferences of Word Embeddings\n",
      "2022-03-29 15:18:47,804 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:201670701\n",
      "2022-03-29 15:18:47,808 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:47,811 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:47,814 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:47,816 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:47,817 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:47,819 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:47,820 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:47,821 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy, Net Neutral, Fraction Neutral, Threshold:tau\n",
      "2022-03-29 15:18:47,823 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:47,824 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:47,827 - INFO - allennlp.common.params - evaluation_data.dataset.name = On Measuring and Mitigating Biased Gender-Occupation Inferences SNLI Dataset\n",
      "2022-03-29 15:18:47,834 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://storage.googleapis.com/allennlp-public-models/binary-gender-bias-mitigated-snli-dataset.jsonl\n",
      "2022-03-29 15:18:47,836 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://github.com/sunipa/On-Measuring-and-Mitigating-Biased-Inferences-of-Word-Embeddings\n",
      "2022-03-29 15:18:47,837 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:47,840 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:47,845 - INFO - allennlp.common.params - training_data.dataset.name = Stanford Natural Language Inference (SNLI) train set\n",
      "2022-03-29 15:18:47,846 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_train.jsonl\n",
      "2022-03-29 15:18:47,847 - INFO - allennlp.common.params - training_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "2022-03-29 15:18:47,848 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:47,849 - INFO - allennlp.common.params - training_data.preprocessing = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:18:47,850 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = Net Neutral: 0.6417539715766907, Fraction Neutral: 0.7002295255661011, Threshold:0.5: 0.6902161836624146, Threshold:0.7: 0.49243637919425964\n",
      "2022-03-29 15:18:47,852 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:47,854 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = Binary gender bias mitigation has been applied to this model. Nonetheless, the model will contain residual biases and bias mitigation does not guarantee entirely bias-free inferences.\n",
      "2022-03-29 15:18:47,855 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:47,981 - INFO - allennlp.common.params - id = mc-roberta-piqa\n",
      "2022-03-29 15:18:47,984 - INFO - allennlp.common.params - registered_model_name = transformer_mc\n",
      "2022-03-29 15:18:47,986 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:47,989 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:47,997 - INFO - allennlp.common.params - display_name = Physical Interaction Question Answering\n",
      "2022-03-29 15:18:48,001 - INFO - allennlp.common.params - task_id = mc\n",
      "2022-03-29 15:18:48,004 - INFO - allennlp.common.params - model_usage.archive_file = piqa.2020-07-08.tar.gz\n",
      "2022-03-29 15:18:48,006 - INFO - allennlp.common.params - model_usage.training_config = mc/piqa.jsonnet\n",
      "2022-03-29 15:18:48,012 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-03-29 15:18:48,016 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:48,019 - INFO - allennlp.common.params - model_details.description = This is a multiple choice model patterned after the BERT architecture. It calculates a score for each sequence on top of the CLS token, and then chooses the alternative with the highest score.\n",
      "2022-03-29 15:18:48,027 - INFO - allennlp.common.params - model_details.short_description = RoBERTa-based multiple choice model for PIQA.\n",
      "2022-03-29 15:18:48,029 - INFO - allennlp.common.params - model_details.developed_by = Devlin et al\n",
      "2022-03-29 15:18:48,038 - INFO - allennlp.common.params - model_details.contributed_by = Dirk Groeneveld\n",
      "2022-03-29 15:18:48,045 - INFO - allennlp.common.params - model_details.date = 2020-07-08\n",
      "2022-03-29 15:18:48,060 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:48,062 - INFO - allennlp.common.params - model_details.model_type = RoBERTa large\n",
      "2022-03-29 15:18:48,068 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and Luke Zettlemoyer and Veselin Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n",
      "2022-03-29 15:18:48,074 - INFO - allennlp.common.params - model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al)\n",
      "2022-03-29 15:18:48,084 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "2022-03-29 15:18:48,105 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:48,110 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:48,113 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:48,116 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:48,121 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:48,135 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:48,137 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:48,143 - INFO - allennlp.common.params - metrics.model_performance_measures = The chosen metric is accuracy, since it is a multiple choice model.\n",
      "2022-03-29 15:18:48,157 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:48,162 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:48,166 - INFO - allennlp.common.params - evaluation_data.dataset.name = PIQA (validation set)\n",
      "2022-03-29 15:18:48,175 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-03-29 15:18:48,182 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://yonatanbisk.com/piqa/\n",
      "2022-03-29 15:18:48,184 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:48,188 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:48,199 - INFO - allennlp.common.params - training_data.dataset.name = PIQA (train set)\n",
      "2022-03-29 15:18:48,200 - INFO - allennlp.common.params - training_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-03-29 15:18:48,204 - INFO - allennlp.common.params - training_data.dataset.url = https://yonatanbisk.com/piqa/\n",
      "2022-03-29 15:18:48,208 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:48,218 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:48,223 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 15:18:48,229 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:48,237 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:48,251 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:48,366 - INFO - allennlp.common.params - id = rc-nmn\n",
      "2022-03-29 15:18:48,371 - INFO - allennlp.common.params - registered_model_name = None\n",
      "2022-03-29 15:18:48,381 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:48,396 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:48,399 - INFO - allennlp.common.params - display_name = Neural Module Network (NMN)\n",
      "2022-03-29 15:18:48,403 - INFO - allennlp.common.params - task_id = rc\n",
      "2022-03-29 15:18:48,411 - INFO - allennlp.common.params - model_usage.archive_file = drop-nmn-2020.04.04.tar.gz\n",
      "2022-03-29 15:18:48,421 - INFO - allennlp.common.params - model_usage.training_config = None\n",
      "2022-03-29 15:18:48,423 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-03-29 15:18:48,427 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:48,440 - INFO - allennlp.common.params - model_details.description = A neural module network trained on DROP.\n",
      "2022-03-29 15:18:48,459 - INFO - allennlp.common.params - model_details.short_description = A neural module network trained on DROP.\n",
      "2022-03-29 15:18:48,464 - INFO - allennlp.common.params - model_details.developed_by = Andreas et al\n",
      "2022-03-29 15:18:48,466 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 15:18:48,467 - INFO - allennlp.common.params - model_details.date = 2020-04-04\n",
      "2022-03-29 15:18:48,476 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:48,488 - INFO - allennlp.common.params - model_details.model_type = Neural Module Network\n",
      "2022-03-29 15:18:48,491 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Andreas2016NeuralMN,\n",
      "title={Neural Module Networks},\n",
      "author={Jacob Andreas and Marcus Rohrbach and Trevor Darrell and D. Klein},\n",
      "journal={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n",
      "year={2016},\n",
      "pages={39-48}}\n",
      "\n",
      "2022-03-29 15:18:48,494 - INFO - allennlp.common.params - model_details.paper.title = Neural Module Networks\n",
      "2022-03-29 15:18:48,496 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:5276660\n",
      "2022-03-29 15:18:48,498 - INFO - allennlp.common.params - model_details.license = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:18:48,501 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:48,509 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:48,511 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:48,515 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:48,520 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:48,524 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:48,527 - INFO - allennlp.common.params - metrics.model_performance_measures = None\n",
      "2022-03-29 15:18:48,530 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:48,535 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:48,539 - INFO - allennlp.common.params - evaluation_data.dataset = None\n",
      "2022-03-29 15:18:48,542 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:48,544 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:48,546 - INFO - allennlp.common.params - training_data.dataset.name = DROP\n",
      "2022-03-29 15:18:48,548 - INFO - allennlp.common.params - training_data.dataset.url = https://allennlp.org/drop\n",
      "2022-03-29 15:18:48,549 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:48,550 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:48,553 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 15:18:48,554 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:48,555 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:48,557 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:48,653 - INFO - allennlp.common.params - id = mc-roberta-commonsenseqa\n",
      "2022-03-29 15:18:48,653 - INFO - allennlp.common.params - registered_model_name = transformer_mc\n",
      "2022-03-29 15:18:48,654 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:48,655 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:48,656 - INFO - allennlp.common.params - display_name = RoBERTa Common Sense QA\n",
      "2022-03-29 15:18:48,657 - INFO - allennlp.common.params - task_id = mc\n",
      "2022-03-29 15:18:48,658 - INFO - allennlp.common.params - model_usage.archive_file = commonsenseqa.2020-07-08.tar.gz\n",
      "2022-03-29 15:18:48,660 - INFO - allennlp.common.params - model_usage.training_config = mc/commonsenseqa.jsonnet\n",
      "2022-03-29 15:18:48,662 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "2022-03-29 15:18:48,664 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:48,668 - INFO - allennlp.common.params - model_details.description = This is a multiple choice model patterned after the BERT architecture. It calculates a score for each sequence on top of the CLS token, and then chooses the alternative with the highest score.\n",
      "2022-03-29 15:18:48,669 - INFO - allennlp.common.params - model_details.short_description = RoBERTa-based multiple choice model for CommonSenseQA.\n",
      "2022-03-29 15:18:48,670 - INFO - allennlp.common.params - model_details.developed_by = Liu et al\n",
      "2022-03-29 15:18:48,672 - INFO - allennlp.common.params - model_details.contributed_by = Dirk Groeneveld\n",
      "2022-03-29 15:18:48,673 - INFO - allennlp.common.params - model_details.date = 2020-07-08\n",
      "2022-03-29 15:18:48,674 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:48,678 - INFO - allennlp.common.params - model_details.model_type = RoBERTa large\n",
      "2022-03-29 15:18:48,680 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and Luke Zettlemoyer and Veselin Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n",
      "2022-03-29 15:18:48,681 - INFO - allennlp.common.params - model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al)\n",
      "2022-03-29 15:18:48,683 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "2022-03-29 15:18:48,689 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:48,690 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:48,692 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:48,697 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:48,705 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:48,707 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:48,708 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:48,709 - INFO - allennlp.common.params - metrics.model_performance_measures = The chosen metric is accuracy, since it is a multiple choice model.\n",
      "2022-03-29 15:18:48,711 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:48,712 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:48,714 - INFO - allennlp.common.params - evaluation_data.dataset.name = CommonSenseQA (validation set)\n",
      "2022-03-29 15:18:48,715 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-03-29 15:18:48,716 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://github.com/jonathanherzig/commonsenseqa\n",
      "2022-03-29 15:18:48,716 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:48,718 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:48,719 - INFO - allennlp.common.params - training_data.dataset.name = CommonSenseQA (train set)\n",
      "2022-03-29 15:18:48,720 - INFO - allennlp.common.params - training_data.dataset.notes = Please download the data from the url provided.\n",
      "2022-03-29 15:18:48,721 - INFO - allennlp.common.params - training_data.dataset.url = https://github.com/jonathanherzig/commonsenseqa\n",
      "2022-03-29 15:18:48,722 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:48,723 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:48,724 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 15:18:48,726 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:48,728 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:48,731 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:48,854 - INFO - allennlp.common.params - id = pair-classification-roberta-mnli\n",
      "2022-03-29 15:18:48,855 - INFO - allennlp.common.params - registered_model_name = basic_classifier\n",
      "2022-03-29 15:18:48,856 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:48,858 - INFO - allennlp.common.params - registered_predictor_name = textual_entailment\n",
      "2022-03-29 15:18:48,865 - INFO - allennlp.common.params - display_name = RoBERTa MNLI\n",
      "2022-03-29 15:18:48,869 - INFO - allennlp.common.params - task_id = textual_entailment\n",
      "2022-03-29 15:18:48,871 - INFO - allennlp.common.params - model_usage.archive_file = mnli-roberta.2021-03-11.tar.gz\n",
      "2022-03-29 15:18:48,872 - INFO - allennlp.common.params - model_usage.training_config = pair_classification/mnli_roberta.jsonnet\n",
      "2022-03-29 15:18:48,873 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 15:18:48,874 - INFO - allennlp.common.params - model_usage.overrides = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:18:48,875 - INFO - allennlp.common.params - model_details.description = This `Model` implements a basic text classifier. The text is embedded into a text field using a RoBERTa-large model. The resulting sequence is pooled using a cls_pooler `Seq2VecEncoder` and then passed to a linear classification layer, which projects into the label space.\n",
      "2022-03-29 15:18:48,878 - INFO - allennlp.common.params - model_details.short_description = RoBERTa finetuned on MNLI.\n",
      "2022-03-29 15:18:48,881 - INFO - allennlp.common.params - model_details.developed_by = Liu et al\n",
      "2022-03-29 15:18:48,883 - INFO - allennlp.common.params - model_details.contributed_by = Dirk Groeneveld\n",
      "2022-03-29 15:18:48,884 - INFO - allennlp.common.params - model_details.date = 2020-07-29\n",
      "2022-03-29 15:18:48,887 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:48,891 - INFO - allennlp.common.params - model_details.model_type = RoBERTa\n",
      "2022-03-29 15:18:48,893 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and Luke Zettlemoyer and Veselin Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n",
      "2022-03-29 15:18:48,899 - INFO - allennlp.common.params - model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al)\n",
      "2022-03-29 15:18:48,901 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "2022-03-29 15:18:48,902 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:48,903 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:48,905 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:48,906 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:48,907 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:48,909 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:48,910 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:48,912 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy\n",
      "2022-03-29 15:18:48,913 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:48,914 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:48,917 - INFO - allennlp.common.params - evaluation_data.dataset.name = Multi-genre Natural Language Inference (MultiNLI) dev set\n",
      "2022-03-29 15:18:48,922 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/multinli/multinli_1.0_dev_mismatched.jsonl\n",
      "2022-03-29 15:18:48,923 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://cims.nyu.edu/~sbowman/multinli/\n",
      "2022-03-29 15:18:48,925 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:48,934 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:48,936 - INFO - allennlp.common.params - training_data.dataset.name = Multi-genre Natural Language Inference (MultiNLI) train set\n",
      "2022-03-29 15:18:48,937 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/multinli/multinli_1.0_train.jsonl\n",
      "2022-03-29 15:18:48,938 - INFO - allennlp.common.params - training_data.dataset.url = https://cims.nyu.edu/~sbowman/multinli/\n",
      "2022-03-29 15:18:48,939 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:48,942 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:48,948 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = None\n",
      "2022-03-29 15:18:48,951 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:48,953 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:48,954 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:49,074 - INFO - allennlp.common.params - id = rc-transformer-qa\n",
      "2022-03-29 15:18:49,076 - INFO - allennlp.common.params - registered_model_name = transformer_qa\n",
      "2022-03-29 15:18:49,078 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:49,079 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:49,081 - INFO - allennlp.common.params - display_name = Transformer QA\n",
      "2022-03-29 15:18:49,082 - INFO - allennlp.common.params - task_id = rc\n",
      "2022-03-29 15:18:49,084 - INFO - allennlp.common.params - model_usage.archive_file = transformer-qa.2021-02-11.tar.gz\n",
      "2022-03-29 15:18:49,086 - INFO - allennlp.common.params - model_usage.training_config = rc/transformer_qa.jsonnet\n",
      "2022-03-29 15:18:49,087 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 15:18:49,088 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:49,090 - INFO - allennlp.common.params - model_details.description = The model implements a reading comprehension model patterned after the proposed model in [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (Devlin et al, 2018)](https://api.semanticscholar.org/CorpusID:52967399), with improvements borrowed from the SQuAD model in the transformers project. It predicts start tokens and end tokens with a linear layer on top of word piece embeddings.\n",
      "2022-03-29 15:18:49,091 - INFO - allennlp.common.params - model_details.short_description = A reading comprehension model patterned after the proposed model in Devlin et al, with improvements borrowed from the SQuAD model in the transformers project\n",
      "2022-03-29 15:18:49,093 - INFO - allennlp.common.params - model_details.developed_by = Devlin et al\n",
      "2022-03-29 15:18:49,103 - INFO - allennlp.common.params - model_details.contributed_by = Dirk Groeneveld and Evan Pete Walsh\n",
      "2022-03-29 15:18:49,107 - INFO - allennlp.common.params - model_details.date = 2020-10-03\n",
      "2022-03-29 15:18:49,108 - INFO - allennlp.common.params - model_details.version = 2\n",
      "2022-03-29 15:18:49,110 - INFO - allennlp.common.params - model_details.model_type = RoBERTa\n",
      "2022-03-29 15:18:49,112 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and L. Zettlemoyer and V. Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n",
      "2022-03-29 15:18:49,113 - INFO - allennlp.common.params - model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach\n",
      "2022-03-29 15:18:49,114 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "2022-03-29 15:18:49,115 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:49,116 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:49,118 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:49,119 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:49,120 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:49,122 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:49,123 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:49,125 - INFO - allennlp.common.params - metrics.model_performance_measures = F1-score, Span Accuracy, Exact Match\n",
      "2022-03-29 15:18:49,127 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:49,136 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:49,141 - INFO - allennlp.common.params - evaluation_data.dataset.name = SQuAD dev set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:18:49,143 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/squad/squad-dev-v2.0.json\n",
      "2022-03-29 15:18:49,145 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://rajpurkar.github.io/SQuAD-explorer/explore/2.0/dev/\n",
      "2022-03-29 15:18:49,147 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:49,149 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:49,151 - INFO - allennlp.common.params - training_data.dataset.name = SQuAD training set\n",
      "2022-03-29 15:18:49,152 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/squad/squad-train-v2.0.json\n",
      "2022-03-29 15:18:49,153 - INFO - allennlp.common.params - training_data.dataset.url = https://rajpurkar.github.io/SQuAD-explorer/explore/2.0/dev/\n",
      "2022-03-29 15:18:49,155 - INFO - allennlp.common.params - training_data.motivation = For the pretrained RoBERTa model, document-level corpora were used rather than a shuffled sentence-level corpus such as the Billion Word Benchmark (Chelba et al., 2013) in order to extract long contiguous sequences\n",
      "2022-03-29 15:18:49,156 - INFO - allennlp.common.params - training_data.preprocessing = For the pretrained RoBERTa model, only the text passages were extracted from English Wikipedia; lists, tables, and headers were ignored.\n",
      "2022-03-29 15:18:49,157 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = On the validation set:\n",
      "F1: 88%\n",
      "Exact match: 84%\n",
      "These are metrics using the official evaluation. Note that the metrics that the model produces while training are calculated on a per-instance basis only. Since there could be more than one instance per question, these metrics are not the official numbers on the SQuAD task. To get official numbers, run the evaluation script at allennlp_models/rc/tools/transformer_qa_eval.py.\n",
      "2022-03-29 15:18:49,158 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:49,160 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:49,169 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:49,323 - INFO - allennlp.common.params - id = tagging-fine-grained-crf-tagger\n",
      "2022-03-29 15:18:49,327 - INFO - allennlp.common.params - registered_model_name = crf_tagger\n",
      "2022-03-29 15:18:49,329 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:49,334 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:49,338 - INFO - allennlp.common.params - display_name = Fine Grained Named Entity Recognition\n",
      "2022-03-29 15:18:49,348 - INFO - allennlp.common.params - task_id = ner\n",
      "2022-03-29 15:18:49,371 - INFO - allennlp.common.params - model_usage.archive_file = fine-grained-ner.2021-02-11.tar.gz\n",
      "2022-03-29 15:18:49,376 - INFO - allennlp.common.params - model_usage.training_config = tagging/fine-grained-ner.jsonnet\n",
      "2022-03-29 15:18:49,379 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 15:18:49,387 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:49,407 - INFO - allennlp.common.params - model_details.description = This model identifies a broad range of 16 semantic types in the input text. It is a reimplementation of Lample (2016) and uses a biLSTM with a CRF layer, character embeddings and ELMo embeddings.\n",
      "2022-03-29 15:18:49,410 - INFO - allennlp.common.params - model_details.short_description = This model identifies a broad range of 16 semantic types in the input text. It is a reimplementation of Lample (2016) and uses a biLSTM with a CRF layer, character embeddings and ELMo embeddings.\n",
      "2022-03-29 15:18:49,424 - INFO - allennlp.common.params - model_details.developed_by = Lample et al\n",
      "2022-03-29 15:18:49,434 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 15:18:49,438 - INFO - allennlp.common.params - model_details.date = 2020-06-24\n",
      "2022-03-29 15:18:49,447 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:49,450 - INFO - allennlp.common.params - model_details.model_type = BiLSTM\n",
      "2022-03-29 15:18:49,455 - INFO - allennlp.common.params - model_details.paper.citation = \n",
      "@article{Lample2016NeuralAF,\n",
      "title={Neural Architectures for Named Entity Recognition},\n",
      "author={Guillaume Lample and Miguel Ballesteros and Sandeep Subramanian and K. Kawakami and Chris Dyer},\n",
      "journal={ArXiv},\n",
      "year={2016},\n",
      "volume={abs/1603.01360}}\n",
      "\n",
      "2022-03-29 15:18:49,457 - INFO - allennlp.common.params - model_details.paper.title = Neural Architectures for Named Entity Recognition\n",
      "2022-03-29 15:18:49,460 - INFO - allennlp.common.params - model_details.paper.url = https://api.semanticscholar.org/CorpusID:6042994\n",
      "2022-03-29 15:18:49,466 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:49,467 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:49,470 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:49,472 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:49,474 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:49,482 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:49,483 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:49,485 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy and Span-based F1 metric\n",
      "2022-03-29 15:18:49,489 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:49,490 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:49,500 - INFO - allennlp.common.params - evaluation_data.dataset.name = Ontonotes 5.0\n",
      "2022-03-29 15:18:49,501 - INFO - allennlp.common.params - evaluation_data.dataset.notes = Unfortunately we cannot release this data due to licensing restrictions.\n",
      "2022-03-29 15:18:49,502 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = /path/do/dataset\n",
      "2022-03-29 15:18:49,511 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "2022-03-29 15:18:49,513 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:49,515 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:49,517 - INFO - allennlp.common.params - training_data.dataset.name = Ontonotes 5.0\n",
      "2022-03-29 15:18:49,519 - INFO - allennlp.common.params - training_data.dataset.notes = Unfortunately we cannot release this data due to licensing restrictions.\n",
      "2022-03-29 15:18:49,520 - INFO - allennlp.common.params - training_data.dataset.processed_url = /path/do/dataset\n",
      "2022-03-29 15:18:49,522 - INFO - allennlp.common.params - training_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "2022-03-29 15:18:49,528 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:49,533 - INFO - allennlp.common.params - training_data.preprocessing = None\n",
      "2022-03-29 15:18:49,539 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = On the validation set:\n",
      "Accuracy: 97%\n",
      "F1: 88%\n",
      "2022-03-29 15:18:49,540 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:49,545 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:49,548 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:49,717 - INFO - allennlp.common.params - id = glove-sst\n",
      "2022-03-29 15:18:49,718 - INFO - allennlp.common.params - registered_model_name = None\n",
      "2022-03-29 15:18:49,719 - INFO - allennlp.common.params - model_class = None\n",
      "2022-03-29 15:18:49,721 - INFO - allennlp.common.params - registered_predictor_name = None\n",
      "2022-03-29 15:18:49,723 - INFO - allennlp.common.params - display_name = GLoVe-LSTM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:18:49,733 - INFO - allennlp.common.params - task_id = sentiment-analysis\n",
      "2022-03-29 15:18:49,735 - INFO - allennlp.common.params - model_usage.archive_file = basic_stanford_sentiment_treebank-2020.06.09.tar.gz\n",
      "2022-03-29 15:18:49,737 - INFO - allennlp.common.params - model_usage.training_config = classification/basic_stanford_sentiment_treebank.jsonnet\n",
      "2022-03-29 15:18:49,739 - INFO - allennlp.common.params - model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "2022-03-29 15:18:49,750 - INFO - allennlp.common.params - model_usage.overrides = None\n",
      "2022-03-29 15:18:49,766 - INFO - allennlp.common.params - model_details.description = This model uses GloVe embeddings and is trained on the binary classification setting of the Stanford Sentiment Treebank. It achieves about 87% on the test set.\n",
      "2022-03-29 15:18:49,773 - INFO - allennlp.common.params - model_details.short_description = LSTM binary classifier with GloVe embeddings.\n",
      "2022-03-29 15:18:49,787 - INFO - allennlp.common.params - model_details.developed_by = None\n",
      "2022-03-29 15:18:49,791 - INFO - allennlp.common.params - model_details.contributed_by = None\n",
      "2022-03-29 15:18:49,796 - INFO - allennlp.common.params - model_details.date = 2020-06-09\n",
      "2022-03-29 15:18:49,800 - INFO - allennlp.common.params - model_details.version = 1\n",
      "2022-03-29 15:18:49,803 - INFO - allennlp.common.params - model_details.model_type = LSTM\n",
      "2022-03-29 15:18:49,806 - INFO - allennlp.common.params - model_details.paper = None\n",
      "2022-03-29 15:18:49,811 - INFO - allennlp.common.params - model_details.license = None\n",
      "2022-03-29 15:18:49,817 - INFO - allennlp.common.params - model_details.contact = allennlp-contact@allenai.org\n",
      "2022-03-29 15:18:49,823 - INFO - allennlp.common.params - intended_use.primary_uses = None\n",
      "2022-03-29 15:18:49,838 - INFO - allennlp.common.params - intended_use.primary_users = None\n",
      "2022-03-29 15:18:49,891 - INFO - allennlp.common.params - intended_use.out_of_scope_use_cases = None\n",
      "2022-03-29 15:18:49,899 - INFO - allennlp.common.params - factors.relevant_factors = None\n",
      "2022-03-29 15:18:49,919 - INFO - allennlp.common.params - factors.evaluation_factors = None\n",
      "2022-03-29 15:18:49,923 - INFO - allennlp.common.params - metrics.model_performance_measures = Accuracy\n",
      "2022-03-29 15:18:49,938 - INFO - allennlp.common.params - metrics.decision_thresholds = None\n",
      "2022-03-29 15:18:49,979 - INFO - allennlp.common.params - metrics.variation_approaches = None\n",
      "2022-03-29 15:18:49,986 - INFO - allennlp.common.params - evaluation_data.dataset.name = Stanford Sentiment Treebank\n",
      "2022-03-29 15:18:50,003 - INFO - allennlp.common.params - evaluation_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/sst/test.txt\n",
      "2022-03-29 15:18:50,005 - INFO - allennlp.common.params - evaluation_data.dataset.url = https://nlp.stanford.edu/sentiment/treebank.html\n",
      "2022-03-29 15:18:50,007 - INFO - allennlp.common.params - evaluation_data.motivation = None\n",
      "2022-03-29 15:18:50,010 - INFO - allennlp.common.params - evaluation_data.preprocessing = None\n",
      "2022-03-29 15:18:50,020 - INFO - allennlp.common.params - training_data.dataset.name = Stanford Sentiment Treebank\n",
      "2022-03-29 15:18:50,022 - INFO - allennlp.common.params - training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/sst/train.txt\n",
      "2022-03-29 15:18:50,030 - INFO - allennlp.common.params - training_data.dataset.url = https://nlp.stanford.edu/sentiment/treebank.html\n",
      "2022-03-29 15:18:50,037 - INFO - allennlp.common.params - training_data.motivation = None\n",
      "2022-03-29 15:18:50,039 - INFO - allennlp.common.params - training_data.preprocessing = Binary classification setting\n",
      "2022-03-29 15:18:50,042 - INFO - allennlp.common.params - quantitative_analyses.unitary_results = Accuracy: 87% on SST test set.\n",
      "2022-03-29 15:18:50,046 - INFO - allennlp.common.params - quantitative_analyses.intersectional_results = None\n",
      "2022-03-29 15:18:50,048 - INFO - allennlp.common.params - model_ethical_considerations.ethical_considerations = None\n",
      "2022-03-29 15:18:50,051 - INFO - allennlp.common.params - model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "2022-03-29 15:18:50,524 - INFO - allennlp.common.plugins - Plugin allennlp_models available\n",
      "2022-03-29 15:18:50,890 - INFO - cached_path - cache of https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz is up-to-date\n",
      "2022-03-29 15:18:50,891 - INFO - allennlp.models.archival - loading archive file https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz from cache at /Users/robertbluemel/.allennlp/cache/b5f1db011cc85691a5fa2bf29e055a712261a2e5d74a74edd7da2fffc98d4ab8.4c4ac7e06ec3d85631bd26b839f90b5a375d3ceeb43e3c74f1cf4758dcee2bb3\n",
      "2022-03-29 15:18:50,893 - INFO - allennlp.models.archival - extracting archive file /Users/robertbluemel/.allennlp/cache/b5f1db011cc85691a5fa2bf29e055a712261a2e5d74a74edd7da2fffc98d4ab8.4c4ac7e06ec3d85631bd26b839f90b5a375d3ceeb43e3c74f1cf4758dcee2bb3 to temp dir /var/folders/4b/mjmc5tls1qvgfsm3xckpy5s40000gn/T/tmp9xxv7pdd\n",
      "2022-03-29 15:19:00,699 - INFO - allennlp.common.params - dataset_reader.type = srl\n",
      "2022-03-29 15:19:00,700 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
      "2022-03-29 15:19:00,701 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
      "2022-03-29 15:19:00,704 - INFO - allennlp.common.params - dataset_reader.manual_multiprocess_sharding = False\n",
      "2022-03-29 15:19:00,706 - INFO - allennlp.common.params - dataset_reader.token_indexers = None\n",
      "2022-03-29 15:19:00,707 - INFO - allennlp.common.params - dataset_reader.domain_identifier = None\n",
      "2022-03-29 15:19:00,708 - INFO - allennlp.common.params - dataset_reader.bert_model_name = bert-base-uncased\n",
      "2022-03-29 15:19:16,920 - INFO - allennlp.common.params - dataset_reader.type = srl\n",
      "2022-03-29 15:19:16,984 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
      "2022-03-29 15:19:17,078 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
      "2022-03-29 15:19:17,088 - INFO - allennlp.common.params - dataset_reader.manual_multiprocess_sharding = False\n",
      "2022-03-29 15:19:17,111 - INFO - allennlp.common.params - dataset_reader.token_indexers = None\n",
      "2022-03-29 15:19:17,119 - INFO - allennlp.common.params - dataset_reader.domain_identifier = None\n",
      "2022-03-29 15:19:17,132 - INFO - allennlp.common.params - dataset_reader.bert_model_name = bert-base-uncased\n",
      "2022-03-29 15:19:22,637 - INFO - allennlp.common.params - type = from_instances\n",
      "2022-03-29 15:19:22,638 - INFO - allennlp.data.vocabulary - Loading token dictionary from /var/folders/4b/mjmc5tls1qvgfsm3xckpy5s40000gn/T/tmp9xxv7pdd/vocabulary.\n",
      "2022-03-29 15:19:22,642 - INFO - allennlp.common.params - model.type = srl_bert\n",
      "2022-03-29 15:19:22,643 - INFO - allennlp.common.params - model.regularizer = None\n",
      "2022-03-29 15:19:22,649 - INFO - allennlp.common.params - model.ddp_accelerator = None\n",
      "2022-03-29 15:19:22,650 - INFO - allennlp.common.params - model.bert_model = bert-base-uncased\n",
      "2022-03-29 15:19:22,651 - INFO - allennlp.common.params - model.embedding_dropout = 0.1\n",
      "2022-03-29 15:19:22,652 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7fd001f96e20>\n",
      "2022-03-29 15:19:22,654 - INFO - allennlp.common.params - model.label_smoothing = None\n",
      "2022-03-29 15:19:22,655 - INFO - allennlp.common.params - model.ignore_span_metric = False\n",
      "2022-03-29 15:19:22,657 - INFO - allennlp.common.params - model.srl_eval_path = /Users/robertbluemel/anaconda3/envs/nlp/lib/python3.8/site-packages/allennlp_models/structured_prediction/tools/srl-eval.pl\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:19:26,861 - INFO - allennlp.nn.initializers - Initializing parameters\n",
      "2022-03-29 15:19:26,865 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "2022-03-29 15:19:26,867 - INFO - allennlp.nn.initializers -    bert_model.embeddings.LayerNorm.bias\n",
      "2022-03-29 15:19:26,885 - INFO - allennlp.nn.initializers -    bert_model.embeddings.LayerNorm.weight\n",
      "2022-03-29 15:19:26,894 - INFO - allennlp.nn.initializers -    bert_model.embeddings.position_embeddings.weight\n",
      "2022-03-29 15:19:26,900 - INFO - allennlp.nn.initializers -    bert_model.embeddings.token_type_embeddings.weight\n",
      "2022-03-29 15:19:26,902 - INFO - allennlp.nn.initializers -    bert_model.embeddings.word_embeddings.weight\n",
      "2022-03-29 15:19:26,912 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "2022-03-29 15:19:26,913 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "2022-03-29 15:19:26,915 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.dense.bias\n",
      "2022-03-29 15:19:26,916 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.dense.weight\n",
      "2022-03-29 15:19:26,922 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.key.bias\n",
      "2022-03-29 15:19:26,925 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.key.weight\n",
      "2022-03-29 15:19:26,926 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.query.bias\n",
      "2022-03-29 15:19:26,928 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.query.weight\n",
      "2022-03-29 15:19:26,930 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.value.bias\n",
      "2022-03-29 15:19:26,931 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.value.weight\n",
      "2022-03-29 15:19:26,932 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.intermediate.dense.bias\n",
      "2022-03-29 15:19:26,934 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.intermediate.dense.weight\n",
      "2022-03-29 15:19:26,937 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.LayerNorm.bias\n",
      "2022-03-29 15:19:26,939 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.LayerNorm.weight\n",
      "2022-03-29 15:19:26,940 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.dense.bias\n",
      "2022-03-29 15:19:26,945 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.dense.weight\n",
      "2022-03-29 15:19:26,949 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "2022-03-29 15:19:26,957 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "2022-03-29 15:19:26,958 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.dense.bias\n",
      "2022-03-29 15:19:26,959 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.dense.weight\n",
      "2022-03-29 15:19:26,961 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.key.bias\n",
      "2022-03-29 15:19:26,962 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.key.weight\n",
      "2022-03-29 15:19:26,963 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.query.bias\n",
      "2022-03-29 15:19:26,964 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.query.weight\n",
      "2022-03-29 15:19:26,966 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.value.bias\n",
      "2022-03-29 15:19:26,968 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.value.weight\n",
      "2022-03-29 15:19:26,970 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.intermediate.dense.bias\n",
      "2022-03-29 15:19:26,971 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.intermediate.dense.weight\n",
      "2022-03-29 15:19:26,972 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.LayerNorm.bias\n",
      "2022-03-29 15:19:26,973 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.LayerNorm.weight\n",
      "2022-03-29 15:19:26,974 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.dense.bias\n",
      "2022-03-29 15:19:26,976 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.dense.weight\n",
      "2022-03-29 15:19:26,978 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "2022-03-29 15:19:26,979 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "2022-03-29 15:19:26,979 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.dense.bias\n",
      "2022-03-29 15:19:26,981 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.dense.weight\n",
      "2022-03-29 15:19:26,982 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.key.bias\n",
      "2022-03-29 15:19:26,983 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.key.weight\n",
      "2022-03-29 15:19:26,990 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.query.bias\n",
      "2022-03-29 15:19:26,996 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.query.weight\n",
      "2022-03-29 15:19:26,997 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.value.bias\n",
      "2022-03-29 15:19:26,998 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.value.weight\n",
      "2022-03-29 15:19:26,999 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.intermediate.dense.bias\n",
      "2022-03-29 15:19:27,001 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.intermediate.dense.weight\n",
      "2022-03-29 15:19:27,002 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.LayerNorm.bias\n",
      "2022-03-29 15:19:27,003 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.LayerNorm.weight\n",
      "2022-03-29 15:19:27,004 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.dense.bias\n",
      "2022-03-29 15:19:27,005 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.dense.weight\n",
      "2022-03-29 15:19:27,006 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "2022-03-29 15:19:27,007 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "2022-03-29 15:19:27,008 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.dense.bias\n",
      "2022-03-29 15:19:27,009 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.dense.weight\n",
      "2022-03-29 15:19:27,010 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.key.bias\n",
      "2022-03-29 15:19:27,010 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.key.weight\n",
      "2022-03-29 15:19:27,011 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.query.bias\n",
      "2022-03-29 15:19:27,012 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.query.weight\n",
      "2022-03-29 15:19:27,013 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.value.bias\n",
      "2022-03-29 15:19:27,014 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.value.weight\n",
      "2022-03-29 15:19:27,015 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.intermediate.dense.bias\n",
      "2022-03-29 15:19:27,016 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.intermediate.dense.weight\n",
      "2022-03-29 15:19:27,018 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.LayerNorm.bias\n",
      "2022-03-29 15:19:27,020 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.LayerNorm.weight\n",
      "2022-03-29 15:19:27,022 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.dense.bias\n",
      "2022-03-29 15:19:27,023 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.dense.weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:19:27,024 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "2022-03-29 15:19:27,025 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "2022-03-29 15:19:27,026 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.dense.bias\n",
      "2022-03-29 15:19:27,028 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.dense.weight\n",
      "2022-03-29 15:19:27,029 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.key.bias\n",
      "2022-03-29 15:19:27,029 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.key.weight\n",
      "2022-03-29 15:19:27,030 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.query.bias\n",
      "2022-03-29 15:19:27,031 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.query.weight\n",
      "2022-03-29 15:19:27,034 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.value.bias\n",
      "2022-03-29 15:19:27,036 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.value.weight\n",
      "2022-03-29 15:19:27,039 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.intermediate.dense.bias\n",
      "2022-03-29 15:19:27,042 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.intermediate.dense.weight\n",
      "2022-03-29 15:19:27,046 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.LayerNorm.bias\n",
      "2022-03-29 15:19:27,048 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.LayerNorm.weight\n",
      "2022-03-29 15:19:27,050 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.dense.bias\n",
      "2022-03-29 15:19:27,053 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.dense.weight\n",
      "2022-03-29 15:19:27,057 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "2022-03-29 15:19:27,059 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "2022-03-29 15:19:27,064 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.dense.bias\n",
      "2022-03-29 15:19:27,067 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.dense.weight\n",
      "2022-03-29 15:19:27,070 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.key.bias\n",
      "2022-03-29 15:19:27,071 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.key.weight\n",
      "2022-03-29 15:19:27,079 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.query.bias\n",
      "2022-03-29 15:19:27,083 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.query.weight\n",
      "2022-03-29 15:19:27,085 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.value.bias\n",
      "2022-03-29 15:19:27,088 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.value.weight\n",
      "2022-03-29 15:19:27,091 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.intermediate.dense.bias\n",
      "2022-03-29 15:19:27,094 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.intermediate.dense.weight\n",
      "2022-03-29 15:19:27,096 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.LayerNorm.bias\n",
      "2022-03-29 15:19:27,098 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.LayerNorm.weight\n",
      "2022-03-29 15:19:27,110 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.dense.bias\n",
      "2022-03-29 15:19:27,115 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.dense.weight\n",
      "2022-03-29 15:19:27,119 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "2022-03-29 15:19:27,123 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "2022-03-29 15:19:27,125 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.dense.bias\n",
      "2022-03-29 15:19:27,128 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.dense.weight\n",
      "2022-03-29 15:19:27,131 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.key.bias\n",
      "2022-03-29 15:19:27,135 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.key.weight\n",
      "2022-03-29 15:19:27,137 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.query.bias\n",
      "2022-03-29 15:19:27,141 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.query.weight\n",
      "2022-03-29 15:19:27,142 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.value.bias\n",
      "2022-03-29 15:19:27,145 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.value.weight\n",
      "2022-03-29 15:19:27,150 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.intermediate.dense.bias\n",
      "2022-03-29 15:19:27,153 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.intermediate.dense.weight\n",
      "2022-03-29 15:19:27,155 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.LayerNorm.bias\n",
      "2022-03-29 15:19:27,157 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.LayerNorm.weight\n",
      "2022-03-29 15:19:27,159 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.dense.bias\n",
      "2022-03-29 15:19:27,164 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.dense.weight\n",
      "2022-03-29 15:19:27,168 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "2022-03-29 15:19:27,170 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "2022-03-29 15:19:27,183 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.dense.bias\n",
      "2022-03-29 15:19:27,217 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.dense.weight\n",
      "2022-03-29 15:19:27,220 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.key.bias\n",
      "2022-03-29 15:19:27,222 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.key.weight\n",
      "2022-03-29 15:19:27,226 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.query.bias\n",
      "2022-03-29 15:19:27,229 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.query.weight\n",
      "2022-03-29 15:19:27,234 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.value.bias\n",
      "2022-03-29 15:19:27,235 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.value.weight\n",
      "2022-03-29 15:19:27,244 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.intermediate.dense.bias\n",
      "2022-03-29 15:19:27,248 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.intermediate.dense.weight\n",
      "2022-03-29 15:19:27,253 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.LayerNorm.bias\n",
      "2022-03-29 15:19:27,254 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.LayerNorm.weight\n",
      "2022-03-29 15:19:27,258 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.dense.bias\n",
      "2022-03-29 15:19:27,260 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.dense.weight\n",
      "2022-03-29 15:19:27,261 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "2022-03-29 15:19:27,263 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "2022-03-29 15:19:27,277 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.dense.bias\n",
      "2022-03-29 15:19:27,279 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.dense.weight\n",
      "2022-03-29 15:19:27,298 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.key.bias\n",
      "2022-03-29 15:19:27,302 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.key.weight\n",
      "2022-03-29 15:19:27,305 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.query.bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 15:19:27,311 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.query.weight\n",
      "2022-03-29 15:19:27,314 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.value.bias\n",
      "2022-03-29 15:19:27,316 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.value.weight\n",
      "2022-03-29 15:19:27,323 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.intermediate.dense.bias\n",
      "2022-03-29 15:19:27,326 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.intermediate.dense.weight\n",
      "2022-03-29 15:19:27,329 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.LayerNorm.bias\n",
      "2022-03-29 15:19:27,332 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.LayerNorm.weight\n",
      "2022-03-29 15:19:27,337 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.dense.bias\n",
      "2022-03-29 15:19:27,339 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.dense.weight\n",
      "2022-03-29 15:19:27,342 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "2022-03-29 15:19:27,344 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "2022-03-29 15:19:27,347 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.dense.bias\n",
      "2022-03-29 15:19:27,352 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.dense.weight\n",
      "2022-03-29 15:19:27,358 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.key.bias\n",
      "2022-03-29 15:19:27,363 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.key.weight\n",
      "2022-03-29 15:19:27,365 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.query.bias\n",
      "2022-03-29 15:19:27,370 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.query.weight\n",
      "2022-03-29 15:19:27,372 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.value.bias\n",
      "2022-03-29 15:19:27,373 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.value.weight\n",
      "2022-03-29 15:19:27,376 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.intermediate.dense.bias\n",
      "2022-03-29 15:19:27,380 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.intermediate.dense.weight\n",
      "2022-03-29 15:19:27,383 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.LayerNorm.bias\n",
      "2022-03-29 15:19:27,390 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.LayerNorm.weight\n",
      "2022-03-29 15:19:27,395 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.dense.bias\n",
      "2022-03-29 15:19:27,396 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.dense.weight\n",
      "2022-03-29 15:19:27,401 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "2022-03-29 15:19:27,403 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "2022-03-29 15:19:27,406 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.dense.bias\n",
      "2022-03-29 15:19:27,409 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.dense.weight\n",
      "2022-03-29 15:19:27,410 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.key.bias\n",
      "2022-03-29 15:19:27,411 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.key.weight\n",
      "2022-03-29 15:19:27,413 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.query.bias\n",
      "2022-03-29 15:19:27,414 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.query.weight\n",
      "2022-03-29 15:19:27,416 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.value.bias\n",
      "2022-03-29 15:19:27,422 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.value.weight\n",
      "2022-03-29 15:19:27,424 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.intermediate.dense.bias\n",
      "2022-03-29 15:19:27,425 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.intermediate.dense.weight\n",
      "2022-03-29 15:19:27,427 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.LayerNorm.bias\n",
      "2022-03-29 15:19:27,429 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.LayerNorm.weight\n",
      "2022-03-29 15:19:27,430 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.dense.bias\n",
      "2022-03-29 15:19:27,433 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.dense.weight\n",
      "2022-03-29 15:19:27,435 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "2022-03-29 15:19:27,436 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "2022-03-29 15:19:27,437 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.dense.bias\n",
      "2022-03-29 15:19:27,439 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.dense.weight\n",
      "2022-03-29 15:19:27,441 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.key.bias\n",
      "2022-03-29 15:19:27,442 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.key.weight\n",
      "2022-03-29 15:19:27,446 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.query.bias\n",
      "2022-03-29 15:19:27,452 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.query.weight\n",
      "2022-03-29 15:19:27,454 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.value.bias\n",
      "2022-03-29 15:19:27,459 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.value.weight\n",
      "2022-03-29 15:19:27,462 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.intermediate.dense.bias\n",
      "2022-03-29 15:19:27,463 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.intermediate.dense.weight\n",
      "2022-03-29 15:19:27,465 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.LayerNorm.bias\n",
      "2022-03-29 15:19:27,468 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.LayerNorm.weight\n",
      "2022-03-29 15:19:27,469 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.dense.bias\n",
      "2022-03-29 15:19:27,471 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.dense.weight\n",
      "2022-03-29 15:19:27,472 - INFO - allennlp.nn.initializers -    bert_model.pooler.dense.bias\n",
      "2022-03-29 15:19:27,473 - INFO - allennlp.nn.initializers -    bert_model.pooler.dense.weight\n",
      "2022-03-29 15:19:27,473 - INFO - allennlp.nn.initializers -    tag_projection_layer.bias\n",
      "2022-03-29 15:19:27,475 - INFO - allennlp.nn.initializers -    tag_projection_layer.weight\n",
      "2022-03-29 15:19:29,162 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /var/folders/4b/mjmc5tls1qvgfsm3xckpy5s40000gn/T/tmp9xxv7pdd\n"
     ]
    }
   ],
   "source": [
    "# load model and inspect output\n",
    "# allennlp srl model: https://docs.allennlp.org/models/main/models/structured_prediction/models/srl/\n",
    "# propbank labels\n",
    "# paper with a bit of error analysis: https://aclanthology.org/P17-1044.pdf\n",
    "\n",
    "#srl_predictor = load_predictor('structured-prediction-srl') \n",
    "\n",
    "srl_predictor = load_predictor('structured-prediction-srl-bert')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbs': [], 'words': ['The', 'old', 'man', 'the', 'boat', '.']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = srl_predictor.predict(\"The killer killed the victim with a knife.\")\n",
    "output\n",
    "\n",
    "output = srl_predictor.predict(\"The old man the boat.\")\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbs': [{'verb': 'walk',\n",
       "   'description': \"'' [ARG0: The buyers] [V: walk] [ARGM-DIR: away] , and the specialist is left alone '' as the buyer of last resort for his stable of stocks , he contends .\",\n",
       "   'tags': ['O',\n",
       "    'B-ARG0',\n",
       "    'I-ARG0',\n",
       "    'B-V',\n",
       "    'B-ARGM-DIR',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O']},\n",
       "  {'verb': 'is',\n",
       "   'description': \"'' The buyers walk away , and the specialist [V: is] left alone '' as the buyer of last resort for his stable of stocks , he contends .\",\n",
       "   'tags': ['O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'B-V',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O']},\n",
       "  {'verb': 'left',\n",
       "   'description': \"'' The buyers walk away , and [ARG1: the specialist] is [V: left] [ARG2: alone] '' [ARG2: as the buyer of last resort for his stable of stocks] , he contends .\",\n",
       "   'tags': ['O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'B-ARG1',\n",
       "    'I-ARG1',\n",
       "    'O',\n",
       "    'B-V',\n",
       "    'B-ARG2',\n",
       "    'O',\n",
       "    'B-ARG2',\n",
       "    'I-ARG2',\n",
       "    'I-ARG2',\n",
       "    'I-ARG2',\n",
       "    'I-ARG2',\n",
       "    'I-ARG2',\n",
       "    'I-ARG2',\n",
       "    'I-ARG2',\n",
       "    'I-ARG2',\n",
       "    'I-ARG2',\n",
       "    'I-ARG2',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O']},\n",
       "  {'verb': 'contends',\n",
       "   'description': \"'' [ARG1: The buyers walk away , and the specialist is left alone '' as the buyer of last resort for his stable of stocks] , [ARG0: he] [V: contends] .\",\n",
       "   'tags': ['O',\n",
       "    'B-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'O',\n",
       "    'B-ARG0',\n",
       "    'B-V',\n",
       "    'O']}],\n",
       " 'words': [\"''\",\n",
       "  'The',\n",
       "  'buyers',\n",
       "  'walk',\n",
       "  'away',\n",
       "  ',',\n",
       "  'and',\n",
       "  'the',\n",
       "  'specialist',\n",
       "  'is',\n",
       "  'left',\n",
       "  'alone',\n",
       "  \"''\",\n",
       "  'as',\n",
       "  'the',\n",
       "  'buyer',\n",
       "  'of',\n",
       "  'last',\n",
       "  'resort',\n",
       "  'for',\n",
       "  'his',\n",
       "  'stable',\n",
       "  'of',\n",
       "  'stocks',\n",
       "  ',',\n",
       "  'he',\n",
       "  'contends',\n",
       "  '.']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "output = srl_predictor.predict(\"\\'\\'The buyers walk away, and the specialist is left alone\\'\\' as the buyer of last resort for his stable of stocks, he contends.\")\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbs': [{'verb': 'Walking',\n",
       "   'description': \"[V: Walking] [ARGM-LOC: amid the hubbub of Taipei today] , [ARG1: on streets filled with people and traffic] , Ko - nan Street , Shanghai Road , the Tri - Service Stadium and the Star Cafe have long since drifted away like the sound of Ko Lan 's mambo song .\",\n",
       "   'tags': ['B-V',\n",
       "    'B-ARGM-LOC',\n",
       "    'I-ARGM-LOC',\n",
       "    'I-ARGM-LOC',\n",
       "    'I-ARGM-LOC',\n",
       "    'I-ARGM-LOC',\n",
       "    'I-ARGM-LOC',\n",
       "    'O',\n",
       "    'B-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O']},\n",
       "  {'verb': 'filled',\n",
       "   'description': \"Walking amid the hubbub of Taipei today , on [ARG1: streets] [V: filled] [ARG2: with people and traffic] , Ko - nan Street , Shanghai Road , the Tri - Service Stadium and the Star Cafe have long since drifted away like the sound of Ko Lan 's mambo song .\",\n",
       "   'tags': ['O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'B-ARG1',\n",
       "    'B-V',\n",
       "    'B-ARG2',\n",
       "    'I-ARG2',\n",
       "    'I-ARG2',\n",
       "    'I-ARG2',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O']},\n",
       "  {'verb': 'have',\n",
       "   'description': \"Walking amid the hubbub of Taipei today , on streets filled with people and traffic , Ko - nan Street , Shanghai Road , the Tri - Service Stadium and the Star Cafe [V: have] long since drifted away like the sound of Ko Lan 's mambo song .\",\n",
       "   'tags': ['O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'B-V',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O']},\n",
       "  {'verb': 'drifted',\n",
       "   'description': \"[ARGM-ADV: Walking amid the hubbub of Taipei today , on streets filled with people and traffic] , [ARG1: Ko - nan Street , Shanghai Road , the Tri - Service Stadium and the Star Cafe] have [ARGM-TMP: long since] [V: drifted] [ARGM-DIR: away] [ARGM-ADV: like the sound of Ko Lan 's mambo song] .\",\n",
       "   'tags': ['B-ARGM-ADV',\n",
       "    'I-ARGM-ADV',\n",
       "    'I-ARGM-ADV',\n",
       "    'I-ARGM-ADV',\n",
       "    'I-ARGM-ADV',\n",
       "    'I-ARGM-ADV',\n",
       "    'I-ARGM-ADV',\n",
       "    'I-ARGM-ADV',\n",
       "    'I-ARGM-ADV',\n",
       "    'I-ARGM-ADV',\n",
       "    'I-ARGM-ADV',\n",
       "    'I-ARGM-ADV',\n",
       "    'I-ARGM-ADV',\n",
       "    'I-ARGM-ADV',\n",
       "    'I-ARGM-ADV',\n",
       "    'O',\n",
       "    'B-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'O',\n",
       "    'B-ARGM-TMP',\n",
       "    'I-ARGM-TMP',\n",
       "    'B-V',\n",
       "    'B-ARGM-DIR',\n",
       "    'B-ARGM-ADV',\n",
       "    'I-ARGM-ADV',\n",
       "    'I-ARGM-ADV',\n",
       "    'I-ARGM-ADV',\n",
       "    'I-ARGM-ADV',\n",
       "    'I-ARGM-ADV',\n",
       "    'I-ARGM-ADV',\n",
       "    'I-ARGM-ADV',\n",
       "    'I-ARGM-ADV',\n",
       "    'O']}],\n",
       " 'words': ['Walking',\n",
       "  'amid',\n",
       "  'the',\n",
       "  'hubbub',\n",
       "  'of',\n",
       "  'Taipei',\n",
       "  'today',\n",
       "  ',',\n",
       "  'on',\n",
       "  'streets',\n",
       "  'filled',\n",
       "  'with',\n",
       "  'people',\n",
       "  'and',\n",
       "  'traffic',\n",
       "  ',',\n",
       "  'Ko',\n",
       "  '-',\n",
       "  'nan',\n",
       "  'Street',\n",
       "  ',',\n",
       "  'Shanghai',\n",
       "  'Road',\n",
       "  ',',\n",
       "  'the',\n",
       "  'Tri',\n",
       "  '-',\n",
       "  'Service',\n",
       "  'Stadium',\n",
       "  'and',\n",
       "  'the',\n",
       "  'Star',\n",
       "  'Cafe',\n",
       "  'have',\n",
       "  'long',\n",
       "  'since',\n",
       "  'drifted',\n",
       "  'away',\n",
       "  'like',\n",
       "  'the',\n",
       "  'sound',\n",
       "  'of',\n",
       "  'Ko',\n",
       "  'Lan',\n",
       "  \"'s\",\n",
       "  'mambo',\n",
       "  'song',\n",
       "  '.']}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inspect output\n",
    "output = srl_predictor.predict('Walking amid the hubbub of Taipei today , on streets filled with people and traffic , Ko - nan Street , Shanghai Road , the Tri-Service Stadium and the Star Cafe have long since drifted away like the sound of Ko Lan \\'s mambo song .')\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbs': [{'verb': 'can',\n",
       "   'description': 'The normal walk of the dog [V: can] be encumbered by long toenails .',\n",
       "   'tags': ['O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'B-V',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O']},\n",
       "  {'verb': 'be',\n",
       "   'description': 'The normal walk of the dog can [V: be] encumbered by long toenails .',\n",
       "   'tags': ['O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'B-V',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O']},\n",
       "  {'verb': 'encumbered',\n",
       "   'description': '[ARG1: The normal walk of the dog] [ARGM-MOD: can] be [V: encumbered] [ARG2: by long toenails] .',\n",
       "   'tags': ['B-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'B-ARGM-MOD',\n",
       "    'O',\n",
       "    'B-V',\n",
       "    'B-ARG2',\n",
       "    'I-ARG2',\n",
       "    'I-ARG2',\n",
       "    'O']}],\n",
       " 'words': ['The',\n",
       "  'normal',\n",
       "  'walk',\n",
       "  'of',\n",
       "  'the',\n",
       "  'dog',\n",
       "  'can',\n",
       "  'be',\n",
       "  'encumbered',\n",
       "  'by',\n",
       "  'long',\n",
       "  'toenails',\n",
       "  '.']}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = srl_predictor.predict('The normal walk of the dog can be encumbered by long toenails.')\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### added by pia ###\n",
    "\n",
    "def predict_srl(data):\n",
    "    \n",
    "    pred = []\n",
    "    for d in data:\n",
    "        pred.append(srl_predictor.predict(d))\n",
    "    return pred\n",
    "\n",
    "predict_and_conf = PredictorWrapper.wrap_predict(predict_srl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'verbs': [{'verb': 'was',\n",
       "     'description': 'Ben Reynolds [V: was] killed by someone last night .',\n",
       "     'tags': ['O', 'O', 'B-V', 'O', 'O', 'O', 'O', 'O', 'O']},\n",
       "    {'verb': 'killed',\n",
       "     'description': '[ARG1: Ben Reynolds] was [V: killed] [ARG0: by someone] [ARGM-TMP: last night] .',\n",
       "     'tags': ['B-ARG1',\n",
       "      'I-ARG1',\n",
       "      'O',\n",
       "      'B-V',\n",
       "      'B-ARG0',\n",
       "      'I-ARG0',\n",
       "      'B-ARGM-TMP',\n",
       "      'I-ARGM-TMP',\n",
       "      'O']}],\n",
       "   'words': ['Ben',\n",
       "    'Reynolds',\n",
       "    'was',\n",
       "    'killed',\n",
       "    'by',\n",
       "    'someone',\n",
       "    'last',\n",
       "    'night',\n",
       "    '.']},\n",
       "  {'verbs': [{'verb': 'killed',\n",
       "     'description': '[ARG0: The killer] [V: killed] [ARG1: the victim] [ARG2: with a knife] .',\n",
       "     'tags': ['B-ARG0',\n",
       "      'I-ARG0',\n",
       "      'B-V',\n",
       "      'B-ARG1',\n",
       "      'I-ARG1',\n",
       "      'B-ARG2',\n",
       "      'I-ARG2',\n",
       "      'I-ARG2',\n",
       "      'O']}],\n",
       "   'words': ['The',\n",
       "    'killer',\n",
       "    'killed',\n",
       "    'the',\n",
       "    'victim',\n",
       "    'with',\n",
       "    'a',\n",
       "    'knife',\n",
       "    '.']}],\n",
       " array([1., 1.]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = [\"Ben Reynolds was killed by someone last night.\",\"The killer killed the victim with a knife.\" ]\n",
    "pred = predict_and_conf(d)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_srl(x, pred, conf, label=None, meta=None):\n",
    "    \n",
    "    return pred['verbs'][0]['description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checklist examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to extract target argument\n",
    "\n",
    "def get_arg(pred, arg_target='ARG1'):\n",
    "    # we assume one predicate:\n",
    "    predicate_arguments = pred['verbs'][0]\n",
    "    words = pred['words']\n",
    "    tags = predicate_arguments['tags']\n",
    "    \n",
    "    arg_list = []\n",
    "    for t, w in zip(tags, words):\n",
    "        arg = t\n",
    "        if '-' in t:\n",
    "            arg = t.split('-')[1]\n",
    "        if arg == arg_target:\n",
    "            arg_list.append(w)\n",
    "    arg_set = set(arg_list)\n",
    "    return arg_set\n",
    "\n",
    "\n",
    "# Helper function to display failures\n",
    "\n",
    "def format_srl(x, pred, conf, label=None, meta=None):\n",
    "    results = []\n",
    "    predicate_structure = pred['verbs'][0]['description']\n",
    "        \n",
    "    return predicate_structure\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test arg1 with names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def found_arg1_people(x, pred, conf, label=None, meta=None):\n",
    "    \n",
    "    # people should be recognized as arg1\n",
    "\n",
    "    people = set([meta['first_name'], meta['last_name']])\n",
    "    arg_1 = get_arg(pred, arg_target='ARG1')\n",
    "\n",
    "    if arg_1 == people:\n",
    "        pass_ = True\n",
    "    else:\n",
    "        pass_ = False\n",
    "    return pass_\n",
    "\n",
    "\n",
    "expect_arg1 = Expect.single(found_arg1_people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'aggregate',\n",
       " 'aggregate_testcase',\n",
       " 'all',\n",
       " 'combine',\n",
       " 'combine_and',\n",
       " 'combine_or',\n",
       " 'eq',\n",
       " 'inv',\n",
       " 'monotonic',\n",
       " 'pairwise',\n",
       " 'single',\n",
       " 'slice_orig',\n",
       " 'slice_pairwise',\n",
       " 'slice_single',\n",
       " 'slice_testcase',\n",
       " 'test',\n",
       " 'testcase',\n",
       " 'wrap_slice']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(Expect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Western names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'checklist.editor.MunchWithAdd'>\n",
      "meta [{'first_name': 'Frances', 'last_name': 'Carter'}, {'first_name': 'George', 'last_name': 'Hall'}, {'first_name': 'Annie', 'last_name': 'Scott'}, {'first_name': 'Ray', 'last_name': 'Murphy'}, {'first_name': 'Charles', 'last_name': 'Foster'}, {'first_name': 'Charles', 'last_name': 'Collins'}, {'first_name': 'Lauren', 'last_name': 'Ward'}, {'first_name': 'Al', 'last_name': 'Foster'}, {'first_name': 'Florence', 'last_name': 'Palmer'}, {'first_name': 'Robin', 'last_name': 'Baker'}]\n",
      "data ['Someone killed Frances Carter last night.', 'Someone killed George Hall last night.', 'Someone killed Annie Scott last night.', 'Someone killed Ray Murphy last night.', 'Someone killed Charles Foster last night.', 'Someone killed Charles Collins last night.', 'Someone killed Lauren Ward last night.', 'Someone killed Al Foster last night.', 'Someone killed Florence Palmer last night.', 'Someone killed Robin Baker last night.']\n"
     ]
    }
   ],
   "source": [
    "# initialize editor object\n",
    "editor = Editor()\n",
    "\n",
    "# create examples\n",
    "t = editor.template(\"Someone killed {first_name} {last_name} last night.\", meta=True, nsamples=10)\n",
    "\n",
    "print(type(t))\n",
    "\n",
    "for k, v in t.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'checklist.editor.MunchWithAdd'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_get_fillin_items',\n",
       " '_load_lexicons',\n",
       " '_set_selected_suggestions',\n",
       " '_wordnet_stuff',\n",
       " 'add_lexicon',\n",
       " 'antonyms',\n",
       " 'data',\n",
       " 'hypernyms',\n",
       " 'hyponyms',\n",
       " 'lexicons',\n",
       " 'related_words',\n",
       " 'selected_suggestions',\n",
       " 'suggest',\n",
       " 'suggest_replace',\n",
       " 'synonyms',\n",
       " 'template',\n",
       " 'tg_params',\n",
       " 'visual_suggest']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(t))\n",
    "dir(editor)\n",
    "\n",
    "#t.data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "editor.add_lexicon(name = 'things_to_spill', values = ['water', 'drink', 'soda', 'coke', 'pepsi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sentiment', 'male', 'female', 'first_name', 'first_pronoun', 'last_name', 'country', 'nationality', 'city', 'religion', 'religion_adj', 'sexual_adj', 'country_city', 'male_from', 'female_from', 'last_from', 'things_to_spill'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "editor.lexicons.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asexual',\n",
       " 'bisexual',\n",
       " 'heterosexual',\n",
       " 'homosexual',\n",
       " 'pansexual',\n",
       " 'queer',\n",
       " 'transsexual',\n",
       " 'trans',\n",
       " 'gay',\n",
       " 'straight',\n",
       " 'transgender',\n",
       " 'lesbian',\n",
       " 'non-binary',\n",
       " 'cisgender']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "editor.lexicons['things_to_spill'][:5]\n",
    "editor.lexicons['sexual_adj']#[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 10 examples\n",
      "Test cases:      10\n",
      "Fails (rate):    0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "# initialize a rest object\n",
    "test = MFT(**t, name = 'detect_arg1_name_default_position', expect=expect_arg1)\n",
    "test.run(predict_and_conf)\n",
    "test.summary(format_example_fn=format_srl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'first_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## try\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#ret = editor.template('This is not {a:pos} {mask}.', pos=pos, labels=0, save=True, nsamples=100)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m t \u001b[38;5;241m=\u001b[39m editor\u001b[38;5;241m.\u001b[39mtemplate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSomeone killed \u001b[39m\u001b[38;5;132;01m{first_name}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{last_name}\u001b[39;00m\u001b[38;5;124m last night.\u001b[39m\u001b[38;5;124m\"\u001b[39m, meta\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, nsamples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m t \u001b[38;5;241m=\u001b[39m editor\u001b[38;5;241m.\u001b[39mtemplate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSomeone killed \u001b[39m\u001b[38;5;132;01m{first_name}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{last_name}\u001b[39;00m\u001b[38;5;124m last night.\u001b[39m\u001b[38;5;124m\"\u001b[39m, meta\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, nsamples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, labels\u001b[38;5;241m=\u001b[39m{\u001b[43mfirst_name\u001b[49m})\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(t)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'first_name' is not defined"
     ]
    }
   ],
   "source": [
    "## try\n",
    "\n",
    "#ret = editor.template('This is not {a:pos} {mask}.', pos=pos, labels=0, save=True, nsamples=100)\n",
    "t = editor.template(\"Someone killed {first_name} {last_name} last night.\", meta=True, nsamples=2, labels=1)\n",
    "t = editor.template(\"Someone killed {first_name} {last_name} last night.\", meta=True, nsamples=2, labels={first_name})\n",
    "\n",
    "print(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds\n",
      "confs\n",
      "expect_results\n",
      "passed\n"
     ]
    }
   ],
   "source": [
    "# the test object:\n",
    "#dir(test)\n",
    "for k, v in test.results.items():\n",
    "    print(k)#, v, '\\n')\n",
    "    \n",
    "#print(test.results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_check_create_results',\n",
       " '_check_results',\n",
       " '_extract_examples_per_testcase',\n",
       " '_form_examples_per_testcase_for_viz',\n",
       " '_label_meta',\n",
       " '_results_exist',\n",
       " 'agg_fn',\n",
       " 'capability',\n",
       " 'data',\n",
       " 'description',\n",
       " 'example_list_and_indices',\n",
       " 'expect',\n",
       " 'fail_idxs',\n",
       " 'filtered_idxs',\n",
       " 'form_test_info',\n",
       " 'form_testcases',\n",
       " 'from_file',\n",
       " 'get_stats',\n",
       " 'labels',\n",
       " 'meta',\n",
       " 'name',\n",
       " 'print',\n",
       " 'print_first',\n",
       " 'print_stats',\n",
       " 'recover_example_list_and_indices',\n",
       " 'result_indexes',\n",
       " 'results',\n",
       " 'run',\n",
       " 'run_from_file',\n",
       " 'run_from_preds_confs',\n",
       " 'run_idxs',\n",
       " 'save',\n",
       " 'set_expect',\n",
       " 'summary',\n",
       " 'templates',\n",
       " 'to_raw_examples',\n",
       " 'to_raw_file',\n",
       " 'update_expect',\n",
       " 'update_results_from_preds',\n",
       " 'visual_summary']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(test)\n",
    "#test.expect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'last_name': 'Hamilton', 'first_name': 'Catherine'},\n",
       " {'last_name': 'Bell', 'first_name': 'Mike'},\n",
       " {'last_name': 'Turner', 'first_name': 'Fred'},\n",
       " {'last_name': 'Carter', 'first_name': 'Marie'},\n",
       " {'last_name': 'Rose', 'first_name': 'Leslie'},\n",
       " {'last_name': 'Murray', 'first_name': 'Barbara'},\n",
       " {'last_name': 'Robertson', 'first_name': 'Julia'},\n",
       " {'last_name': 'Morris', 'first_name': 'Andrea'},\n",
       " {'last_name': 'Allen', 'first_name': 'Hugh'},\n",
       " {'last_name': 'Kennedy', 'first_name': 'Robert'}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.description = 'arg1 with names'\n",
    "test.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test cases:      10\n",
      "Fails (rate):    0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "test.summary(format_example_fn=format_srl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 10 examples\n",
      "Test cases:      10\n",
      "Fails (rate):    10 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "Joe Parker [V: was] killed by someone last night .\n",
      "----\n",
      "Kim Cook [V: was] killed by someone last night .\n",
      "----\n",
      "Ruth Watson [V: was] killed by someone last night .\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "editor = Editor()\n",
    "t = editor.template(\"{first_name} {last_name} was killed by someone last night.\", meta=True, nsamples=10)\n",
    "test = MFT(**t, expect=expect_arg1)\n",
    "test.run(predict_and_conf)\n",
    "test.summary(format_example_fn=format_srl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 10 examples\n",
      "Test cases:      10\n",
      "Fails (rate):    10 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "It [V: was] [ARG2: Leslie Watson] [ARG1: who got killed last night] .\n",
      "----\n",
      "[ARG1: It] [V: was] [ARG2: Sophie Bennett] [ARGM-PRD: who got killed last night] .\n",
      "----\n",
      "[ARG1: It] [V: was] [ARG2: Angela Thompson who got killed last night] .\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "editor = Editor()\n",
    "t = editor.template(\"It was {first_name} {last_name} who got killed last night.\", meta=True, nsamples=10)\n",
    "test = MFT(**t, expect=expect_arg1)\n",
    "test.run(predict_and_conf)\n",
    "test.summary(format_example_fn=format_srl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-western names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = [x.split()[0] for x in editor.lexicons.male_from.Vietnam +  editor.lexicons.female_from.Vietnam]\n",
    "last = [x.split()[0] for x in editor.lexicons.last_from.Vietnam]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 10 examples\n",
      "Test cases:      10\n",
      "Fails (rate):    1 (10.0%)\n",
      "\n",
      "Example fails:\n",
      "[ARG0: Someone] [V: killed] [ARG1: Walter] Khc [ARGM-TMP: last night] .\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "t = editor.template(\"Someone killed {first_name} {last_name}  last night.\", first_name=first, last_name=last, meta=True, nsamples=10)\n",
    "test = MFT(**t, expect=expect_arg1)\n",
    "test.run(predict_and_conf)\n",
    "test.summary(format_example_fn=format_srl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 10 examples\n",
      "Test cases:      10\n",
      "Fails (rate):    10 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "Th Tun [V: was] killed by someone last night .\n",
      "----\n",
      "Alfred Khc [V: was] killed by someone last night .\n",
      "----\n",
      "Andrew Vu [V: was] killed by someone last night .\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "t = editor.template(\"{first_name} {last_name} was killed by someone last night.\", first_name=first, last_name=last, meta=True, nsamples=10)\n",
    "test = MFT(**t, expect=expect_arg1)\n",
    "test.run(predict_and_conf)\n",
    "test.summary(format_example_fn=format_srl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 10 examples\n",
      "Test cases:      10\n",
      "Fails (rate):    10 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "[ARG1: It] [V: was] [ARG2: Augustine Walters who was killed last night] .\n",
      "----\n",
      "[ARG1: It] [V: was] [ARG2: Thi Diem] [ARGM-PRD: who was killed last night] .\n",
      "----\n",
      "It [V: was] [ARG2: Lien Kelly] [ARG1: who was] [ARGM-PRD: killed last night] .\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "t = editor.template(\"It was {first_name} {last_name} who was killed last night.\", first_name=first, last_name=last, meta=True, nsamples=10)\n",
    "test = MFT(**t, expect=expect_arg1)\n",
    "test.run(predict_and_conf)\n",
    "test.summary(format_example_fn=format_srl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test instrument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def found_arg2_instrument(x, pred, conf, label=None, meta=None):\n",
    "    \n",
    "    # people should be recognized as arg1\n",
    "    \n",
    "    instrument = set(meta['instrument'].split(' '))\n",
    "    arg_3 = get_arg(pred, arg_target='ARG2')\n",
    "\n",
    "    if arg_3 == instrument:\n",
    "        pass_ = True\n",
    "    else:\n",
    "        pass_ = False\n",
    "    return pass_\n",
    "\n",
    "\n",
    "expect_arg2 = Expect.single(found_arg2_instrument)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 1 examples\n",
      "Test cases:      1\n",
      "Fails (rate):    0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "t = editor.template(\"The girl broke the vase {instrument}.\", instrument=['with a football'],  meta=True, nsamples=1)\n",
    "test = MFT(**t, expect=expect_arg2)\n",
    "test.run(predict_and_conf)\n",
    "test.summary(format_example_fn=format_srl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 1 examples\n",
      "Test cases:      1\n",
      "Fails (rate):    1 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "[ARG0: The girl] [V: opened] [ARG1: the envenlope] [ARG3: with a knife] .\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "t = editor.template(\"The girl opened the envenlope {instrument}.\", instrument=['with a knife'],  meta=True, nsamples=1)\n",
    "test = MFT(**t, expect=expect_arg2)\n",
    "test.run(predict_and_conf)\n",
    "test.summary(format_example_fn=format_srl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 1 examples\n",
      "Test cases:      1\n",
      "Fails (rate):    1 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "[ARG0: The knife] [V: opened] [ARG1: the envelope]\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "t = editor.template(\"{instrument} opened the envelope\", instrument=['The knife'],  meta=True, nsamples=1)\n",
    "test = MFT(**t, expect=expect_arg2)\n",
    "test.run(predict_and_conf)\n",
    "test.summary(format_example_fn=format_srl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 1 examples\n",
      "Test cases:      1\n",
      "Fails (rate):    1 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "[ARG0: The wind] [V: shut] [ARG1: the door] .\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "t = editor.template(\"{instrument} shut the door.\", instrument=['The wind'],  meta=True, nsamples=1)\n",
    "test = MFT(**t, expect=expect_arg2)\n",
    "test.run(predict_and_conf)\n",
    "test.summary(format_example_fn=format_srl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 1 examples\n",
      "Test cases:      1\n",
      "Fails (rate):    1 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "[ARG0: The ball] [V: broke] [ARG1: the window] .\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "t = editor.template(\"{instrument} broke the window.\", instrument=['The ball'],  meta=True, nsamples=1)\n",
    "test = MFT(**t, expect=expect_arg2)\n",
    "test.run(predict_and_conf)\n",
    "test.summary(format_example_fn=format_srl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting with other test types: DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(editor)\n",
    "# help(editor.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def change_agent_instrument(x, meta=True, *args, **kwargs):\n",
    "    agents = ['John', 'Mary']\n",
    "    instruments = ['The hammer'] #, 'The hammer']\n",
    "    \n",
    "    ret = []\n",
    "    ret_meta = []\n",
    "    \n",
    "    for a in agents:\n",
    "        if re.search(r'\\b%s\\b' % a, x):\n",
    "            for i in instruments:\n",
    "                ret.append(re.sub(r'\\b%s\\b' % a, i, x))\n",
    "                ret_meta.append((a, i))\n",
    "                \n",
    "#             ret.extend([re.sub(r'\\b%s\\b' % a, i, x) for i in instruments])\n",
    "#             ret_meta.extend([(a, i) for i in instruments])\n",
    "    if meta:\n",
    "        return ret, ret_meta\n",
    "    else:\n",
    "        return ret\n",
    "    \n",
    "    \n",
    "    \n",
    "def change_instrument_mod(x, meta=True, *args, **kwargs):\n",
    "    instruments = ['the hammer', 'the key', 'the knife'] #, 'The hammer']\n",
    "    mods = ['the flower'] #, 'the stripes', 'the stain']\n",
    "    \n",
    "    ret = []\n",
    "    ret_meta = []\n",
    "    \n",
    "    for i in instruments:\n",
    "        if re.search(r'\\b%s\\b' % i, x):\n",
    "            for m in mods:\n",
    "                ret.append(re.sub(r'\\b%s\\b' % i, m, x))\n",
    "                ret_meta.append((i, m))\n",
    "                \n",
    "#             ret.extend([re.sub(r'\\b%s\\b' % a, i, x) for i in instruments])\n",
    "#             ret_meta.extend([(a, i) for i in instruments])\n",
    "    if meta:\n",
    "        return ret, ret_meta\n",
    "    else:\n",
    "        return ret\n",
    "    \n",
    "    \n",
    "# create test\n",
    "\n",
    "def get_arg_span(pred, target_span=[]):\n",
    "    # we assume one predicate:\n",
    "    predicate_arguments = pred['verbs'][0]\n",
    "    words = pred['words']\n",
    "    tags = predicate_arguments['tags']\n",
    "    \n",
    "    arg_list = []\n",
    "    for t, w in zip(tags, words):\n",
    "        arg = t\n",
    "        if '-' in t:\n",
    "            arg = t.split('-')[1]\n",
    "        if w in target_span:\n",
    "            arg_list.append(arg)\n",
    "    return arg_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compare_spans(orig_pred, pred, orig_conf, conf, labels=None, meta=None):\n",
    "    \n",
    "    sp_orig = meta[0].split(' ')\n",
    "    sp_pred = meta[1].split(' ')\n",
    "    \n",
    "    \n",
    "    l_orig = set(get_arg_span(orig_pred, sp_orig))\n",
    "    l_pred = set(get_arg_span(pred, sp_pred))\n",
    "    \n",
    "    if l_orig == l_pred:\n",
    "        pass_ = False\n",
    "    else:\n",
    "        pass_ = True\n",
    "    \n",
    "    \n",
    "    return pass_\n",
    "\n",
    "expect_fn = Expect.pairwise(compare_spans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent v.s. instrument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "\n",
    "data = ['John broke the vase.',\n",
    "       'Mary broke the window.',\n",
    "       'John openend the door.',\n",
    "       'Mary broke the log.',\n",
    "       'John broke the glass.',\n",
    "       'Mary broke the plate.']\n",
    "        \n",
    "\n",
    "t_p = Perturb.perturb(data, change_agent_instrument, \n",
    "                      meta=True, keep_original=True, n_samples=1)\n",
    "\n",
    "# Modify the structure of the meta-data so they can be used for this test\n",
    "new_meta=[]\n",
    "for m in t_p.meta:\n",
    "    new_meta.append(m[1])\n",
    "t_p.meta = new_meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 12 examples\n",
      "Test cases:      6\n",
      "Fails (rate):    5 (83.3%)\n",
      "\n",
      "Example fails:\n",
      "[ARG0: Mary] [V: broke] [ARG1: the log] .\n",
      "[ARG0: The hammer] [V: broke] [ARG1: the log] .\n",
      "\n",
      "----\n",
      "[ARG0: John] [V: broke] [ARG1: the vase] .\n",
      "[ARG0: The hammer] [V: broke] [ARG1: the vase] .\n",
      "\n",
      "----\n",
      "[ARG0: Mary] [V: broke] [ARG1: the plate] .\n",
      "[ARG0: The hammer] [V: broke] [ARG1: the plate] .\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "# run test\n",
    "test = DIR(**t_p, expect = expect_fn)\n",
    "test.run(predict_and_conf)\n",
    "test.summary(format_example_fn=format_srl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'verbs': [{'verb': 'broke', 'description': '[ARG0: John] [V: broke] [ARG1: the vase] .', 'tags': ['B-ARG0', 'B-V', 'B-ARG1', 'I-ARG1', 'O']}], 'words': ['John', 'broke', 'the', 'vase', '.']}\n",
      " {'verbs': [{'verb': 'broke', 'description': '[ARG0: The hammer] [V: broke] [ARG1: the vase] .', 'tags': ['B-ARG0', 'I-ARG0', 'B-V', 'B-ARG1', 'I-ARG1', 'O']}], 'words': ['The', 'hammer', 'broke', 'the', 'vase', '.']}]\n",
      "\n",
      "[{'verbs': [{'verb': 'broke', 'description': '[ARG0: Mary] [V: broke] [ARG1: the window] .', 'tags': ['B-ARG0', 'B-V', 'B-ARG1', 'I-ARG1', 'O']}], 'words': ['Mary', 'broke', 'the', 'window', '.']}\n",
      " {'verbs': [{'verb': 'broke', 'description': '[ARG0: The hammer] [V: broke] [ARG1: the window] .', 'tags': ['B-ARG0', 'I-ARG0', 'B-V', 'B-ARG1', 'I-ARG1', 'O']}], 'words': ['The', 'hammer', 'broke', 'the', 'window', '.']}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# inspect results\n",
    "# ask yourself: is this test useful? what can it do? what can't it do?\n",
    "for p in test.results.preds[:2]:\n",
    "    print(p)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrument v.s. NP modifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = ['John broke the vase with the hammer.',\n",
    "       'Mary broke the window with the hammer.',\n",
    "       'John openend the door with the key.',\n",
    "       'John broke the glass with the hammer.',\n",
    "       'Mary openend the envelope with the knife.']\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MunchWithAdd({'data': [['John broke the vase with the hammer.', 'John broke the vase with the flower.'], ['Mary broke the window with the hammer.', 'Mary broke the window with the flower.'], ['John openend the door with the key.', 'John openend the door with the flower.'], ['John broke the glass with the hammer.', 'John broke the glass with the flower.'], ['Mary openend the envelope with the knife.', 'Mary openend the envelope with the flower.']], 'meta': [('the hammer', 'the flower'), ('the hammer', 'the flower'), ('the key', 'the flower'), ('the hammer', 'the flower'), ('the knife', 'the flower')]})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_p = Perturb.perturb(data, change_instrument_mod, \n",
    "                      meta=True, keep_original=True, n_samples=1)\n",
    "new_meta=[]\n",
    "for m in t_p.meta:\n",
    "    new_meta.append(m[1])\n",
    "t_p.meta = new_meta\n",
    "\n",
    "\n",
    "t_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running\n",
      "Predicting 10 examples\n",
      "Test cases:      5\n",
      "Fails (rate):    3 (60.0%)\n",
      "\n",
      "Example fails:\n",
      "[ARGM-MNR: John] [V: openend] [ARG1: the door] [ARGM-MNR: with the key] .\n",
      "[ARGM-MNR: John] [V: openend] [ARG1: the door] [ARGM-MNR: with the flower] .\n",
      "\n",
      "----\n",
      "[ARG0: John] [V: broke] [ARG1: the vase] [ARG2: with the hammer] .\n",
      "[ARG0: John] [V: broke] [ARG1: the vase] [ARG2: with the flower] .\n",
      "\n",
      "----\n",
      "[ARG0: Mary] [V: openend] [ARG1: the envelope] [ARGM-MNR: with the knife] .\n",
      "[ARG0: Mary] [V: openend] [ARG1: the envelope] [ARGM-MNR: with the flower] .\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "test = DIR(**t_p, expect = expect_fn)\n",
    "print('running')\n",
    "test.run(predict_and_conf)\n",
    "test.summary(format_example_fn=format_srl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'verbs': [{'verb': 'broke', 'description': '[ARG0: John] [V: broke] [ARG1: the vase] [ARG2: with the hammer] .', 'tags': ['B-ARG0', 'B-V', 'B-ARG1', 'I-ARG1', 'B-ARG2', 'I-ARG2', 'I-ARG2', 'O']}], 'words': ['John', 'broke', 'the', 'vase', 'with', 'the', 'hammer', '.']}\n",
      " {'verbs': [{'verb': 'broke', 'description': '[ARG0: John] [V: broke] [ARG1: the vase] [ARG2: with the flower] .', 'tags': ['B-ARG0', 'B-V', 'B-ARG1', 'I-ARG1', 'B-ARG2', 'I-ARG2', 'I-ARG2', 'O']}], 'words': ['John', 'broke', 'the', 'vase', 'with', 'the', 'flower', '.']}]\n",
      "\n",
      "[{'verbs': [{'verb': 'broke', 'description': '[ARG0: Mary] [V: broke] [ARG1: the window] [ARG2: with the hammer] .', 'tags': ['B-ARG0', 'B-V', 'B-ARG1', 'I-ARG1', 'B-ARG2', 'I-ARG2', 'I-ARG2', 'O']}], 'words': ['Mary', 'broke', 'the', 'window', 'with', 'the', 'hammer', '.']}\n",
      " {'verbs': [{'verb': 'broke', 'description': '[ARG0: Mary] [V: broke] [ARG1: the window] [ARGM-MNR: with the flower] .', 'tags': ['B-ARG0', 'B-V', 'B-ARG1', 'I-ARG1', 'B-ARGM-MNR', 'I-ARGM-MNR', 'I-ARGM-MNR', 'O']}], 'words': ['Mary', 'broke', 'the', 'window', 'with', 'the', 'flower', '.']}]\n",
      "\n",
      "[{'verbs': [{'verb': 'openend', 'description': '[ARGM-MNR: John] [V: openend] [ARG1: the door] [ARGM-MNR: with the key] .', 'tags': ['B-ARGM-MNR', 'B-V', 'B-ARG1', 'I-ARG1', 'B-ARGM-MNR', 'I-ARGM-MNR', 'I-ARGM-MNR', 'O']}], 'words': ['John', 'openend', 'the', 'door', 'with', 'the', 'key', '.']}\n",
      " {'verbs': [{'verb': 'openend', 'description': '[ARGM-MNR: John] [V: openend] [ARG1: the door] [ARGM-MNR: with the flower] .', 'tags': ['B-ARGM-MNR', 'B-V', 'B-ARG1', 'I-ARG1', 'B-ARGM-MNR', 'I-ARGM-MNR', 'I-ARGM-MNR', 'O']}], 'words': ['John', 'openend', 'the', 'door', 'with', 'the', 'flower', '.']}]\n",
      "\n",
      "[{'verbs': [{'verb': 'broke', 'description': '[ARG0: John] [V: broke] [ARG1: the glass] [ARG2: with the hammer] .', 'tags': ['B-ARG0', 'B-V', 'B-ARG1', 'I-ARG1', 'B-ARG2', 'I-ARG2', 'I-ARG2', 'O']}], 'words': ['John', 'broke', 'the', 'glass', 'with', 'the', 'hammer', '.']}\n",
      " {'verbs': [{'verb': 'broke', 'description': '[ARG0: John] [V: broke] [ARG1: the glass] [ARGM-MNR: with the flower] .', 'tags': ['B-ARG0', 'B-V', 'B-ARG1', 'I-ARG1', 'B-ARGM-MNR', 'I-ARGM-MNR', 'I-ARGM-MNR', 'O']}], 'words': ['John', 'broke', 'the', 'glass', 'with', 'the', 'flower', '.']}]\n",
      "\n",
      "[{'verbs': [{'verb': 'openend', 'description': '[ARG0: Mary] [V: openend] [ARG1: the envelope] [ARGM-MNR: with the knife] .', 'tags': ['B-ARG0', 'B-V', 'B-ARG1', 'I-ARG1', 'B-ARGM-MNR', 'I-ARGM-MNR', 'I-ARGM-MNR', 'O']}], 'words': ['Mary', 'openend', 'the', 'envelope', 'with', 'the', 'knife', '.']}\n",
      " {'verbs': [{'verb': 'openend', 'description': '[ARG0: Mary] [V: openend] [ARG1: the envelope] [ARGM-MNR: with the flower] .', 'tags': ['B-ARG0', 'B-V', 'B-ARG1', 'I-ARG1', 'B-ARGM-MNR', 'I-ARGM-MNR', 'I-ARGM-MNR', 'O']}], 'words': ['Mary', 'openend', 'the', 'envelope', 'with', 'the', 'flower', '.']}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for pred in test.results.preds:\n",
    "    print(pred)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
